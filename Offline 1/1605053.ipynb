{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import math\n",
    "import random\n",
    "\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.core.display import display\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# set random seed\n",
    "random.seed(a=2)\n",
    "np.random.seed(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# information gain function\n",
    "def info_gain(df: DataFrame):\n",
    "    all_features = list(df.columns)\n",
    "    y_feature = all_features.pop(len(all_features) - 1)\n",
    "    data = df.copy()\n",
    "    y = data.pop(y_feature)\n",
    "    x = data\n",
    "    importances = mutual_info_classif(x, y)\n",
    "    info_gain_map = {\n",
    "        feature: gain for feature, gain in zip(all_features, importances)\n",
    "    }\n",
    "\n",
    "    info_gain_map = {k: v for k, v in sorted(info_gain_map.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return list(info_gain_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# One-Hot encoding\n",
    "def encode_and_bind(original_dataframe, feature_to_encode):\n",
    "    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
    "    dummies = dummies.iloc[:, :-1]\n",
    "    res = pd.concat([original_dataframe, dummies], axis=1)\n",
    "    res = res.drop([feature_to_encode], axis=1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pre-processor 1\n",
    "def read_telco_data():\n",
    "    return pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv',\n",
    "                             converters={\n",
    "                                 'gender': lambda x: int(x == 'Female'),\n",
    "                                 'Partner': lambda x: int(x == 'Yes'),\n",
    "                                 'Dependents': lambda x: int(x == 'Yes'),\n",
    "                                 'PhoneService': lambda x: int(x =='Yes'),\n",
    "                                 'PaperlessBilling': lambda x: int(x =='Yes'),\n",
    "                                 'Churn': lambda x: int(x =='Yes'),\n",
    "                             })\n",
    "\n",
    "def process_telco_data(telco_data):\n",
    "    telco_data.drop('customerID', axis=1, inplace=True)\n",
    "    telco_data = telco_data.astype({\n",
    "        'tenure': int,\n",
    "        \"MonthlyCharges\": float,\n",
    "        \"TotalCharges\": float\n",
    "    }, errors=\"ignore\")\n",
    "\n",
    "    total_charges_median = (telco_data['TotalCharges'].loc[telco_data['TotalCharges'] != ' ']).median()\n",
    "    telco_data['TotalCharges'].replace([' '], total_charges_median, regex=True, inplace=True)\n",
    "\n",
    "    columns_to_encode = ['MultipleLines', 'InternetService', 'OnlineSecurity',\n",
    "                         'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
    "                         'StreamingMovies', 'Contract', 'PaymentMethod']\n",
    "    for column in columns_to_encode:\n",
    "        telco_data = encode_and_bind(telco_data, column)\n",
    "\n",
    "    # Move final column for better visualization\n",
    "    telco_data.insert(len(telco_data.columns)-1, 'Churn', telco_data.pop('Churn'))\n",
    "\n",
    "    all_columns = list(telco_data.columns)\n",
    "    telco_data[all_columns] = MinMaxScaler().fit_transform(telco_data[all_columns])\n",
    "\n",
    "    return telco_data\n",
    "\n",
    "def preprocess_telco_data():\n",
    "    telco_data = read_telco_data()\n",
    "    telco_data = process_telco_data(telco_data)\n",
    "    telco_data.to_csv('telco.csv')\n",
    "    return telco_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# pre processor 2\n",
    "def read_adult_data(file_name):\n",
    "    column_names = ['C'+str(i) for i in range(15)]\n",
    "    return pd.read_csv(file_name,\n",
    "                         names=column_names,\n",
    "                         header=None,\n",
    "                         sep=' *, * ',\n",
    "                         engine=\"python\",\n",
    "                         converters={\n",
    "                            'C9': lambda x: float(x == 'Male'),\n",
    "                            'C14': lambda x: float(x == '>50K')\n",
    "                         })\n",
    "\n",
    "def process_adult_data(adult_data):\n",
    "    all_columns = list(adult_data.columns)\n",
    "    missing_value_columns = [\n",
    "        column\n",
    "        for column in all_columns\n",
    "        if '?' in adult_data[column].values.tolist()\n",
    "    ]\n",
    "\n",
    "    for column in missing_value_columns:\n",
    "        adult_data[column].replace(['?'], adult_data[column].mode(), inplace=True)\n",
    "\n",
    "    columns_to_encode = ['C1', 'C3', 'C5', 'C6', 'C7', 'C8', 'C13']\n",
    "\n",
    "    for column in columns_to_encode:\n",
    "        adult_data = encode_and_bind(adult_data, column)\n",
    "\n",
    "    adult_data.insert(len(adult_data.columns)-1, 'C14', adult_data.pop('C14'))\n",
    "\n",
    "    all_columns = list(adult_data.columns)\n",
    "    adult_data[all_columns] = MinMaxScaler().fit_transform(adult_data[all_columns])\n",
    "\n",
    "    return adult_data\n",
    "\n",
    "def preprocess_adult_data():\n",
    "    adult_data = read_adult_data('adult.csv')\n",
    "    adult_test = read_adult_data('adult.test.csv')\n",
    "\n",
    "    data_size = adult_data.shape[0]\n",
    "    frames = [adult_data, adult_test]\n",
    "    df = pd.concat(frames)\n",
    "\n",
    "    df = process_adult_data(df)\n",
    "    adult_data, adult_test = df.iloc[0:data_size, :], df.iloc[data_size: , :]\n",
    "\n",
    "    adult_data.to_csv('adult-data.csv')\n",
    "    adult_test.to_csv('adult-test.csv')\n",
    "\n",
    "    return adult_data, adult_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# pre processor 3\n",
    "def read_cc_data():\n",
    "    return pd.read_csv('creditcard.csv')\n",
    "\n",
    "def process_cc_data(cc_data: DataFrame):\n",
    "    positive_data = cc_data.loc[cc_data['Class'] == 1]\n",
    "    negative_data = cc_data.loc[cc_data['Class'] == 0]\n",
    "\n",
    "    negative_sub_data = negative_data.sample(n=20000, replace=False, random_state=15)\n",
    "\n",
    "    frames = [positive_data, negative_sub_data]\n",
    "    cc_data = pd.concat(frames)\n",
    "    # cc_data = cc_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    all_columns = list(cc_data.columns)\n",
    "    cc_data[all_columns] = MinMaxScaler().fit_transform(cc_data[all_columns])\n",
    "\n",
    "    return cc_data\n",
    "\n",
    "def preprocess_cc_data():\n",
    "    cc_data = read_cc_data()\n",
    "    cc_data = process_cc_data(cc_data)\n",
    "    cc_data.to_csv('cc.csv')\n",
    "    return cc_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "def loss(y_predicted, y_actual, size):\n",
    "    return 0.5 * np.sum((y_actual - y_predicted) ** 2) / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# accuracy function\n",
    "def accuracy(y_predicted, y_actual):\n",
    "    return accuracy_score(y_actual, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# prediction function for determining label of hypothesis\n",
    "def predict(hypothesis):\n",
    "    labels = np.array([1.0 if it > 0.0 else -1.0 for it in hypothesis])\n",
    "    labels = labels.reshape((labels.shape[0], 1))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "def train(x, y, early_terminate_threshold=0.0, learning_rate=0.0001, no_of_iterations=10000):\n",
    "    no_of_data, no_of_features = x.shape\n",
    "    w = np.random.rand(no_of_features, 1)\n",
    "    for _ in range(no_of_iterations):\n",
    "        # z = np.dot(x, w)\n",
    "        z = x @ w\n",
    "        h = np.tanh(z)\n",
    "        # y_pred = predict(h)\n",
    "        # error = 1 - accuracy(y_pred, y)\n",
    "        error = loss(h, y, no_of_data)\n",
    "        if error < early_terminate_threshold:\n",
    "            break\n",
    "        # gradient = np.dot(x.T, (y - h) * (1 - h ** 2))\n",
    "        gradient = x.T @ ((y - h) * (1 - h ** 2))\n",
    "        w += learning_rate * gradient\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# resample function for adaboost\n",
    "def resample(x, y, w):\n",
    "    indices = np.random.choice(x.shape[0], x.shape[0], replace=True, p=w )\n",
    "    x_data = x[indices]\n",
    "    y_data = y[indices]\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Adaboost\n",
    "def adaboost(example_x, example_y, k):\n",
    "    no_of_data = example_x.shape[0]\n",
    "    w = np.array([1/no_of_data] * no_of_data)\n",
    "    h = []\n",
    "    z = []\n",
    "    for _ in range(k):\n",
    "        x_data, y_data = resample(example_x, example_y, w)\n",
    "        w_learn = train(x_data, y_data, early_terminate_threshold=0.5)\n",
    "        h_k = np.tanh(np.dot(example_x, w_learn))\n",
    "        h_k = predict(h_k)\n",
    "        error = sum(w[j] for j in range(no_of_data) if h_k[j] != example_y[j])\n",
    "        if error > 0.5:\n",
    "            continue\n",
    "\n",
    "        for j in range(no_of_data):\n",
    "            if h_k[j] == example_y[j]:\n",
    "                w[j] = w[j] * (error / (1-error))\n",
    "\n",
    "        w /= np.sum(w)\n",
    "        h.append(w_learn)\n",
    "        # z.append(math.log((1-error)/error, 2))\n",
    "        z.append(np.log((1-error)/error))\n",
    "\n",
    "    return h, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def logistic_regression_test(training_x, training_y, test_x, test_y, threshold, learning_rate=0.0001):\n",
    "    w_logi = train(training_x, training_y, early_terminate_threshold=threshold, learning_rate=learning_rate)\n",
    "    h_logi = np.tanh(np.dot(test_x, w_logi))\n",
    "    h_logi = predict(h_logi)\n",
    "    print('Logistic regression accuracy {}.'.format(accuracy(h_logi, test_y)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def adaboost_test(training_x, training_y, test_x, test_y, k):\n",
    "    h_ada, z_ada = adaboost(training_x, training_y, k)\n",
    "\n",
    "    hypo = np.zeros(test_y.shape)\n",
    "    for _h, _z in zip(h_ada, z_ada):\n",
    "        l = np.tanh(np.dot(test_x, _h))\n",
    "        hypo += _z * l\n",
    "\n",
    "    # hypo /= sum(z_ada)\n",
    "\n",
    "    h_out = predict(hypo)\n",
    "    print('Adaboost accuracy for k = {} is {}.'.format(k, accuracy(h_out, test_y)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "data = preprocess_telco_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "      gender  SeniorCitizen  Partner  Dependents    tenure  PhoneService  \\\n0        1.0            0.0      1.0         0.0  0.013889           0.0   \n1        0.0            0.0      0.0         0.0  0.472222           1.0   \n2        0.0            0.0      0.0         0.0  0.027778           1.0   \n3        0.0            0.0      0.0         0.0  0.625000           0.0   \n4        1.0            0.0      0.0         0.0  0.027778           1.0   \n...      ...            ...      ...         ...       ...           ...   \n7038     0.0            0.0      1.0         1.0  0.333333           1.0   \n7039     1.0            0.0      1.0         1.0  1.000000           1.0   \n7040     1.0            0.0      1.0         1.0  0.152778           0.0   \n7041     0.0            1.0      1.0         0.0  0.055556           1.0   \n7042     0.0            0.0      0.0         0.0  0.916667           1.0   \n\n      PaperlessBilling  MonthlyCharges  TotalCharges  MultipleLines_No  ...  \\\n0                  1.0        0.115423      0.001275               0.0  ...   \n1                  0.0        0.385075      0.215867               1.0  ...   \n2                  1.0        0.354229      0.010310               1.0  ...   \n3                  0.0        0.239303      0.210241               0.0  ...   \n4                  1.0        0.521891      0.015330               1.0  ...   \n...                ...             ...           ...               ...  ...   \n7038               1.0        0.662189      0.227521               0.0  ...   \n7039               1.0        0.845274      0.847461               0.0  ...   \n7040               1.0        0.112935      0.037809               0.0  ...   \n7041               1.0        0.558706      0.033210               0.0  ...   \n7042               1.0        0.869652      0.787641               1.0  ...   \n\n      StreamingTV_No  StreamingTV_No internet service  StreamingMovies_No  \\\n0                1.0                              0.0                 1.0   \n1                1.0                              0.0                 1.0   \n2                1.0                              0.0                 1.0   \n3                1.0                              0.0                 1.0   \n4                1.0                              0.0                 1.0   \n...              ...                              ...                 ...   \n7038             0.0                              0.0                 0.0   \n7039             0.0                              0.0                 0.0   \n7040             1.0                              0.0                 1.0   \n7041             1.0                              0.0                 1.0   \n7042             0.0                              0.0                 0.0   \n\n      StreamingMovies_No internet service  Contract_Month-to-month  \\\n0                                     0.0                      1.0   \n1                                     0.0                      0.0   \n2                                     0.0                      1.0   \n3                                     0.0                      0.0   \n4                                     0.0                      1.0   \n...                                   ...                      ...   \n7038                                  0.0                      0.0   \n7039                                  0.0                      0.0   \n7040                                  0.0                      1.0   \n7041                                  0.0                      1.0   \n7042                                  0.0                      0.0   \n\n      Contract_One year  PaymentMethod_Bank transfer (automatic)  \\\n0                   0.0                                      0.0   \n1                   1.0                                      0.0   \n2                   0.0                                      0.0   \n3                   1.0                                      1.0   \n4                   0.0                                      0.0   \n...                 ...                                      ...   \n7038                1.0                                      0.0   \n7039                1.0                                      0.0   \n7040                0.0                                      0.0   \n7041                0.0                                      0.0   \n7042                0.0                                      1.0   \n\n      PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n0                                       0.0                             1.0   \n1                                       0.0                             0.0   \n2                                       0.0                             0.0   \n3                                       0.0                             0.0   \n4                                       0.0                             1.0   \n...                                     ...                             ...   \n7038                                    0.0                             0.0   \n7039                                    1.0                             0.0   \n7040                                    0.0                             1.0   \n7041                                    0.0                             0.0   \n7042                                    0.0                             0.0   \n\n      Churn  \n0       0.0  \n1       0.0  \n2       1.0  \n3       0.0  \n4       1.0  \n...     ...  \n7038    0.0  \n7039    0.0  \n7040    0.0  \n7041    1.0  \n7042    0.0  \n\n[7043 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>SeniorCitizen</th>\n      <th>Partner</th>\n      <th>Dependents</th>\n      <th>tenure</th>\n      <th>PhoneService</th>\n      <th>PaperlessBilling</th>\n      <th>MonthlyCharges</th>\n      <th>TotalCharges</th>\n      <th>MultipleLines_No</th>\n      <th>...</th>\n      <th>StreamingTV_No</th>\n      <th>StreamingTV_No internet service</th>\n      <th>StreamingMovies_No</th>\n      <th>StreamingMovies_No internet service</th>\n      <th>Contract_Month-to-month</th>\n      <th>Contract_One year</th>\n      <th>PaymentMethod_Bank transfer (automatic)</th>\n      <th>PaymentMethod_Credit card (automatic)</th>\n      <th>PaymentMethod_Electronic check</th>\n      <th>Churn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.013889</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.115423</td>\n      <td>0.001275</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.472222</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.385075</td>\n      <td>0.215867</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.027778</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.354229</td>\n      <td>0.010310</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.625000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.239303</td>\n      <td>0.210241</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.027778</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.521891</td>\n      <td>0.015330</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7038</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.662189</td>\n      <td>0.227521</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7039</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.845274</td>\n      <td>0.847461</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7040</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.152778</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.112935</td>\n      <td>0.037809</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7041</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.055556</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.558706</td>\n      <td>0.033210</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>7042</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.916667</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.869652</td>\n      <td>0.787641</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7043 rows Ã— 31 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Churn data full\n",
    "data.insert(0, 'Ones', 1.0)\n",
    "data = data.to_numpy()\n",
    "\n",
    "data_x = data[:, :-1]\n",
    "data_y = data[:, -1]\n",
    "\n",
    "data_y = np.array([1.0 if it > 0 else -1.0 for it in data_y])\n",
    "data_y = data_y.reshape((data_y.shape[0], 1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.2, random_state=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# data = preprocess_cc_data()\n",
    "# final_column = data.columns[-1]\n",
    "# train_dataset, test_dataset = train_test_split(data, test_size=0.2, random_state=10)\n",
    "#\n",
    "# columns = info_gain(train_dataset)\n",
    "# feature_cutoff = 70\n",
    "# columns_to_use = columns[0:feature_cutoff]\n",
    "# columns_to_use.append(final_column)\n",
    "# reduced_training, reduced_test = train_dataset[columns_to_use], test_dataset[columns_to_use]\n",
    "#\n",
    "# reduced_training.insert(0, 'Ones', 1.0)\n",
    "# reduced_training = reduced_training.to_numpy()\n",
    "#\n",
    "# reduced_test.insert(0, 'Ones', 1.0)\n",
    "# reduced_test = reduced_test.to_numpy()\n",
    "#\n",
    "# x_train = reduced_training[:, :-1]\n",
    "# y_train = reduced_training[:, -1]\n",
    "# y_train = np.array([1.0 if it > 0 else -1.0 for it in y_train])\n",
    "# y_train = y_train.reshape((y_train.shape[0], 1))\n",
    "#\n",
    "# x_test = reduced_test[:, :-1]\n",
    "# y_test = reduced_test[:, -1]\n",
    "# y_test = np.array([1.0 if it > 0 else -1.0 for it in y_test])\n",
    "# y_test = y_test.reshape((y_test.shape[0], 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy 0.6763662171753017.\n"
     ]
    }
   ],
   "source": [
    "# logistic_regression_test(x_train, y_train, x_test, y_test, 0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost accuracy for k = 5 is 0.7750177430801988.\n",
      "Adaboost accuracy for k = 10 is 0.7892122072391767.\n",
      "Adaboost accuracy for k = 15 is 0.7863733144073811.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for i in range(1, 5):\n",
    "#     adaboost_test(x_train, y_train, x_test, y_test, i*5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_set, test_set = preprocess_adult_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training_set.insert(0, 'Ones', 1.0)\n",
    "# training_set = training_set.to_numpy()\n",
    "# #\n",
    "# test_set.insert(0, 'Ones', 1.0)\n",
    "# test_set = test_set.to_numpy()\n",
    "#\n",
    "# x_train = training_set[:, :-1]\n",
    "# y_train = training_set[:, -1]\n",
    "# #\n",
    "# x_test = test_set[:, :-1]\n",
    "# y_test = test_set[:, -1]\n",
    "# #\n",
    "# y_train = np.array([1.0 if it > 0 else -1.0 for it in y_train])\n",
    "# y_train = y_train.reshape((y_train.shape[0], 1))\n",
    "# #\n",
    "# y_test = np.array([1.0 if it > 0 else -1.0 for it in y_test])\n",
    "# y_test = y_test.reshape((y_test.shape[0], 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# logistic_regression_test(x_train, y_train, x_test, y_test, 0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for i in range(1, 5):\n",
    "#     adaboost_test(x_train, y_train, x_test, y_test, i*5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = preprocess_cc_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Churn data full\n",
    "# data.insert(0, 'Ones', 1.0)\n",
    "# data = data.to_numpy()\n",
    "#\n",
    "# data_x = data[:, :-1]\n",
    "# data_y = data[:, -1]\n",
    "#\n",
    "# data_y = np.array([1.0 if it > 0.0 else -1.0 for it in data_y])\n",
    "# data_y = data_y.reshape((data_y.shape[0], 1))\n",
    "#\n",
    "# x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.2, random_state=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# logistic_regression_test(x_train, y_train, x_test, y_test, 0.5, learning_rate=0.0001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for i in range(1, 5):\n",
    "#     adaboost_test(x_train, y_train, x_test, y_test, i*5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data = preprocess_telco_data()\n",
    "# # data = preprocess_cc_data()\n",
    "# # final_column = data.columns[-1]\n",
    "# # train_dataset, test_dataset = train_test_split(data, test_size=0.2, random_state=10)\n",
    "# #\n",
    "# # columns = info_gain(train_dataset)\n",
    "# # feature_cutoff = 70\n",
    "# # columns_to_use = columns[0:feature_cutoff]\n",
    "# # columns_to_use.append(final_column)\n",
    "# # reduced_training, reduced_test = train_dataset[columns_to_use], test_dataset[columns_to_use]\n",
    "# #\n",
    "# # reduced_training.insert(0, 'Ones', 1.0)\n",
    "# # reduced_training = reduced_training.to_numpy()\n",
    "# #\n",
    "# # reduced_test.insert(0, 'Ones', 1.0)\n",
    "# # reduced_test = reduced_test.to_numpy()\n",
    "# #\n",
    "# # x_train = reduced_training[:, :-1]\n",
    "# # y_train = reduced_training[:, -1]\n",
    "# # y_train = np.array([1.0 if it > 0 else -1.0 for it in y_train])\n",
    "# # y_train = y_train.reshape((y_train.shape[0], 1))\n",
    "# #\n",
    "# # x_test = reduced_test[:, :-1]\n",
    "# # y_test = reduced_test[:, -1]\n",
    "# # y_test = np.array([1.0 if it > 0 else -1.0 for it in y_test])\n",
    "# # y_test = y_test.reshape((y_test.shape[0], 1))\n",
    "#\n",
    "# data.insert(0, 'Ones', 1.0)\n",
    "# data = data.to_numpy()\n",
    "# print(data.shape)\n",
    "# # rows, columns = data.shape\n",
    "#\n",
    "# data_x = data[:, :-1]\n",
    "# data_y = data[:, -1]\n",
    "#\n",
    "# data_y = np.array([1.0 if it > 0 else -1.0 for it in data_y])\n",
    "# data_y = data_y.reshape((data_y.shape[0], 1))\n",
    "#\n",
    "# x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.2, random_state=10)\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(x_test.shape)\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# preprocess_adult_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training_set, test_set = preprocess_adult_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training_set.insert(0, 'Ones', 1.0)\n",
    "# training_set = training_set.to_numpy()\n",
    "#\n",
    "# test_set.insert(0, 'Ones', 1.0)\n",
    "# test_set = test_set.to_numpy()\n",
    "# # # # rows, columns = training_set.shape\n",
    "# # #\n",
    "# x_train = training_set[:, :-1]\n",
    "# y_train = training_set[:, -1]\n",
    "#\n",
    "# x_test = test_set[:, :-1]\n",
    "# y_test = test_set[:, -1]\n",
    "#\n",
    "# y_train = np.array([1.0 if it > 0 else -1.0 for it in y_train])\n",
    "# y_train = y_train.reshape((y_train.shape[0], 1))\n",
    "#\n",
    "# y_test = np.array([1.0 if it > 0 else -1.0 for it in y_test])\n",
    "# y_test = y_test.reshape((y_test.shape[0], 1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic_regression_test(x_train, y_train, x_test, y_test, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for i in range(1, 5):\n",
    "#     adaboost_test(x_train, y_train, x_test, y_test, i*5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}