{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from mlxtend.data import loadlocal_mnist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def process_mnist_data() -> (np.ndarray, np.ndarray, np.ndarray, np.ndarray):\n",
    "    mnist_path = './MNIST/'\n",
    "    train_images, train_labels = loadlocal_mnist(\n",
    "        images_path = mnist_path + './train-images.idx3-ubyte',\n",
    "        labels_path = mnist_path + './train-labels.idx1-ubyte'\n",
    "    )\n",
    "    test_images, test_labels = loadlocal_mnist(\n",
    "        images_path = mnist_path + './t10k-images.idx3-ubyte',\n",
    "        labels_path = mnist_path + './t10k-labels.idx1-ubyte'\n",
    "    )\n",
    "    return train_images, train_labels, test_images, test_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        data_dict = pickle.load(fo, encoding='bytes')\n",
    "    return data_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def process_cifar_dataset() -> (np.ndarray, np.ndarray, np.ndarray, np.ndarray):\n",
    "    cifar_path = './cifar-10-python/cifar-10-batches-py'\n",
    "    data_batch = unpickle(cifar_path + '/data_batch_1')\n",
    "    train_images, train_labels = data_batch[b'data'], np.array(data_batch[b'labels'])\n",
    "    for i in range(2,6):\n",
    "        data_batch = unpickle(cifar_path + '/data_batch_' + str(i))\n",
    "        train_images = np.concatenate((train_images, data_batch[b'data']), axis=0)\n",
    "        train_labels = np.concatenate((train_labels, np.array(data_batch[b'labels'])), axis=0)\n",
    "    test_batch = unpickle(cifar_path + '/test_batch')\n",
    "    test_images, test_labels = test_batch[b'data'], np.array(test_batch[b'labels'])\n",
    "    return train_images, train_labels, test_images, test_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def process_toy_dataset():\n",
    "    toy_dataset_path = './Toy Dataset/'\n",
    "    a = np.loadtxt(toy_dataset_path + 'trainNN.txt')\n",
    "    b = np.loadtxt(toy_dataset_path + 'testNN.txt')\n",
    "    train_x, train_y, test_x, test_y = a[:, 0:4], a[:, -1], b[:, 0:4], b[:, -1]\n",
    "    return train_x, train_y, test_x, test_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def parse_input_model():\n",
    "    path = './input_model.txt'\n",
    "    model = []\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            tokens = line.split()\n",
    "            if tokens[0] == 'Conv':\n",
    "                model.append(ConvolutionLayer(int(tokens[1]), int(tokens[2]), int(tokens[3]), int(tokens[4])))\n",
    "            if tokens[0] == 'ReLU':\n",
    "                model.append(ActivationLayer())\n",
    "            if tokens[0] == 'Pool':\n",
    "                model.append(MaxPoolingLayer(int(tokens[1]), int(tokens[2])))\n",
    "            if tokens[0] == 'FC':\n",
    "                model.append(FlatteningLayer())\n",
    "                model.append(FullyConnectedLayer(int(tokens[1])))\n",
    "            if tokens[0] == 'Softmax':\n",
    "                model.append(SoftmaxLayer())\n",
    "        return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def relu(matrix:np.ndarray) -> np.ndarray:\n",
    "    return matrix * (matrix > 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class ConvolutionLayer:\n",
    "    def __init__(self, output_channel_count: int, filter_dimension: int, stride: int, padding: int):\n",
    "        self.output_channel_count = output_channel_count\n",
    "        self.filter_dimension = filter_dimension\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self, input_image: np.ndarray) -> np.ndarray:\n",
    "        input_dimentions = input_image.shape[0]\n",
    "        output_dimentions = (input_dimentions - self.filter_dimension + 2 * self.padding) // self.stride + 1\n",
    "        input_shape = input_image.shape\n",
    "\n",
    "        filters = np.random.rand(\n",
    "            self.output_channel_count,\n",
    "            self.filter_dimension,\n",
    "            self.filter_dimension,\n",
    "            input_shape[2]\n",
    "        )\n",
    "\n",
    "        bias = np.random.rand(self.output_channel_count)\n",
    "\n",
    "        padded_image = np.pad(input_image, [(self.padding,self.padding), (self.padding,self.padding), (0,0)], mode='constant') * 1.0\n",
    "        padded_image /= 255.0\n",
    "        padded_dimensions = padded_image.shape\n",
    "\n",
    "        output = np.zeros((output_dimentions, output_dimentions, self.output_channel_count))\n",
    "\n",
    "        # for i in range(self.output_channel_count):\n",
    "        #     image_y = out_y = 0\n",
    "        #     while image_y + self.filter_dimension <= padded_dimensions[1]:\n",
    "        #         image_x = out_x = 0\n",
    "        #         while image_x + self.filter_dimension <= padded_dimensions[0]:\n",
    "        #             image_slice = padded_image[image_x:image_x+self.filter_dimension, image_y:image_y+self.filter_dimension, :]\n",
    "        #             output[out_x, out_y, i] = np.sum(image_slice * filters[i, :, :, :]) + bias[i]\n",
    "        #             image_x += self.stride\n",
    "        #             out_x += 1\n",
    "        #         image_y += self.stride\n",
    "        #         out_y += 1\n",
    "\n",
    "        image_y = out_y = 0\n",
    "        while image_y + self.filter_dimension <= padded_dimensions[1]:\n",
    "            image_x = out_x = 0\n",
    "            while image_x + self.filter_dimension <= padded_dimensions[0]:\n",
    "                image_slice = padded_image[image_x:image_x+self.filter_dimension, image_y:image_y+self.filter_dimension, :]\n",
    "                output[out_x, out_y, :] = np.sum(image_slice * filters) + bias\n",
    "                image_x += self.stride\n",
    "                out_x += 1\n",
    "            image_y += self.stride\n",
    "            out_y += 1\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class ActivationLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, input_matrix: np.ndarray) -> np.ndarray:\n",
    "        return relu(input_matrix)\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class MaxPoolingLayer:\n",
    "    def __init__(self, filter_dimension: int, stride: int):\n",
    "        self.filter_dimension = filter_dimension\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, image: np.ndarray) -> np.ndarray:\n",
    "        input_dimensions = image.shape\n",
    "        output_dimension = (input_dimensions[0] - self.filter_dimension) // self.stride + 1\n",
    "\n",
    "        output = np.zeros((output_dimension, output_dimension, input_dimensions[2]))\n",
    "\n",
    "        image_y = out_y = 0\n",
    "        while image_y + self.filter_dimension <= input_dimensions[1]:\n",
    "            image_x = out_x = 0\n",
    "            while image_x + self.filter_dimension <= input_dimensions[0]:\n",
    "                image_slice = image[image_x: image_x+self.filter_dimension, image_y: image_y+self.filter_dimension, :]\n",
    "                output[out_x, out_y, :] = np.max(image_slice, axis=(0, 1))\n",
    "                image_x += self.stride\n",
    "                out_x += 1\n",
    "            image_y += self.stride\n",
    "            out_y += 1\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class FlatteningLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, image: np.ndarray) -> np.ndarray:\n",
    "        return image.flatten().reshape(-1, 1)\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class FullyConnectedLayer:\n",
    "    def __init__(self, output_dimension: int):\n",
    "        self.output_dimension = output_dimension\n",
    "\n",
    "    def forward(self, flattened_input: np.ndarray) -> np.ndarray:\n",
    "        weights = np.random.rand(flattened_input.shape[0], self.output_dimension)\n",
    "        bias = np.random.rand(self.output_dimension, 1)\n",
    "\n",
    "        return weights.T @ flattened_input + bias\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class SoftmaxLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, input_matrix: np.ndarray):\n",
    "        exp = np.exp(input_matrix)\n",
    "        exp /= np.sum(exp)\n",
    "        return exp\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f880ae3b7f0>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = process_mnist_data()\n",
    "img = x_train[0].reshape(28, 28, 1)\n",
    "plt.imshow(img, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.46369228,  0.62404397,  0.85360656,  1.03580981,  2.09692542,\n         3.77655185,  5.30202185,  5.88744633,  6.69527028,  8.31177495,\n         9.6485233 ,  9.36286912,  9.14008746,  7.12817536,  4.4803251 ,\n         1.81410337,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.68047562,  1.1278147 ,  1.97313141,  3.60957893,\n         5.54209407,  7.95155438, 10.79355543, 12.57192885, 15.16380858,\n        18.4085868 , 19.530537  , 18.89958047, 19.03543135, 22.55582615,\n        23.24065276, 20.53433407, 17.25196484, 12.22362598,  7.45248944,\n         2.57820853,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.83302686,  3.37063593,  7.13939033, 10.76950625, 15.69228365,\n        20.04425331, 22.81704447, 25.96132882, 27.54717705, 30.17668748,\n        32.189416  , 32.28696085, 28.91659761, 29.33049902, 29.13515653,\n        26.22427865, 22.68900246, 19.17283268, 14.25770654,  8.20253591,\n         2.57967166,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         1.1854492 ,  6.65103082, 14.15631597, 19.89785336, 26.94523226,\n        33.51827219, 36.82433223, 38.77598051, 39.92462757, 42.13044717,\n        44.36628499, 41.61388326, 35.47162919, 34.71296497, 30.35755273,\n        25.32718316, 22.35974019, 20.55629469, 15.74624243,  8.99596626,\n         2.91744477,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         1.250819  ,  7.60109227, 16.066553  , 23.34269147, 32.82565261,\n        42.81393147, 47.35302814, 48.30049807, 47.71279725, 48.26089695,\n        50.36240847, 45.00673506, 38.46153126, 36.97214777, 32.56610333,\n        26.90438845, 23.9666549 , 21.17858572, 15.08640912,  8.45665322,\n         2.73300357,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         1.08236706,  7.02622355, 14.57913182, 22.7629115 , 34.56110812,\n        49.21171518, 54.47337931, 53.76965318, 52.40272823, 50.47575908,\n        47.5733146 , 40.01645713, 34.46207129, 31.01932488, 24.99023018,\n        17.27207498, 14.38199897, 11.2173869 ,  7.15178987,  3.7924698 ,\n         1.14670568,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         1.12098568,  6.69941021, 14.05940553, 20.84007751, 32.90556792,\n        47.77483985, 52.9063256 , 49.35865342, 47.93534227, 42.78839669,\n        35.26772695, 25.24133022, 21.79811897, 18.01508225, 11.9266653 ,\n         4.46161863,  3.38224299,  2.37577549,  1.458022  ,  0.87049457,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.63243442,  3.73080099,  8.64800733, 12.80173846, 21.92090267,\n        35.33551067, 43.12281754, 42.34324733, 40.08863856, 34.49403151,\n        24.80351787, 13.55736792, 10.17015789,  8.25934376,  5.24443451,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  1.29662381,  3.34245719,  4.82169665, 10.60068395,\n        21.07874333, 31.8874322 , 34.34451699, 34.08621663, 29.57038199,\n        20.18113438,  9.27064509,  5.58650613,  3.67263835,  2.1518885 ,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.58958349,  0.644564  ,  3.60774102,\n        11.69904575, 21.29520536, 28.28387719, 33.39168955, 33.91111438,\n        26.44201038, 15.90341978, 10.44326881,  5.94960859,  2.00809582,\n         0.71017574,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  2.02428735,\n         7.25124852, 15.81528843, 22.47213166, 30.04151019, 35.78528907,\n        34.37899046, 26.50926602, 20.02085709, 13.32394709,  6.70452176,\n         2.63838744,  0.73182138,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.55744529,\n         2.93186732,  9.30231498, 15.62414029, 22.12951457, 31.1381773 ,\n        36.2688612 , 34.97369673, 29.97244979, 22.47037281, 14.1298664 ,\n         7.47483482,  2.77087773,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.81455086,  4.21104331,  9.9648313 , 16.54362403, 24.03291527,\n        33.8769418 , 40.17519489, 39.15584145, 33.03021245, 23.10953049,\n        13.81176909,  6.25274019,  1.13226571,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  1.30733654,  4.89498897, 11.30021085, 19.60557052,\n        32.01389864, 43.29640177, 46.69855893, 41.96829147, 31.97181253,\n        19.44348885,  8.69627859,  1.18991498,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.75273673,  2.14681362,  5.68378348, 12.64262465, 21.91785407,\n        35.41772998, 45.71053412, 51.5613371 , 46.69780838, 37.68050567,\n        24.98310609, 11.29630476,  1.17363385,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.63230154,  1.67424469,\n         4.44928784,  9.36671939, 15.95566748, 22.87320091, 29.80014568,\n        39.90414176, 47.66284812, 51.16254613, 44.73696026, 36.522563  ,\n        23.9443297 , 11.20877513,  1.35207793,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.62427253,  1.27554658,  3.55232029,  8.06744582,\n        14.42506103, 21.73035465, 28.90864738, 35.05574799, 39.65387484,\n        44.52464166, 46.8730915 , 45.21597069, 37.54278547, 30.14883709,\n        18.8561016 ,  8.77488928,  1.17452587,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.58412747,\n         2.05206542,  4.93533317,  8.53468532, 14.36390229, 21.94663483,\n        27.80874266, 33.8582821 , 39.78640173, 43.91653932, 45.66604319,\n        44.96171872, 42.505922  , 38.28137186, 29.58627278, 20.4941098 ,\n        12.11456622,  5.2787676 ,  0.46170213,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.88120094,  2.55239793,  5.31323693,\n        10.22971882, 16.87121705, 22.16530747, 28.4317939 , 34.47976057,\n        39.57364849, 43.88000199, 46.50341338, 46.2936839 , 43.76886079,\n        39.67028289, 34.34892874, 27.4989835 , 19.27722386, 11.7689246 ,\n         6.15198828,  2.45042213,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  2.20650393,  7.43675697, 13.80151103,\n        21.11033332, 28.38766052, 33.85955052, 38.49983751, 43.00298814,\n        45.12008356, 45.02146588, 43.97000419, 40.43966673, 34.91823327,\n        27.80714356, 20.5062944 , 13.20307662,  7.36038797,  3.48757051,\n         1.30138391,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  2.77118399,  8.60746193, 13.96283322,\n        20.42945969, 27.97014881, 33.42490831, 38.19256743, 42.33172609,\n        41.27535831, 39.36364701, 36.08202739, 29.111988  , 21.12437219,\n        13.28039254,  7.47051781,  3.60594043,  1.35502687,  0.46170213,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  2.55610636,  6.48373857, 11.2145286 ,\n        18.99995738, 27.58200418, 33.30988134, 36.1589804 , 36.22743896,\n        33.5104691 , 28.79964725, 22.40920692, 14.76311519,  8.28869866,\n         3.67226   ,  1.41572015,  0.53904124,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  2.21092181,  6.47572369, 11.9734799 ,\n        18.10128518, 23.98653472, 26.73549695, 26.40530888, 24.13124695,\n        20.01113824, 14.44457902,  9.49045239,  4.84976972,  2.02178534,\n         0.56113813,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  1.8965368 ,  5.03688788,  8.25130425,\n        11.0139355 , 13.27641356, 13.17533783, 11.59518429,  8.98985272,\n         5.93173952,  3.47117437,  2.06198098,  0.61638035,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524],\n       [ 0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524,  0.43960524,  0.43960524,\n         0.43960524,  0.43960524,  0.43960524]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = parse_input_model()\n",
    "mnist_batch_1 = x_train[0:64].reshape(64, 28, 28, 1)\n",
    "o = m[0].forward(mnist_batch_1[0,:,:,:])\n",
    "o[:, :, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}