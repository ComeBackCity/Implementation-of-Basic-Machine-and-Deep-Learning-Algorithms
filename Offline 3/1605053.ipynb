{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importing Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pickle\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting Numpy Seed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Processing MNIST Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def process_mnist_data() -> (np.ndarray, np.ndarray, np.ndarray, np.ndarray):\n",
    "    mnist_path = './MNIST/'\n",
    "    train_images, train_labels = loadlocal_mnist(\n",
    "        images_path = mnist_path + './train-images.idx3-ubyte',\n",
    "        labels_path = mnist_path + './train-labels.idx1-ubyte'\n",
    "    )\n",
    "    test_images, test_labels = loadlocal_mnist(\n",
    "        images_path = mnist_path + './t10k-images.idx3-ubyte',\n",
    "        labels_path = mnist_path + './t10k-labels.idx1-ubyte'\n",
    "    )\n",
    "    return train_images, train_labels, test_images, test_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Processing CIFAR-10 Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        data_dict = pickle.load(fo, encoding='bytes')\n",
    "    return data_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def process_cifar_dataset() -> (np.ndarray, np.ndarray, np.ndarray, np.ndarray):\n",
    "    cifar_path = './cifar-10-python/cifar-10-batches-py'\n",
    "    data_batch = unpickle(cifar_path + '/data_batch_1')\n",
    "    train_images, train_labels = data_batch[b'data'], np.array(data_batch[b'labels'])\n",
    "    for i in range(2,6):\n",
    "        data_batch = unpickle(cifar_path + '/data_batch_' + str(i))\n",
    "        train_images = np.concatenate((train_images, data_batch[b'data']), axis=0)\n",
    "        train_labels = np.concatenate((train_labels, np.array(data_batch[b'labels'])), axis=0)\n",
    "    test_batch = unpickle(cifar_path + '/test_batch')\n",
    "    test_images, test_labels = test_batch[b'data'], np.array(test_batch[b'labels'])\n",
    "    return train_images, train_labels, test_images, test_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Processing Toy Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def process_toy_dataset():\n",
    "    toy_dataset_path = './Toy Dataset/'\n",
    "    a = np.loadtxt(toy_dataset_path + 'trainNN.txt')\n",
    "    b = np.loadtxt(toy_dataset_path + 'testNN.txt')\n",
    "    train_x, train_y, test_x, test_y = a[:, 0:4], a[:, -1], b[:, 0:4], b[:, -1]\n",
    "    return train_x, train_y, test_x, test_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 9.21323266, 11.82445528],\n       [16.69098092, 19.56967227]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_toy, y_train_toy, x_test_toy, y_test_toy = process_toy_dataset()\n",
    "toy_batch_1 = x_train_toy[0:50].reshape(50, 1, 2, 2)\n",
    "toy_batch_1[0, 0, :, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 0, 0, 0],\n       [0, 1, 0, 0],\n       [0, 0, 0, 1],\n       [0, 0, 1, 0],\n       [0, 0, 0, 1],\n       [0, 1, 0, 0],\n       [1, 0, 0, 0],\n       [0, 0, 1, 0],\n       [1, 0, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 1, 0, 0],\n       [1, 0, 0, 0],\n       [0, 1, 0, 0],\n       [1, 0, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [1, 0, 0, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [1, 0, 0, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [0, 1, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 1, 0, 0],\n       [1, 0, 0, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [0, 0, 0, 1],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 0, 1],\n       [0, 1, 0, 0],\n       [0, 0, 0, 1],\n       [0, 0, 1, 0]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_binarizer = LabelBinarizer()\n",
    "label_binarizer.fit(range(1,5))\n",
    "toy_labels_1 = label_binarizer.transform(y_train_toy[0:50].T)\n",
    "toy_labels_1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parsing Input Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def parse_input_model():\n",
    "    path = './input_model.txt'\n",
    "    model = []\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            tokens = line.split()\n",
    "            if tokens[0] == 'Conv':\n",
    "                model.append(ConvolutionLayerBatch(int(tokens[1]), int(tokens[2]), int(tokens[3]), int(tokens[4])))\n",
    "            if tokens[0] == 'ReLU':\n",
    "                model.append(ActivationLayer())\n",
    "            if tokens[0] == 'Pool':\n",
    "                model.append(MaxPoolingLayerBatch(int(tokens[1]), int(tokens[2])))\n",
    "            if tokens[0] == 'FC':\n",
    "                model.append(FlatteningLayerBatch())\n",
    "                model.append(FullyConnectedLayerBatch(int(tokens[1])))\n",
    "            if tokens[0] == 'Softmax':\n",
    "                model.append(SoftmaxLayerBatch())\n",
    "        return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ReLU and ReLU Derivative Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def relu(matrix:np.ndarray) -> np.ndarray:\n",
    "    return matrix * (matrix > 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 8,  3],\n       [-1,  0]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randint(-1, 10, (2, 2))\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def relu_derivative(matrix: np.ndarray) -> np.ndarray:\n",
    "    return (matrix > 0).astype(np.int32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convolution Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class ConvolutionLayer:\n",
    "    def __init__(self, output_channel_count: int, filter_dimension: int, stride: int, padding: int):\n",
    "        self.output_channel_count = output_channel_count\n",
    "        self.filter_dimension = filter_dimension\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self, input_image: np.ndarray) -> np.ndarray:\n",
    "        input_dimentions = input_image.shape[0]\n",
    "        output_dimentions = (input_dimentions - self.filter_dimension + 2 * self.padding) // self.stride + 1\n",
    "        input_shape = input_image.shape\n",
    "\n",
    "        filters = np.random.rand(\n",
    "            self.output_channel_count,\n",
    "            self.filter_dimension,\n",
    "            self.filter_dimension,\n",
    "            input_shape[2]\n",
    "        )\n",
    "\n",
    "        bias = np.random.rand(self.output_channel_count)\n",
    "\n",
    "        padded_image = np.pad(input_image, [(self.padding,self.padding), (self.padding,self.padding), (0,0)], mode='constant') * 1.0\n",
    "        # padded_image /= 255.0\n",
    "        padded_dimensions = padded_image.shape\n",
    "\n",
    "        output = np.zeros((output_dimentions, output_dimentions, self.output_channel_count))\n",
    "\n",
    "        image_y = out_y = 0\n",
    "        while image_y + self.filter_dimension <= padded_dimensions[1]:\n",
    "            image_x = out_x = 0\n",
    "            while image_x + self.filter_dimension <= padded_dimensions[0]:\n",
    "                image_slice = padded_image[image_x:image_x+self.filter_dimension, image_y:image_y+self.filter_dimension, :]\n",
    "                output[out_x, out_y, :] = np.sum(image_slice * filters) + bias\n",
    "                image_x += self.stride\n",
    "                out_x += 1\n",
    "            image_y += self.stride\n",
    "            out_y += 1\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class ConvolutionLayerBatch:\n",
    "    def __init__(self, output_channel_count: int, filter_dimension: int, stride: int, padding: int):\n",
    "        self.output_channel_count = output_channel_count\n",
    "        self.filter_dimension = filter_dimension\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.bias = None\n",
    "        self.filters = None\n",
    "        self.input_batch = None\n",
    "\n",
    "    def forward(self, input_batch: np.ndarray) -> np.ndarray:\n",
    "        self.input_batch = input_batch\n",
    "\n",
    "        input_dimentions = input_batch.shape\n",
    "        output_dimentions = (input_dimentions[2] - self.filter_dimension + 2 * self.padding) // self.stride + 1\n",
    "        input_shape = input_batch.shape\n",
    "\n",
    "        if self.filters is None:\n",
    "            self.filters = np.random.randn(\n",
    "                self.output_channel_count,\n",
    "                input_shape[1],\n",
    "                self.filter_dimension,\n",
    "                self.filter_dimension\n",
    "            ) * np.sqrt(2/input_shape[1] * self.filter_dimension ** 2)\n",
    "\n",
    "        # if self.filters is None:\n",
    "        #     self.filters = np.random.randn(\n",
    "        #         self.output_channel_count,\n",
    "        #         input_shape[1],\n",
    "        #         self.filter_dimension,\n",
    "        #         self.filter_dimension\n",
    "        #     ) * 0.01\n",
    "\n",
    "        if self.bias is None:\n",
    "            self.bias = np.zeros(self.output_channel_count)\n",
    "\n",
    "        padded_image = np.pad(input_batch, [(0, 0), (0, 0), (self.padding,self.padding), (self.padding,self.padding)], mode='constant') * 1.0\n",
    "        padded_image /= 255.0\n",
    "        padded_dimensions = padded_image.shape\n",
    "\n",
    "        output = np.zeros((input_dimentions[0], self.output_channel_count, output_dimentions, output_dimentions))\n",
    "\n",
    "        for i in range(input_dimentions[0]):\n",
    "            image_y = out_y = 0\n",
    "            while image_y + self.filter_dimension <= padded_dimensions[3]:\n",
    "                image_x = out_x = 0\n",
    "                while image_x + self.filter_dimension <= padded_dimensions[2]:\n",
    "                    image_slice = padded_image[i, :, image_x:image_x+self.filter_dimension, image_y:image_y+self.filter_dimension]\n",
    "                    output[i, :, out_x, out_y] = np.sum(image_slice * self.filters) + self.bias\n",
    "                    image_x += self.stride\n",
    "                    out_x += 1\n",
    "                image_y += self.stride\n",
    "                out_y += 1\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self, dz: np.ndarray, learning_rate:float = 1e-3) -> np.ndarray:\n",
    "        batch_size = dz.shape[0]\n",
    "        db = np.sum(dz, axis=(0, 2, 3))\n",
    "        self.bias = self.bias - learning_rate * db / batch_size\n",
    "        padded_image = np.pad(self.input_batch, [(0, 0), (0, 0), (self.padding,self.padding), (self.padding,self.padding)], mode='constant') * 1.0\n",
    "        padded_dimensions = padded_image.shape\n",
    "\n",
    "        dw = np.zeros(self.filters.shape)\n",
    "        dz_prime_dim = (dz.shape[2] - 1) * self.stride + 1\n",
    "        dz_prime = np.zeros((dz.shape[0], dz.shape[1], dz_prime_dim, dz_prime_dim))\n",
    "        dz_prime[:, :, ::self.stride, ::self.stride] = dz\n",
    "\n",
    "        # calculate dw\n",
    "        for i in range(padded_dimensions[0]):\n",
    "            image_y = out_y = 0\n",
    "            while image_y + dz_prime_dim <= padded_dimensions[3]:\n",
    "                image_x = out_x = 0\n",
    "                while image_x + dz_prime_dim <= padded_dimensions[2]:\n",
    "                    image_slice = padded_image[i, :, image_x:image_x+dz_prime_dim, image_y:image_y+dz_prime_dim]\n",
    "                    dz_slice = dz_prime[i, :, :, :]\n",
    "                    dz_slice_shape = dz_slice.shape\n",
    "                    dz_slice = np.broadcast_to(dz_slice, (image_slice.shape[0], dz_slice_shape[0], dz_slice_shape[1], dz_slice_shape[2])).transpose((1, 0, 2, 3))\n",
    "                    dw[:, :, out_x, out_y] += np.sum(image_slice * dz_slice, axis=(2, 3))\n",
    "                    image_x += 1\n",
    "                    out_x += 1\n",
    "                image_y += 1\n",
    "                out_y += 1\n",
    "\n",
    "        rotated_filter = np.rot90(self.filters, 2, axes=(2, 3))\n",
    "        dx = np.zeros(self.input_batch.shape)\n",
    "        padding = self.filter_dimension - 1 - self.padding\n",
    "        if padding < 0:\n",
    "            dz_prime_padded = dz_prime[:, :, -padding:padding, -padding:padding]\n",
    "        else:\n",
    "            dz_prime_padded = np.pad(dz_prime, [(0, 0), (0, 0), (padding, padding), (padding, padding)], mode='constant')\n",
    "\n",
    "        dz_padded_dimensions = dz_prime_padded.shape\n",
    "\n",
    "        # calculate dx\n",
    "        for i in range(dz_padded_dimensions[0]):\n",
    "            dz_y = out_y = 0\n",
    "            while dz_y + self.filter_dimension <= dz_padded_dimensions[3]:\n",
    "                dz_x = out_x = 0\n",
    "                while dz_x + self.filter_dimension <= dz_padded_dimensions[2]:\n",
    "                    dzp_slice = dz_prime_padded[i, :, dz_x:dz_x+self.filter_dimension, dz_y:dz_y+self.filter_dimension]\n",
    "                    dzp_slice = dzp_slice.reshape(dz_padded_dimensions[1], 1, self.filter_dimension, self.filter_dimension)\n",
    "                    dx[i, :, out_x, out_y] = np.sum(dzp_slice * rotated_filter, axis=(0, 2, 3))\n",
    "                    dz_x += 1\n",
    "                    out_x += 1\n",
    "                dz_y += 1\n",
    "                out_y += 1\n",
    "\n",
    "        self.filters -= learning_rate * dw / batch_size\n",
    "        return dx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 4, 3, 3)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_conv = ConvolutionLayerBatch(4, 2, 2, 2)\n",
    "test_conv_out = test_conv.forward(toy_batch_1)\n",
    "test_conv_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.        , 0.        ],\n       [0.        , 0.94339174, 0.        ],\n       [0.        , 0.        , 0.        ]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_conv_out[0, 0, :, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Activation Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class ActivationLayer:\n",
    "    def __init__(self):\n",
    "        self.input_batch = None\n",
    "\n",
    "    def forward(self, input_matrix: np.ndarray) -> np.ndarray:\n",
    "        self.input_batch = input_matrix\n",
    "        return relu(input_matrix)\n",
    "\n",
    "    def backward(self, input_matrix: np.ndarray) -> np.ndarray:\n",
    "        return input_matrix * relu_derivative(self.input_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 4, 3, 3)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_activation = ActivationLayer()\n",
    "test_activation_out = test_activation.forward(test_conv_out)\n",
    "test_activation_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.        , 0.        ],\n       [0.        , 0.94339174, 0.        ],\n       [0.        , 0.        , 0.        ]])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_activation_out[0, 0, :, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Max Pooling Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class MaxPoolingLayer:\n",
    "    def __init__(self, filter_dimension: int, stride: int):\n",
    "        self.filter_dimension = filter_dimension\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, image: np.ndarray) -> np.ndarray:\n",
    "        input_dimensions = image.shape\n",
    "        output_dimension = (input_dimensions[0] - self.filter_dimension) // self.stride + 1\n",
    "\n",
    "        output = np.zeros((output_dimension, output_dimension, input_dimensions[2]))\n",
    "\n",
    "        image_y = out_y = 0\n",
    "        while image_y + self.filter_dimension <= input_dimensions[1]:\n",
    "            image_x = out_x = 0\n",
    "            while image_x + self.filter_dimension <= input_dimensions[0]:\n",
    "                image_slice = image[image_x: image_x+self.filter_dimension, image_y: image_y+self.filter_dimension, :]\n",
    "                output[out_x, out_y, :] = np.max(image_slice, axis=(0, 1))\n",
    "                image_x += self.stride\n",
    "                out_x += 1\n",
    "            image_y += self.stride\n",
    "            out_y += 1\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class MaxPoolingLayerBatch:\n",
    "    def __init__(self, filter_dimension: int, stride: int):\n",
    "        self.filter_dimension = filter_dimension\n",
    "        self.stride = stride\n",
    "        self.mask = None\n",
    "        self.input_dimensions = None\n",
    "\n",
    "    def forward(self, image: np.ndarray) -> np.ndarray:\n",
    "        input_dimensions = image.shape\n",
    "        self.input_dimensions = input_dimensions\n",
    "        output_dimension = (input_dimensions[2] - self.filter_dimension) // self.stride + 1\n",
    "\n",
    "        output = np.zeros((input_dimensions[0], input_dimensions[1], output_dimension, output_dimension))\n",
    "        self.mask = np.zeros(input_dimensions)\n",
    "\n",
    "        for i in range(input_dimensions[0]):\n",
    "            image_y = out_y = 0\n",
    "            while image_y + self.filter_dimension <= input_dimensions[3]:\n",
    "                image_x = out_x = 0\n",
    "                while image_x + self.filter_dimension <= input_dimensions[2]:\n",
    "                    image_slice = image[i, :, image_x: image_x+self.filter_dimension, image_y: image_y+self.filter_dimension]\n",
    "                    max_val = np.max(image_slice, axis=(1, 2))\n",
    "                    output[i, :, out_x, out_y] = max_val\n",
    "                    self.mask[i, :, image_x: image_x+self.filter_dimension, image_y: image_y+self.filter_dimension] = image_slice == max_val.reshape(input_dimensions[1], 1, 1)\n",
    "                    image_x += self.stride\n",
    "                    out_x += 1\n",
    "                image_y += self.stride\n",
    "                out_y += 1\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self, dh:np.ndarray) -> np.ndarray:\n",
    "        output = np.zeros(self.input_dimensions)\n",
    "\n",
    "        for i in range(self.input_dimensions[0]):\n",
    "            out_y = dh_y = 0\n",
    "            while out_y + self.filter_dimension <= self.input_dimensions[3]:\n",
    "                out_x = dh_x = 0\n",
    "                while out_x + self.filter_dimension <= self.input_dimensions[2]:\n",
    "                    mask_patch = self.mask[i, :, out_x: out_x+self.filter_dimension, out_y: out_y+self.filter_dimension]\n",
    "                    output[i, :, out_x: out_x+self.filter_dimension, out_y: out_y+self.filter_dimension] += mask_patch * dh[i, :, dh_x, dh_y].reshape(self.input_dimensions[1], 1, 1)\n",
    "                    out_x += self.stride\n",
    "                    dh_x += 1\n",
    "                out_y += self.stride\n",
    "                dh_y += 1\n",
    "\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 4, 2, 2)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_maxpool = MaxPoolingLayerBatch(2, 1)\n",
    "test_maxpool_out = test_maxpool.forward(test_activation_out)\n",
    "test_maxpool_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.94339174, 0.94339174],\n       [0.94339174, 0.94339174]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_maxpool_out[0, 0, :, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Flattening Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "class FlatteningLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(image: np.ndarray) -> np.ndarray:\n",
    "        return image.flatten().reshape(-1, 1)\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "class FlatteningLayerBatch:\n",
    "    def __init__(self):\n",
    "        self.input_shape = None\n",
    "\n",
    "    def forward(self, input_batch: np.ndarray) -> np.ndarray:\n",
    "        input_shape = input_batch.shape\n",
    "        self.input_shape = input_shape\n",
    "        return input_batch.reshape((input_shape[0], -1))\n",
    "\n",
    "    def backward(self, dh_flattened: np.ndarray) -> np.ndarray:\n",
    "        return dh_flattened.reshape(self.input_shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 16)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_flattening = FlatteningLayerBatch()\n",
    "test_flattening_out = test_flattening.forward(test_maxpool_out)\n",
    "test_flattening_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.94339174, 0.94339174, 0.94339174, 0.94339174, 0.94339174,\n        0.94339174, 0.94339174, 0.94339174, 0.94339174, 0.94339174,\n        0.94339174, 0.94339174, 0.94339174, 0.94339174, 0.94339174,\n        0.94339174],\n       [1.85173385, 1.85173385, 1.85173385, 1.85173385, 1.85173385,\n        1.85173385, 1.85173385, 1.85173385, 1.85173385, 1.85173385,\n        1.85173385, 1.85173385, 1.85173385, 1.85173385, 1.85173385,\n        1.85173385],\n       [3.69483751, 3.69483751, 3.69483751, 3.69483751, 3.69483751,\n        3.69483751, 3.69483751, 3.69483751, 3.69483751, 3.69483751,\n        3.69483751, 3.69483751, 3.69483751, 3.69483751, 3.69483751,\n        3.69483751],\n       [2.78262626, 2.78262626, 2.78262626, 2.78262626, 2.78262626,\n        2.78262626, 2.78262626, 2.78262626, 2.78262626, 2.78262626,\n        2.78262626, 2.78262626, 2.78262626, 2.78262626, 2.78262626,\n        2.78262626],\n       [3.70786021, 3.70786021, 3.70786021, 3.70786021, 3.70786021,\n        3.70786021, 3.70786021, 3.70786021, 3.70786021, 3.70786021,\n        3.70786021, 3.70786021, 3.70786021, 3.70786021, 3.70786021,\n        3.70786021],\n       [1.84069571, 1.84069571, 1.84069571, 1.84069571, 1.84069571,\n        1.84069571, 1.84069571, 1.84069571, 1.84069571, 1.84069571,\n        1.84069571, 1.84069571, 1.84069571, 1.84069571, 1.84069571,\n        1.84069571],\n       [0.9161183 , 0.9161183 , 0.9161183 , 0.9161183 , 0.9161183 ,\n        0.9161183 , 0.9161183 , 0.9161183 , 0.9161183 , 0.9161183 ,\n        0.9161183 , 0.9161183 , 0.9161183 , 0.9161183 , 0.9161183 ,\n        0.9161183 ],\n       [2.81248521, 2.81248521, 2.81248521, 2.81248521, 2.81248521,\n        2.81248521, 2.81248521, 2.81248521, 2.81248521, 2.81248521,\n        2.81248521, 2.81248521, 2.81248521, 2.81248521, 2.81248521,\n        2.81248521],\n       [0.92571388, 0.92571388, 0.92571388, 0.92571388, 0.92571388,\n        0.92571388, 0.92571388, 0.92571388, 0.92571388, 0.92571388,\n        0.92571388, 0.92571388, 0.92571388, 0.92571388, 0.92571388,\n        0.92571388],\n       [2.7764411 , 2.7764411 , 2.7764411 , 2.7764411 , 2.7764411 ,\n        2.7764411 , 2.7764411 , 2.7764411 , 2.7764411 , 2.7764411 ,\n        2.7764411 , 2.7764411 , 2.7764411 , 2.7764411 , 2.7764411 ,\n        2.7764411 ],\n       [2.77780753, 2.77780753, 2.77780753, 2.77780753, 2.77780753,\n        2.77780753, 2.77780753, 2.77780753, 2.77780753, 2.77780753,\n        2.77780753, 2.77780753, 2.77780753, 2.77780753, 2.77780753,\n        2.77780753],\n       [2.78489229, 2.78489229, 2.78489229, 2.78489229, 2.78489229,\n        2.78489229, 2.78489229, 2.78489229, 2.78489229, 2.78489229,\n        2.78489229, 2.78489229, 2.78489229, 2.78489229, 2.78489229,\n        2.78489229],\n       [2.80679467, 2.80679467, 2.80679467, 2.80679467, 2.80679467,\n        2.80679467, 2.80679467, 2.80679467, 2.80679467, 2.80679467,\n        2.80679467, 2.80679467, 2.80679467, 2.80679467, 2.80679467,\n        2.80679467],\n       [1.81777033, 1.81777033, 1.81777033, 1.81777033, 1.81777033,\n        1.81777033, 1.81777033, 1.81777033, 1.81777033, 1.81777033,\n        1.81777033, 1.81777033, 1.81777033, 1.81777033, 1.81777033,\n        1.81777033],\n       [0.90801877, 0.90801877, 0.90801877, 0.90801877, 0.90801877,\n        0.90801877, 0.90801877, 0.90801877, 0.90801877, 0.90801877,\n        0.90801877, 0.90801877, 0.90801877, 0.90801877, 0.90801877,\n        0.90801877],\n       [1.84351866, 1.84351866, 1.84351866, 1.84351866, 1.84351866,\n        1.84351866, 1.84351866, 1.84351866, 1.84351866, 1.84351866,\n        1.84351866, 1.84351866, 1.84351866, 1.84351866, 1.84351866,\n        1.84351866],\n       [0.9209529 , 0.9209529 , 0.9209529 , 0.9209529 , 0.9209529 ,\n        0.9209529 , 0.9209529 , 0.9209529 , 0.9209529 , 0.9209529 ,\n        0.9209529 , 0.9209529 , 0.9209529 , 0.9209529 , 0.9209529 ,\n        0.9209529 ],\n       [2.78646972, 2.78646972, 2.78646972, 2.78646972, 2.78646972,\n        2.78646972, 2.78646972, 2.78646972, 2.78646972, 2.78646972,\n        2.78646972, 2.78646972, 2.78646972, 2.78646972, 2.78646972,\n        2.78646972],\n       [3.68373401, 3.68373401, 3.68373401, 3.68373401, 3.68373401,\n        3.68373401, 3.68373401, 3.68373401, 3.68373401, 3.68373401,\n        3.68373401, 3.68373401, 3.68373401, 3.68373401, 3.68373401,\n        3.68373401],\n       [0.91847986, 0.91847986, 0.91847986, 0.91847986, 0.91847986,\n        0.91847986, 0.91847986, 0.91847986, 0.91847986, 0.91847986,\n        0.91847986, 0.91847986, 0.91847986, 0.91847986, 0.91847986,\n        0.91847986],\n       [0.95127094, 0.95127094, 0.95127094, 0.95127094, 0.95127094,\n        0.95127094, 0.95127094, 0.95127094, 0.95127094, 0.95127094,\n        0.95127094, 0.95127094, 0.95127094, 0.95127094, 0.95127094,\n        0.95127094],\n       [3.69742072, 3.69742072, 3.69742072, 3.69742072, 3.69742072,\n        3.69742072, 3.69742072, 3.69742072, 3.69742072, 3.69742072,\n        3.69742072, 3.69742072, 3.69742072, 3.69742072, 3.69742072,\n        3.69742072],\n       [0.94377042, 0.94377042, 0.94377042, 0.94377042, 0.94377042,\n        0.94377042, 0.94377042, 0.94377042, 0.94377042, 0.94377042,\n        0.94377042, 0.94377042, 0.94377042, 0.94377042, 0.94377042,\n        0.94377042],\n       [0.92313126, 0.92313126, 0.92313126, 0.92313126, 0.92313126,\n        0.92313126, 0.92313126, 0.92313126, 0.92313126, 0.92313126,\n        0.92313126, 0.92313126, 0.92313126, 0.92313126, 0.92313126,\n        0.92313126],\n       [3.68547725, 3.68547725, 3.68547725, 3.68547725, 3.68547725,\n        3.68547725, 3.68547725, 3.68547725, 3.68547725, 3.68547725,\n        3.68547725, 3.68547725, 3.68547725, 3.68547725, 3.68547725,\n        3.68547725],\n       [0.93250065, 0.93250065, 0.93250065, 0.93250065, 0.93250065,\n        0.93250065, 0.93250065, 0.93250065, 0.93250065, 0.93250065,\n        0.93250065, 0.93250065, 0.93250065, 0.93250065, 0.93250065,\n        0.93250065],\n       [3.71369541, 3.71369541, 3.71369541, 3.71369541, 3.71369541,\n        3.71369541, 3.71369541, 3.71369541, 3.71369541, 3.71369541,\n        3.71369541, 3.71369541, 3.71369541, 3.71369541, 3.71369541,\n        3.71369541],\n       [0.92343877, 0.92343877, 0.92343877, 0.92343877, 0.92343877,\n        0.92343877, 0.92343877, 0.92343877, 0.92343877, 0.92343877,\n        0.92343877, 0.92343877, 0.92343877, 0.92343877, 0.92343877,\n        0.92343877],\n       [1.84862424, 1.84862424, 1.84862424, 1.84862424, 1.84862424,\n        1.84862424, 1.84862424, 1.84862424, 1.84862424, 1.84862424,\n        1.84862424, 1.84862424, 1.84862424, 1.84862424, 1.84862424,\n        1.84862424],\n       [2.77147537, 2.77147537, 2.77147537, 2.77147537, 2.77147537,\n        2.77147537, 2.77147537, 2.77147537, 2.77147537, 2.77147537,\n        2.77147537, 2.77147537, 2.77147537, 2.77147537, 2.77147537,\n        2.77147537],\n       [2.77271866, 2.77271866, 2.77271866, 2.77271866, 2.77271866,\n        2.77271866, 2.77271866, 2.77271866, 2.77271866, 2.77271866,\n        2.77271866, 2.77271866, 2.77271866, 2.77271866, 2.77271866,\n        2.77271866],\n       [2.79385602, 2.79385602, 2.79385602, 2.79385602, 2.79385602,\n        2.79385602, 2.79385602, 2.79385602, 2.79385602, 2.79385602,\n        2.79385602, 2.79385602, 2.79385602, 2.79385602, 2.79385602,\n        2.79385602],\n       [2.77099607, 2.77099607, 2.77099607, 2.77099607, 2.77099607,\n        2.77099607, 2.77099607, 2.77099607, 2.77099607, 2.77099607,\n        2.77099607, 2.77099607, 2.77099607, 2.77099607, 2.77099607,\n        2.77099607],\n       [1.89232919, 1.89232919, 1.89232919, 1.89232919, 1.89232919,\n        1.89232919, 1.89232919, 1.89232919, 1.89232919, 1.89232919,\n        1.89232919, 1.89232919, 1.89232919, 1.89232919, 1.89232919,\n        1.89232919],\n       [0.90450693, 0.90450693, 0.90450693, 0.90450693, 0.90450693,\n        0.90450693, 0.90450693, 0.90450693, 0.90450693, 0.90450693,\n        0.90450693, 0.90450693, 0.90450693, 0.90450693, 0.90450693,\n        0.90450693],\n       [3.7141321 , 3.7141321 , 3.7141321 , 3.7141321 , 3.7141321 ,\n        3.7141321 , 3.7141321 , 3.7141321 , 3.7141321 , 3.7141321 ,\n        3.7141321 , 3.7141321 , 3.7141321 , 3.7141321 , 3.7141321 ,\n        3.7141321 ],\n       [0.94002948, 0.94002948, 0.94002948, 0.94002948, 0.94002948,\n        0.94002948, 0.94002948, 0.94002948, 0.94002948, 0.94002948,\n        0.94002948, 0.94002948, 0.94002948, 0.94002948, 0.94002948,\n        0.94002948],\n       [2.79829612, 2.79829612, 2.79829612, 2.79829612, 2.79829612,\n        2.79829612, 2.79829612, 2.79829612, 2.79829612, 2.79829612,\n        2.79829612, 2.79829612, 2.79829612, 2.79829612, 2.79829612,\n        2.79829612],\n       [3.73117828, 3.73117828, 3.73117828, 3.73117828, 3.73117828,\n        3.73117828, 3.73117828, 3.73117828, 3.73117828, 3.73117828,\n        3.73117828, 3.73117828, 3.73117828, 3.73117828, 3.73117828,\n        3.73117828],\n       [0.94681574, 0.94681574, 0.94681574, 0.94681574, 0.94681574,\n        0.94681574, 0.94681574, 0.94681574, 0.94681574, 0.94681574,\n        0.94681574, 0.94681574, 0.94681574, 0.94681574, 0.94681574,\n        0.94681574],\n       [3.69914211, 3.69914211, 3.69914211, 3.69914211, 3.69914211,\n        3.69914211, 3.69914211, 3.69914211, 3.69914211, 3.69914211,\n        3.69914211, 3.69914211, 3.69914211, 3.69914211, 3.69914211,\n        3.69914211],\n       [0.91749911, 0.91749911, 0.91749911, 0.91749911, 0.91749911,\n        0.91749911, 0.91749911, 0.91749911, 0.91749911, 0.91749911,\n        0.91749911, 0.91749911, 0.91749911, 0.91749911, 0.91749911,\n        0.91749911],\n       [3.70690356, 3.70690356, 3.70690356, 3.70690356, 3.70690356,\n        3.70690356, 3.70690356, 3.70690356, 3.70690356, 3.70690356,\n        3.70690356, 3.70690356, 3.70690356, 3.70690356, 3.70690356,\n        3.70690356],\n       [3.69459447, 3.69459447, 3.69459447, 3.69459447, 3.69459447,\n        3.69459447, 3.69459447, 3.69459447, 3.69459447, 3.69459447,\n        3.69459447, 3.69459447, 3.69459447, 3.69459447, 3.69459447,\n        3.69459447],\n       [0.93873652, 0.93873652, 0.93873652, 0.93873652, 0.93873652,\n        0.93873652, 0.93873652, 0.93873652, 0.93873652, 0.93873652,\n        0.93873652, 0.93873652, 0.93873652, 0.93873652, 0.93873652,\n        0.93873652],\n       [2.76855582, 2.76855582, 2.76855582, 2.76855582, 2.76855582,\n        2.76855582, 2.76855582, 2.76855582, 2.76855582, 2.76855582,\n        2.76855582, 2.76855582, 2.76855582, 2.76855582, 2.76855582,\n        2.76855582],\n       [3.70081751, 3.70081751, 3.70081751, 3.70081751, 3.70081751,\n        3.70081751, 3.70081751, 3.70081751, 3.70081751, 3.70081751,\n        3.70081751, 3.70081751, 3.70081751, 3.70081751, 3.70081751,\n        3.70081751],\n       [1.84196348, 1.84196348, 1.84196348, 1.84196348, 1.84196348,\n        1.84196348, 1.84196348, 1.84196348, 1.84196348, 1.84196348,\n        1.84196348, 1.84196348, 1.84196348, 1.84196348, 1.84196348,\n        1.84196348],\n       [3.68751753, 3.68751753, 3.68751753, 3.68751753, 3.68751753,\n        3.68751753, 3.68751753, 3.68751753, 3.68751753, 3.68751753,\n        3.68751753, 3.68751753, 3.68751753, 3.68751753, 3.68751753,\n        3.68751753],\n       [2.77292344, 2.77292344, 2.77292344, 2.77292344, 2.77292344,\n        2.77292344, 2.77292344, 2.77292344, 2.77292344, 2.77292344,\n        2.77292344, 2.77292344, 2.77292344, 2.77292344, 2.77292344,\n        2.77292344]])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_flattening_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fully Connected Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "class FullyConnectedLayer:\n",
    "    def __init__(self, output_dimension: int):\n",
    "        self.output_dimension = output_dimension\n",
    "\n",
    "    def forward(self, flattened_input: np.ndarray) -> np.ndarray:\n",
    "        weights = np.random.rand(flattened_input.shape[0], self.output_dimension)\n",
    "        bias = np.random.rand(self.output_dimension, 1)\n",
    "\n",
    "        return weights.T @ flattened_input + bias\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "class FullyConnectedLayerBatch:\n",
    "    def __init__(self, output_dimension: int):\n",
    "        self.output_dimension = output_dimension\n",
    "        self.input_matrix = None\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def forward(self, flattened_input: np.ndarray) -> np.ndarray:\n",
    "        if self.weights is None:\n",
    "            self.weights = np.random.randn(flattened_input.shape[1], self.output_dimension) * np.sqrt(2/flattened_input.shape[1])\n",
    "            # self.weights = np.random.randn(flattened_input.shape[1], self.output_dimension) * 0.01\n",
    "        if self.bias is None:\n",
    "            self.bias = np.zeros((1, self.output_dimension))\n",
    "        self.input_matrix = flattened_input\n",
    "\n",
    "        return flattened_input @ self.weights + self.bias\n",
    "\n",
    "    def backward(self, d_theta: np.ndarray, learning_rate: float = 1e-3) -> np.ndarray:\n",
    "        n = d_theta.shape[0]\n",
    "        dw = self.input_matrix.T @ d_theta\n",
    "        db = np.sum(d_theta, axis=0, keepdims=True)\n",
    "        dh = d_theta @ self.weights.T\n",
    "        self.weights = self.weights - learning_rate * dw / n\n",
    "        self.bias = self.bias - learning_rate * db / n\n",
    "\n",
    "        return dh"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 4)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fc = FullyConnectedLayerBatch(4)\n",
    "test_fc_out = test_fc.forward(test_flattening_out)\n",
    "test_fc_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.00278571, -0.13054229,  0.04797275,  0.1314437 ],\n       [-0.00546792, -0.25623457,  0.09416318,  0.25800389],\n       [-0.01091036, -0.51127494,  0.1878875 ,  0.51480534],\n       [-0.00821672, -0.38504726,  0.14150032,  0.38770605],\n       [-0.01094881, -0.51307696,  0.18854972,  0.5166198 ],\n       [-0.00543533, -0.25470716,  0.09360187,  0.25646594],\n       [-0.00270517, -0.12676832,  0.04658586,  0.12764366],\n       [-0.00830489, -0.38917901,  0.14301869,  0.39186633],\n       [-0.00273351, -0.12809611,  0.04707381,  0.12898062],\n       [-0.00819846, -0.38419139,  0.1411858 ,  0.38684426],\n       [-0.00820249, -0.38438047,  0.14125528,  0.38703465],\n       [-0.00822341, -0.38536083,  0.14161555,  0.38802178],\n       [-0.00828809, -0.38839158,  0.14272932,  0.39107346],\n       [-0.00536763, -0.25153485,  0.09243609,  0.25327172],\n       [-0.00268126, -0.12564754,  0.04617399,  0.12651515],\n       [-0.00544366, -0.25509779,  0.09374543,  0.25685926],\n       [-0.00271945, -0.12743731,  0.0468317 ,  0.12831727],\n       [-0.00822807, -0.3855791 ,  0.14169577,  0.38824156],\n       [-0.01087757, -0.50973849,  0.18732287,  0.51325828],\n       [-0.00271215, -0.1270951 ,  0.04670595,  0.1279727 ],\n       [-0.00280898, -0.13163258,  0.04837342,  0.13254151],\n       [-0.01091799, -0.51163239,  0.18801886,  0.51516526],\n       [-0.00278683, -0.13059469,  0.04799201,  0.13149646],\n       [-0.00272588, -0.12773874,  0.04694248,  0.12862078],\n       [-0.01088272, -0.50997971,  0.18741152,  0.51350116],\n       [-0.00275355, -0.12903523,  0.04741892,  0.12992623],\n       [-0.01096605, -0.51388441,  0.18884645,  0.51743283],\n       [-0.00272679, -0.12778129,  0.04695811,  0.12866363],\n       [-0.00545874, -0.25580428,  0.09400505,  0.25757063],\n       [-0.0081838 , -0.38350425,  0.14093328,  0.38615238],\n       [-0.00818747, -0.38367629,  0.14099651,  0.38632561],\n       [-0.00824988, -0.38660119,  0.14207137,  0.3892707 ],\n       [-0.00818238, -0.38343793,  0.14090891,  0.3860856 ],\n       [-0.00558779, -0.26185197,  0.09622751,  0.26366008],\n       [-0.00267089, -0.12516159,  0.0459954 ,  0.12602584],\n       [-0.01096733, -0.51394484,  0.18886866,  0.51749367],\n       [-0.00277578, -0.13007704,  0.04780177,  0.13097523],\n       [-0.00826299, -0.38721559,  0.14229715,  0.38988934],\n       [-0.01101767, -0.51630361,  0.18973548,  0.51986873],\n       [-0.00279582, -0.13101609,  0.04814687,  0.13192077],\n       [-0.01092307, -0.51187059,  0.18810639,  0.5154051 ],\n       [-0.00270925, -0.12695939,  0.04665607,  0.12783605],\n       [-0.01094599, -0.51294458,  0.18850108,  0.51648651],\n       [-0.01090964, -0.51124131,  0.18787514,  0.51477147],\n       [-0.00277196, -0.12989812,  0.04773603,  0.13079508],\n       [-0.00817517, -0.38310026,  0.14078482,  0.3857456 ],\n       [-0.01092802, -0.51210242,  0.18819159,  0.51563854],\n       [-0.00543907, -0.25488259,  0.09366634,  0.25664258],\n       [-0.01088875, -0.51026203,  0.18751527,  0.51378544],\n       [-0.00818807, -0.38370463,  0.14100692,  0.38635415]])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fc_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Softmax Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "class SoftmaxLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(input_matrix: np.ndarray) -> np.ndarray:\n",
    "        exp = np.exp(input_matrix)\n",
    "        exp /= np.sum(exp)\n",
    "        return exp\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "class SoftmaxLayerBatch:\n",
    "    def __init__(self):\n",
    "        self.y_hat = None\n",
    "\n",
    "    def forward(self, input_matrix: np.ndarray) -> np.ndarray:\n",
    "        input_matrix -= np.max(input_matrix)\n",
    "        exp = np.exp(input_matrix)\n",
    "        exp_sum = np.sum(exp, axis=1).reshape(-1, 1)\n",
    "        exp /= exp_sum\n",
    "        self.y_hat = exp\n",
    "        return exp\n",
    "\n",
    "    def backward(self, y: np.ndarray) -> np.ndarray:\n",
    "        return self.y_hat - y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 4)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_softmax = SoftmaxLayerBatch()\n",
    "test_softmax_out = test_softmax.forward(test_fc_out)\n",
    "test_softmax_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.24535112, 0.21592557, 0.25812624, 0.28059707],\n       [0.23898244, 0.18597708, 0.26401903, 0.31102145],\n       [0.22134109, 0.13420122, 0.27002181, 0.37443588],\n       [0.23077141, 0.15831664, 0.26804227, 0.34286968],\n       [0.22119792, 0.1338781 , 0.2700363 , 0.37488768],\n       [0.23907009, 0.1863236 , 0.26395905, 0.31064726],\n       [0.2455147 , 0.21686905, 0.25791959, 0.27969666],\n       [0.23048288, 0.15748063, 0.26813757, 0.34389893],\n       [0.24545734, 0.21653681, 0.25799249, 0.28001336],\n       [0.23083099, 0.15849022, 0.26802227, 0.34265652],\n       [0.23081784, 0.15845186, 0.2680267 , 0.34270361],\n       [0.23074956, 0.15825309, 0.26804958, 0.34294777],\n       [0.23053798, 0.15763971, 0.26811957, 0.34370274],\n       [0.23925137, 0.18704468, 0.26383356, 0.30987039],\n       [0.24556296, 0.21714972, 0.25785789, 0.27942943],\n       [0.2390477 , 0.18623494, 0.26397442, 0.31074295],\n       [0.24548583, 0.21670161, 0.25795635, 0.27985621],\n       [0.23073435, 0.15820885, 0.26805465, 0.34300214],\n       [0.22146298, 0.13447718, 0.27000916, 0.37405068],\n       [0.2455006 , 0.21678725, 0.25793755, 0.27977459],\n       [0.24530355, 0.21565347, 0.25818563, 0.28085735],\n       [0.2213127 , 0.13413708, 0.27002472, 0.3745255 ],\n       [0.24534884, 0.21591248, 0.2581291 , 0.28060958],\n       [0.2454728 , 0.2166262 , 0.25797289, 0.27992811],\n       [0.22144385, 0.13443383, 0.27001117, 0.37411115],\n       [0.24541664, 0.21630202, 0.25804393, 0.28023741],\n       [0.22113369, 0.13373351, 0.27004266, 0.37509013],\n       [0.24547096, 0.21661556, 0.25797523, 0.27993826],\n       [0.23900716, 0.18607465, 0.26400216, 0.31091603],\n       [0.23087879, 0.15862967, 0.26800615, 0.3424854 ],\n       [0.23086682, 0.15859475, 0.26801019, 0.34252824],\n       [0.23066307, 0.15800185, 0.26807836, 0.34325673],\n       [0.2308834 , 0.15864314, 0.26800459, 0.34246888],\n       [0.23865802, 0.18470638, 0.26423713, 0.31239847],\n       [0.24558384, 0.21727149, 0.25783109, 0.27931358],\n       [0.22112889, 0.1337227 , 0.27004314, 0.37510528],\n       [0.24537138, 0.21604174, 0.25810086, 0.28048602],\n       [0.23062017, 0.15787751, 0.26809254, 0.34340978],\n       [0.22094101, 0.13330101, 0.27006128, 0.3756967 ],\n       [0.24533046, 0.2158073 , 0.25815207, 0.28071017],\n       [0.22129379, 0.13409435, 0.27002664, 0.37458522],\n       [0.24550646, 0.21682122, 0.25793009, 0.27974223],\n       [0.22120844, 0.13390182, 0.27003525, 0.37485449],\n       [0.22134376, 0.13420725, 0.27002154, 0.37442745],\n       [0.24537916, 0.21608643, 0.25809109, 0.28044332],\n       [0.23090687, 0.1587117 , 0.26799664, 0.34238479],\n       [0.22127537, 0.13405277, 0.27002851, 0.37464335],\n       [0.23906004, 0.18628378, 0.26396595, 0.31069023],\n       [0.22142146, 0.1343831 , 0.2700135 , 0.37418194],\n       [0.23086485, 0.158589  , 0.26801085, 0.3425353 ]])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_softmax_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Backprop Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Loss Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    labels = y_true * np.log(y_pred) * -1.0\n",
    "    return np.sum(labels) / y_true.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "1.308813541231649"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function_test = loss_function(toy_labels_1, test_softmax_out)\n",
    "loss_function_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Softmax Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[-0.75464888,  0.21592557,  0.25812624,  0.28059707],\n       [ 0.23898244, -0.81402292,  0.26401903,  0.31102145],\n       [ 0.22134109,  0.13420122,  0.27002181, -0.62556412],\n       [ 0.23077141,  0.15831664, -0.73195773,  0.34286968],\n       [ 0.22119792,  0.1338781 ,  0.2700363 , -0.62511232],\n       [ 0.23907009, -0.8136764 ,  0.26395905,  0.31064726],\n       [-0.7544853 ,  0.21686905,  0.25791959,  0.27969666],\n       [ 0.23048288,  0.15748063, -0.73186243,  0.34389893],\n       [-0.75454266,  0.21653681,  0.25799249,  0.28001336],\n       [ 0.23083099,  0.15849022, -0.73197773,  0.34265652],\n       [ 0.23081784,  0.15845186, -0.7319733 ,  0.34270361],\n       [ 0.23074956,  0.15825309, -0.73195042,  0.34294777],\n       [ 0.23053798,  0.15763971, -0.73188043,  0.34370274],\n       [ 0.23925137, -0.81295532,  0.26383356,  0.30987039],\n       [-0.75443704,  0.21714972,  0.25785789,  0.27942943],\n       [ 0.2390477 , -0.81376506,  0.26397442,  0.31074295],\n       [-0.75451417,  0.21670161,  0.25795635,  0.27985621],\n       [ 0.23073435,  0.15820885, -0.73194535,  0.34300214],\n       [ 0.22146298,  0.13447718,  0.27000916, -0.62594932],\n       [-0.7544994 ,  0.21678725,  0.25793755,  0.27977459],\n       [-0.75469645,  0.21565347,  0.25818563,  0.28085735],\n       [ 0.2213127 ,  0.13413708,  0.27002472, -0.6254745 ],\n       [-0.75465116,  0.21591248,  0.2581291 ,  0.28060958],\n       [-0.7545272 ,  0.2166262 ,  0.25797289,  0.27992811],\n       [ 0.22144385,  0.13443383,  0.27001117, -0.62588885],\n       [-0.75458336,  0.21630202,  0.25804393,  0.28023741],\n       [ 0.22113369,  0.13373351,  0.27004266, -0.62490987],\n       [-0.75452904,  0.21661556,  0.25797523,  0.27993826],\n       [ 0.23900716, -0.81392535,  0.26400216,  0.31091603],\n       [ 0.23087879,  0.15862967, -0.73199385,  0.3424854 ],\n       [ 0.23086682,  0.15859475, -0.73198981,  0.34252824],\n       [ 0.23066307,  0.15800185, -0.73192164,  0.34325673],\n       [ 0.2308834 ,  0.15864314, -0.73199541,  0.34246888],\n       [ 0.23865802, -0.81529362,  0.26423713,  0.31239847],\n       [-0.75441616,  0.21727149,  0.25783109,  0.27931358],\n       [ 0.22112889,  0.1337227 ,  0.27004314, -0.62489472],\n       [-0.75462862,  0.21604174,  0.25810086,  0.28048602],\n       [ 0.23062017,  0.15787751, -0.73190746,  0.34340978],\n       [ 0.22094101,  0.13330101,  0.27006128, -0.6243033 ],\n       [-0.75466954,  0.2158073 ,  0.25815207,  0.28071017],\n       [ 0.22129379,  0.13409435,  0.27002664, -0.62541478],\n       [-0.75449354,  0.21682122,  0.25793009,  0.27974223],\n       [ 0.22120844,  0.13390182,  0.27003525, -0.62514551],\n       [ 0.22134376,  0.13420725,  0.27002154, -0.62557255],\n       [-0.75462084,  0.21608643,  0.25809109,  0.28044332],\n       [ 0.23090687,  0.1587117 , -0.73200336,  0.34238479],\n       [ 0.22127537,  0.13405277,  0.27002851, -0.62535665],\n       [ 0.23906004, -0.81371622,  0.26396595,  0.31069023],\n       [ 0.22142146,  0.1343831 ,  0.2700135 , -0.62581806],\n       [ 0.23086485,  0.158589  , -0.73198915,  0.3425353 ]])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_softmax_back = test_softmax.backward(toy_labels_1)\n",
    "print(test_softmax_back.shape)\n",
    "test_softmax_back"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fully Connected Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[ 1.48398111e-01, -4.00215037e-01, -2.18462332e-01,\n         4.68962041e-02, -4.49048247e-02,  2.02109211e-01,\n         3.37565231e-03,  1.12917608e-01, -1.68423022e-01,\n         5.72480166e-02, -4.08124047e-02,  5.47060433e-01,\n        -3.25673935e-01,  3.29883463e-02,  4.18397047e-01,\n        -3.46327567e-01],\n       [ 4.04812354e-01,  7.15113212e-01,  7.50546247e-02,\n        -7.41437308e-02, -5.36685405e-01, -2.66817536e-01,\n        -4.03044846e-01,  3.74228888e-01,  5.81652425e-01,\n        -1.54708783e-01,  1.98329516e-02, -3.99784709e-01,\n         8.33220567e-01,  9.10672596e-02, -8.88087519e-01,\n        -2.03013967e-01],\n       [-5.54869592e-01,  2.69185792e-01,  1.93421191e-01,\n        -4.78794955e-02,  1.20880216e-03, -2.89522795e-01,\n         2.24074043e-01,  8.30975898e-02, -2.20382552e-01,\n        -4.72494402e-02, -1.62007463e-01, -7.83851735e-02,\n         2.38559206e-01,  2.58231151e-01,  4.98057447e-02,\n        -9.94024537e-03],\n       [ 3.10334217e-01, -4.40869335e-01, -9.92845363e-02,\n         6.60546632e-02,  3.77709799e-01,  3.55694569e-01,\n        -2.89366701e-02, -4.40119697e-01,  5.55150462e-02,\n         1.07242714e-01,  2.26503459e-01, -1.26816227e-01,\n        -5.42428697e-01, -4.10700625e-01,  1.34096555e-01,\n         4.43967511e-01],\n       [-5.54438753e-01,  2.69254118e-01,  1.93321757e-01,\n        -4.78763828e-02,  1.00469844e-03, -2.89451463e-01,\n         2.23823283e-01,  8.32146771e-02, -2.20096186e-01,\n        -4.72742869e-02, -1.61931801e-01, -7.84022558e-02,\n         2.38697490e-01,  2.58149925e-01,  4.95290364e-02,\n        -1.00682725e-02],\n       [ 4.04442498e-01,  7.14966598e-01,  7.51196715e-02,\n        -7.41358453e-02, -5.36457025e-01, -2.66832349e-01,\n        -4.02806320e-01,  3.74084616e-01,  5.81366446e-01,\n        -1.54669053e-01,  1.97782272e-02, -3.99728173e-01,\n         8.33004036e-01,  9.11087733e-02, -8.87768554e-01,\n        -2.02881158e-01],\n       [ 1.47489617e-01, -4.00692660e-01, -2.18330434e-01,\n         4.69296317e-02, -4.42748264e-02,  2.02134434e-01,\n         3.99242833e-03,  1.12507229e-01, -1.69179747e-01,\n         5.73699876e-02, -4.09341707e-02,  5.47258275e-01,\n        -3.26335622e-01,  3.30543348e-02,  4.19290346e-01,\n        -3.45974317e-01],\n       [ 3.11332049e-01, -4.40599579e-01, -9.94893408e-02,\n         6.60484723e-02,  3.77168982e-01,  3.55800782e-01,\n        -2.95469912e-02, -4.39792178e-01,  5.62289471e-02,\n         1.07161771e-01,  2.26665371e-01, -1.26907798e-01,\n        -5.41984116e-01, -4.10852374e-01,  1.33352840e-01,\n         4.43640697e-01],\n       [ 1.47809220e-01, -4.00524225e-01, -2.18376736e-01,\n         4.69178230e-02, -4.44966949e-02,  2.02125346e-01,\n         3.77534258e-03,  1.12651791e-01, -1.68913346e-01,\n         5.73269940e-02, -4.08913772e-02,  5.47188466e-01,\n        -3.26102392e-01,  3.30312442e-02,  4.18975704e-01,\n        -3.46098679e-01],\n       [ 3.10127493e-01, -4.40925698e-01, -9.92422166e-02,\n         6.60560031e-02,  3.77822130e-01,  3.55672816e-01,\n        -2.88101021e-02, -4.40187788e-01,  5.53669279e-02,\n         1.07259583e-01,  2.26469970e-01, -1.26797029e-01,\n        -5.42521333e-01, -4.10669340e-01,  1.34251075e-01,\n         4.44035343e-01],\n       [ 3.10173163e-01, -4.40913232e-01, -9.92515628e-02,\n         6.60557054e-02,  3.77797305e-01,  3.55677615e-01,\n        -2.88380678e-02, -4.40172738e-01,  5.53996573e-02,\n         1.07255853e-01,  2.26477367e-01, -1.26801277e-01,\n        -5.42500852e-01, -4.10676248e-01,  1.34216924e-01,\n         4.44020353e-01],\n       [ 3.10409951e-01, -4.40848727e-01, -9.93000499e-02,\n         6.60541773e-02,  3.77668671e-01,  3.55702560e-01,\n        -2.89830281e-02, -4.40094772e-01,  5.55692915e-02,\n         1.07236542e-01,  2.26515732e-01, -1.26823241e-01,\n        -5.42394805e-01, -4.10712100e-01,  1.34039985e-01,\n         4.43942672e-01],\n       [ 3.11141898e-01, -4.40650691e-01, -9.94502445e-02,\n         6.60496168e-02,  3.77271865e-01,  3.55780386e-01,\n        -2.94307636e-02, -4.39854445e-01,  5.60930373e-02,\n         1.07177134e-01,  2.26634482e-01, -1.26890488e-01,\n        -5.42068510e-01, -4.10823362e-01,  1.33494293e-01,\n         4.43702899e-01],\n       [ 4.03674360e-01,  7.14660313e-01,  7.52543439e-02,\n        -7.41192541e-02, -5.35981652e-01, -2.66862173e-01,\n        -4.02310466e-01,  3.73784118e-01,  5.80771685e-01,\n        -1.54586167e-01,  1.96647698e-02, -3.99609871e-01,\n         8.32552352e-01,  9.11944357e-02, -8.87104442e-01,\n        -2.02604902e-01],\n       [ 1.47219871e-01, -4.00835166e-01, -2.18291437e-01,\n         4.69396397e-02, -4.40873667e-02,  2.02142286e-01,\n         4.17574053e-03,  1.12385055e-01, -1.69404752e-01,\n         5.74063461e-02, -4.09702522e-02,  5.47317371e-01,\n        -3.26532852e-01,  3.30737188e-02,  4.19556230e-01,\n        -3.45869279e-01],\n       [ 4.04537086e-01,  7.15004146e-01,  7.51030487e-02,\n        -7.41378683e-02, -5.36515463e-01, -2.66828588e-01,\n        -4.02867336e-01,  3.74121538e-01,  5.81439608e-01,\n        -1.54679225e-01,  1.97922168e-02, -3.99742658e-01,\n         8.33059472e-01,  9.10981730e-02, -8.87850177e-01,\n        -2.02915136e-01],\n       [ 1.47650640e-01, -4.00607742e-01, -2.18353749e-01,\n         4.69236756e-02, -4.43866412e-02,  2.02129826e-01,\n         3.88304093e-03,  1.12580089e-01, -1.69045502e-01,\n         5.73483149e-02, -4.09126162e-02,  5.47223075e-01,\n        -3.26218054e-01,  3.30427180e-02,  4.19131770e-01,\n        -3.46036986e-01],\n       [ 3.10462670e-01, -4.40834395e-01, -9.93108519e-02,\n         6.60538406e-02,  3.77640049e-01,  3.55708129e-01,\n        -2.90152948e-02, -4.40077428e-01,  5.56070461e-02,\n         1.07232249e-01,  2.26524277e-01, -1.26828117e-01,\n        -5.42371227e-01, -4.10720092e-01,  1.34000617e-01,\n         4.43925384e-01],\n       [-5.55237003e-01,  2.69126995e-01,  1.93505867e-01,\n        -4.78820862e-02,  1.38318389e-03, -2.89583345e-01,\n         2.24288027e-01,  8.29974690e-02, -2.20626999e-01,\n        -4.72281401e-02, -1.62071920e-01, -7.83703642e-02,\n         2.38440689e-01,  2.58300244e-01,  5.00422021e-02,\n        -9.83091699e-03],\n       [ 1.47568271e-01, -4.00651167e-01, -2.18341819e-01,\n         4.69267207e-02, -4.43294521e-02,  2.02132176e-01,\n         3.93899288e-03,  1.12542825e-01, -1.69114167e-01,\n         5.73593983e-02, -4.09236436e-02,  5.47241074e-01,\n        -3.26278179e-01,  3.30486647e-02,  4.19212874e-01,\n        -3.46004932e-01],\n       [ 1.48660622e-01, -4.00077696e-01, -2.18500604e-01,\n         4.68866251e-02, -4.50864748e-02,  2.02102273e-01,\n         3.19760867e-03,  1.13035873e-01, -1.68204674e-01,\n         5.72129113e-02, -4.07771497e-02,  5.47003607e-01,\n        -3.25483476e-01,  3.29690766e-02,  4.18139554e-01,\n        -3.46429492e-01],\n       [-5.54784123e-01,  2.69199399e-01,  1.93401477e-01,\n        -4.78788844e-02,  1.16827970e-03, -2.89508673e-01,\n         2.24024284e-01,  8.31208446e-02, -2.20325720e-01,\n        -4.72543804e-02, -1.61992460e-01, -7.83885865e-02,\n         2.38586698e-01,  2.58215056e-01,  4.97508031e-02,\n        -9.96565814e-03],\n       [ 1.48410727e-01, -4.00208430e-01, -2.18464169e-01,\n         4.68957429e-02, -4.49135586e-02,  2.02108874e-01,\n         3.36709395e-03,  1.12923295e-01, -1.68412525e-01,\n         5.72463280e-02, -4.08107111e-02,  5.47057698e-01,\n        -3.25664774e-01,  3.29874223e-02,  4.18384666e-01,\n        -3.46332467e-01],\n       [ 1.47723196e-01, -4.00569516e-01, -2.18364263e-01,\n         4.69209962e-02, -4.44370026e-02,  2.02127769e-01,\n         3.83376149e-03,  1.12612901e-01, -1.68985030e-01,\n         5.73385570e-02, -4.09029000e-02,  5.47207233e-01,\n        -3.26165120e-01,  3.30374724e-02,  4.19060352e-01,\n        -3.46065216e-01],\n       [-5.55179315e-01,  2.69136259e-01,  1.93492579e-01,\n        -4.78816833e-02,  1.35578425e-03, -2.89573855e-01,\n         2.24254421e-01,  8.30132056e-02, -2.20588604e-01,\n        -4.72314912e-02, -1.62061804e-01, -7.83727042e-02,\n         2.38459334e-01,  2.58289407e-01,  5.00050462e-02,\n        -9.84809179e-03],\n       [ 1.48035289e-01, -4.00405352e-01, -2.18409553e-01,\n         4.69095024e-02, -4.46534759e-02,  2.02119059e-01,\n         3.62185859e-03,  1.12753919e-01, -1.68725032e-01,\n         5.72966383e-02, -4.08610792e-02,  5.47139224e-01,\n        -3.25937714e-01,  3.30148300e-02,  4.18753396e-01,\n        -3.46186586e-01],\n       [-5.54245730e-01,  2.69284512e-01,  1.93277160e-01,\n        -4.78749622e-02,  9.13390573e-04, -2.89419390e-01,\n         2.23710997e-01,  8.32670227e-02, -2.19967988e-01,\n        -4.72853730e-02, -1.61897877e-01, -7.84098098e-02,\n         2.38759201e-01,  2.58113463e-01,  4.94052660e-02,\n        -1.01255693e-02],\n       [ 1.47733439e-01, -4.00564122e-01, -2.18365748e-01,\n         4.69206182e-02, -4.44441111e-02,  2.02127480e-01,\n         3.82680522e-03,  1.12617533e-01, -1.68976494e-01,\n         5.73371798e-02, -4.09015282e-02,  5.47204998e-01,\n        -3.26157649e-01,  3.30367314e-02,  4.19050271e-01,\n        -3.46069201e-01],\n       [ 4.04708159e-01,  7.15071965e-01,  7.50729628e-02,\n        -7.41415161e-02, -5.36621100e-01, -2.66821739e-01,\n        -4.02977664e-01,  3.74188271e-01,  5.81571886e-01,\n        -1.54697603e-01,  1.98175286e-02, -3.99768810e-01,\n         8.33159630e-01,  9.10789723e-02, -8.87997714e-01,\n        -2.02976566e-01],\n       [ 3.09961520e-01, -4.40971069e-01, -9.92082665e-02,\n         6.60570930e-02,  3.77912390e-01,  3.55655414e-01,\n        -2.87084523e-02, -4.40242515e-01,  5.52479529e-02,\n         1.07273151e-01,  2.26443097e-01, -1.26781559e-01,\n        -5.42595840e-01, -4.10644261e-01,  1.34375244e-01,\n         4.44089834e-01],\n       [ 3.10003076e-01, -4.40959700e-01, -9.92167645e-02,\n         6.60568189e-02,  3.77889785e-01,  3.55659766e-01,\n        -2.87339057e-02, -4.40228808e-01,  5.52777461e-02,\n         1.07269752e-01,  2.26449825e-01, -1.26785437e-01,\n        -5.42577174e-01, -4.10650537e-01,  1.34344146e-01,\n         4.44076188e-01],\n       [ 3.10709520e-01, -4.40767427e-01, -9.93614638e-02,\n         6.60522810e-02,  3.77506117e-01,  3.55734281e-01,\n        -2.91663417e-02, -4.39996288e-01,  5.57837619e-02,\n         1.07212176e-01,  2.26564305e-01, -1.26850881e-01,\n        -5.42260984e-01, -4.10757557e-01,  1.33816416e-01,\n         4.43844474e-01],\n       [ 3.09945499e-01, -4.40975454e-01, -9.92049908e-02,\n         6.60571989e-02,  3.77921106e-01,  3.55653738e-01,\n        -2.86986392e-02, -4.40247801e-01,  5.52364665e-02,\n         1.07274462e-01,  2.26440504e-01, -1.26780063e-01,\n        -5.42603038e-01, -4.10641842e-01,  1.34387235e-01,\n         4.44095095e-01],\n       [ 4.06172641e-01,  7.15647637e-01,  7.48142601e-02,\n        -7.41721572e-02, -5.37522510e-01, -2.66760532e-01,\n        -4.03920850e-01,  3.74757182e-01,  5.82702014e-01,\n        -1.54853907e-01,  2.00347533e-02, -3.99990276e-01,\n         8.34011624e-01,  9.09130816e-02, -8.89256162e-01,\n        -2.03501271e-01],\n       [ 1.47102921e-01, -4.00897050e-01, -2.18274553e-01,\n         4.69439906e-02, -4.40060347e-02,  2.02145742e-01,\n         4.25524279e-03,  1.12332040e-01, -1.69502351e-01,\n         5.74221300e-02, -4.09858852e-02,  5.47343042e-01,\n        -3.26618471e-01,  3.30820931e-02,  4.19671598e-01,\n        -3.45823718e-01],\n       [-5.54231286e-01,  2.69286782e-01,  1.93273821e-01,\n        -4.78748553e-02,  9.06560999e-04, -2.89416987e-01,\n         2.23702595e-01,  8.32709372e-02, -2.19958397e-01,\n        -4.72862015e-02, -1.61895338e-01, -7.84103727e-02,\n         2.38763813e-01,  2.58110732e-01,  4.93960088e-02,\n        -1.01298555e-02],\n       [ 1.48286097e-01, -4.00273732e-01, -2.18446023e-01,\n         4.69003023e-02, -4.48272615e-02,  2.02112219e-01,\n         3.45164740e-03,  1.12867101e-01, -1.68516233e-01,\n         5.72630149e-02, -4.08274384e-02,  5.47084727e-01,\n        -3.25755304e-01,  3.29965411e-02,  4.18507005e-01,\n        -3.46284056e-01],\n       [ 3.10857902e-01, -4.40727285e-01, -9.93919126e-02,\n         6.60513570e-02,  3.77425679e-01,  3.55750061e-01,\n        -2.92571062e-02, -4.39947571e-01,  5.58899346e-02,\n         1.07200134e-01,  2.26588378e-01, -1.26864512e-01,\n        -5.42194842e-01, -4.10780114e-01,  1.33705796e-01,\n         4.43795868e-01],\n       [-5.53667516e-01,  2.69374758e-01,  1.93143384e-01,\n        -4.78706101e-02,  6.40366071e-04, -2.89322888e-01,\n         2.23374846e-01,  8.34234165e-02, -2.19584323e-01,\n        -4.73184133e-02, -1.61796156e-01, -7.84320719e-02,\n         2.38943164e-01,  2.58003970e-01,  4.90352399e-02,\n        -1.02969793e-02],\n       [ 1.48512185e-01, -4.00155319e-01, -2.18478954e-01,\n         4.68920371e-02, -4.49837825e-02,  2.02106177e-01,\n         3.29827353e-03,  1.12969018e-01, -1.68328121e-01,\n         5.72327539e-02, -4.07970885e-02,  5.47035720e-01,\n        -3.25591130e-01,  3.29799837e-02,  4.18285119e-01,\n        -3.46371867e-01],\n       [-5.54727171e-01,  2.69208452e-01,  1.93388338e-01,\n        -4.78784754e-02,  1.14128650e-03, -2.89499254e-01,\n         2.23991131e-01,  8.31363330e-02, -2.20287856e-01,\n        -4.72576693e-02, -1.61982460e-01, -7.83908542e-02,\n         2.38605001e-01,  2.58204325e-01,  4.97142060e-02,\n        -9.98258786e-03],\n       [ 1.47535606e-01, -4.00668395e-01, -2.18337090e-01,\n         4.69279292e-02, -4.43067680e-02,  2.02133112e-01,\n         3.96118369e-03,  1.12528043e-01, -1.69141401e-01,\n         5.73637953e-02, -4.09280159e-02,  5.47248216e-01,\n        -3.26302031e-01,  3.30510205e-02,  4.19245045e-01,\n        -3.45992218e-01],\n       [-5.54470400e-01,  2.69249122e-01,  1.93329066e-01,\n        -4.78766142e-02,  1.01967653e-03, -2.89456715e-01,\n         2.23841697e-01,  8.32060883e-02, -2.20117211e-01,\n        -4.72724666e-02, -1.61937361e-01, -7.84010114e-02,\n         2.38687358e-01,  2.58155899e-01,  4.95493407e-02,\n        -1.00588749e-02],\n       [-5.54877633e-01,  2.69184510e-01,  1.93423045e-01,\n        -4.78795528e-02,  1.21261570e-03, -2.89524123e-01,\n         2.24078726e-01,  8.30954011e-02, -2.20387900e-01,\n        -4.72489751e-02, -1.62008874e-01, -7.83848517e-02,\n         2.38556618e-01,  2.58232665e-01,  4.98109154e-02,\n        -9.93785393e-03],\n       [ 1.48243023e-01, -4.00296317e-01, -2.18439755e-01,\n         4.69018800e-02, -4.47974269e-02,  2.02113384e-01,\n         3.48087444e-03,  1.12847672e-01, -1.68552083e-01,\n         5.72687853e-02, -4.08332179e-02,  5.47094076e-01,\n        -3.25786610e-01,  3.29996879e-02,  4.18549302e-01,\n        -3.46267321e-01],\n       [ 3.09863934e-01, -4.40997795e-01, -9.91883166e-02,\n         6.60577398e-02,  3.77965489e-01,  3.55645209e-01,\n        -2.86486734e-02, -4.40274717e-01,  5.51779781e-02,\n         1.07281139e-01,  2.26427303e-01, -1.26772440e-01,\n        -5.42639702e-01, -4.10629531e-01,  1.34448296e-01,\n         4.44121885e-01],\n       [-5.54671741e-01,  2.69217252e-01,  1.93375547e-01,\n        -4.78780761e-02,  1.11502198e-03, -2.89490082e-01,\n         2.23958867e-01,  8.31514015e-02, -2.20251009e-01,\n        -4.72608678e-02, -1.61972727e-01, -7.83930560e-02,\n         2.38622802e-01,  2.58193878e-01,  4.96785978e-02,\n        -9.99906173e-03],\n       [ 4.04484977e-01,  7.14983465e-01,  7.51122074e-02,\n        -7.41367543e-02, -5.36483272e-01, -2.66830662e-01,\n        -4.02833723e-01,  3.74101199e-01,  5.81399304e-01,\n        -1.54673622e-01,  1.97845093e-02, -3.99734680e-01,\n         8.33028937e-01,  9.11040142e-02, -8.87805214e-01,\n        -2.02896418e-01],\n       [-5.55111800e-01,  2.69147086e-01,  1.93477024e-01,\n        -4.78812100e-02,  1.32372632e-03, -2.89562741e-01,\n         2.24215094e-01,  8.30316151e-02, -2.20543674e-01,\n        -4.72354100e-02, -1.62049962e-01, -7.83754358e-02,\n         2.38481137e-01,  2.58276718e-01,  4.99615746e-02,\n        -9.86818813e-03],\n       [ 3.10009920e-01, -4.40957827e-01, -9.92181644e-02,\n         6.60567739e-02,  3.77886062e-01,  3.55660483e-01,\n        -2.87380980e-02, -4.40226550e-01,  5.52826530e-02,\n         1.07269192e-01,  2.26450933e-01, -1.26786076e-01,\n        -5.42574100e-01, -4.10651571e-01,  1.34339024e-01,\n         4.44073941e-01]])"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fc_back = test_fc.backward(test_softmax_back, learning_rate=0.01)\n",
    "print(test_fc_back.shape)\n",
    "test_fc_back"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Flattening Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.14839811, -0.40021504],\n       [-0.21846233,  0.0468962 ]])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_flattening_back = test_flattening.backward(test_fc_back)\n",
    "test_flattening_back[0, 0, :, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### MaxPooling Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 4, 2, 2)"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_maxpool_back = test_maxpool.backward(test_flattening_back)\n",
    "test_flattening_back.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.        ,  0.        ,  0.        ],\n       [ 0.        , -0.42338305,  0.        ],\n       [ 0.        ,  0.        ,  0.        ]])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_maxpool_back[0, 0, :, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Activation Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 4, 3, 3)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_activation_back = test_activation.backward(test_maxpool_back)\n",
    "test_activation_back.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.        ,  0.        ,  0.        ],\n       [ 0.        , -0.42338305,  0.        ],\n       [ 0.        ,  0.        ,  0.        ]])"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_activation_back[0, 0, :, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Convolution Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 1, 2, 2)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_conv_back = test_conv.backward(test_activation_back, learning_rate=0.01)\n",
    "test_conv_back.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.74448892, -1.39867239],\n       [ 2.44351392,  0.00654209]])"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_conv_back[0, 0, :, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Predictiona and Accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def measure_accuracy(y_true, y_pred):\n",
    "    accurate = np.sum(np.all(y_true == y_pred, axis=1))\n",
    "    total = y_true.shape[0]\n",
    "    return accurate / total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def predict_labels(a):\n",
    "    return (a == a.max(axis=1)[:,None]).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7ff7d1d626d0>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = process_mnist_data()\n",
    "img = x_train[0].reshape(28, 28, 1)\n",
    "plt.imshow(img, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mnist Dataset Train-test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "model = parse_input_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# train\n",
    "random_index = random.sample(range(0, 60000), 1280)\n",
    "mnist_subsample_x = x_train[random_index]\n",
    "mnist_subsample_y = y_train[random_index]\n",
    "# validation\n",
    "mnist_validation_x = x_test[:200]\n",
    "mnist_validation_y = y_test[:200]\n",
    "# test\n",
    "mnist_test_x = x_test[5001:7001]\n",
    "mnist_test_y = y_test[5001:7001]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "LabelBinarizer()"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_binarizer = LabelBinarizer()\n",
    "label_binarizer.fit(range(0,10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "validation_batch = mnist_validation_x.reshape(200, 1, 28, 28) / 255.0\n",
    "validation_labels = label_binarizer.transform(mnist_validation_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_labels[0:100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "test_batch = mnist_test_x.reshape(2000, 1, 28, 28)\n",
    "test_labels = label_binarizer.transform(mnist_test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# inp = mnist_batch_1\n",
    "# for layer in model:\n",
    "#     inp = layer.forward(inp)\n",
    "#\n",
    "# labels_true = label_binarizer.transform(mnist_labels_1)\n",
    "# l = loss_function(labels_true, inp)\n",
    "#\n",
    "# out = labels_true\n",
    "# for layer in reversed(model):\n",
    "#     out = layer.backward(out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation_losses = []\n",
    "validation_accuracy = []\n",
    "validation_index = [i for i in range(1,101)]\n",
    "for i in range(100):\n",
    "    # losses = []\n",
    "    # index = [i for i in range(1,157)]\n",
    "    for j in range(0, 1280, 32):\n",
    "        batch_x = mnist_subsample_x[j:j+32].reshape(32, 1, 28, 28).astype(np.float64)\n",
    "        batch_x /= 255.0\n",
    "        batch_y = mnist_subsample_y[j:j+32]\n",
    "        model_out = batch_x\n",
    "        # train\n",
    "        for layer in model:\n",
    "            # print(layer)\n",
    "            model_out = layer.forward(model_out)\n",
    "            # print(model_out.shape)\n",
    "\n",
    "        true_labels = label_binarizer.transform(batch_y)\n",
    "        l = loss_function(true_labels, model_out)\n",
    "        # losses.append(l)\n",
    "        # print(\"Epoc {} batch {} loss = {}\".format(i, j//32, l))\n",
    "\n",
    "\n",
    "        model_back = true_labels\n",
    "        for layer in reversed(model):\n",
    "            # print(layer)\n",
    "            model_back = layer.backward(model_back)\n",
    "            # print(model_back.shape)\n",
    "\n",
    "    # plt.plot(index, losses)\n",
    "    # plt.show()\n",
    "\n",
    "    #validation\n",
    "    validation_out = validation_batch\n",
    "    for layer in model:\n",
    "        validation_out = layer.forward(validation_out)\n",
    "    validation_loss = loss_function(validation_labels, validation_out)\n",
    "    validation_losses.append(validation_loss)\n",
    "    # print('Validation loss after epoc {} is {}'.format(i, validation_loss))\n",
    "    validation_predictions = predict_labels(validation_out)\n",
    "    accuracy = measure_accuracy(validation_labels, validation_predictions)\n",
    "    validation_accuracy.append(accuracy * 100)\n",
    "    # print('Validation accuracy after epoc {} is {}'.format(i, accuracy))\n",
    "\n",
    "plt.plot(validation_index, validation_losses)\n",
    "plt.show()\n",
    "plt.plot(validation_index, validation_accuracy)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Toy Dataset Train-test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# label_binarizer_toy = LabelBinarizer()\n",
    "# label_binarizer_toy.fit(range(1,5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# toy_model = [FullyConnectedLayerBatch(4), SoftmaxLayerBatch()]\n",
    "# x_train, y_train, x_test, y_test = process_toy_dataset()\n",
    "# x_validation, y_validation = x_test[:250], y_test[:250]\n",
    "# x_test, y_test = x_test[250:], y_test[250:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# y_validation = label_binarizer_toy.transform(y_validation)\n",
    "# y_test = label_binarizer_toy.transform(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# validation_losses = []\n",
    "# validation_accuracy = []\n",
    "# validation_index = [i for i in range(1,12001)]\n",
    "# for i in range(12000):\n",
    "#     losses = []\n",
    "#     index = [i for i in range(1,21)]\n",
    "#     for j in range(0, 500, 25):\n",
    "#         batch_x = x_train[j:j+25]\n",
    "#         batch_y = y_train[j:j+25]\n",
    "#         model_out = batch_x\n",
    "#         # train\n",
    "#         for layer in toy_model:\n",
    "#             model_out = layer.forward(model_out)\n",
    "#\n",
    "#         true_labels = label_binarizer_toy.transform(batch_y)\n",
    "#         l = loss_function(true_labels, model_out)\n",
    "#         losses.append(l)\n",
    "#\n",
    "#         model_back_toy = true_labels\n",
    "#         for layer in reversed(toy_model):\n",
    "#             model_back_toy = layer.backward(model_back_toy)\n",
    "#\n",
    "#     #validation\n",
    "#     validation_out = x_validation\n",
    "#     for layer in toy_model:\n",
    "#         validation_out = layer.forward(validation_out)\n",
    "#     validation_loss = loss_function(y_validation, validation_out)\n",
    "#     validation_losses.append(validation_loss)\n",
    "#     validation_predictions = predict_labels(validation_out)\n",
    "#     accuracy = measure_accuracy(y_validation, validation_predictions)\n",
    "#     validation_accuracy.append(accuracy*100)\n",
    "#\n",
    "# # print(validation_losses)\n",
    "# plt.plot(validation_index, validation_losses)\n",
    "# plt.show()\n",
    "# plt.plot(validation_index, validation_accuracy)\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# test_out = x_test\n",
    "# for layer in toy_model:\n",
    "#     test_out = layer.forward(test_out)\n",
    "# test_prediction = predict_labels(test_out)\n",
    "# accuracy = measure_accuracy(y_test, test_prediction)\n",
    "# accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}