{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importing Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pickle\n",
    "from mlxtend.data import loadlocal_mnist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting Numpy Seed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Processing MNIST Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def process_mnist_data() -> (np.ndarray, np.ndarray, np.ndarray, np.ndarray):\n",
    "    mnist_path = './MNIST/'\n",
    "    train_images, train_labels = loadlocal_mnist(\n",
    "        images_path = mnist_path + './train-images.idx3-ubyte',\n",
    "        labels_path = mnist_path + './train-labels.idx1-ubyte'\n",
    "    )\n",
    "    test_images, test_labels = loadlocal_mnist(\n",
    "        images_path = mnist_path + './t10k-images.idx3-ubyte',\n",
    "        labels_path = mnist_path + './t10k-labels.idx1-ubyte'\n",
    "    )\n",
    "    return train_images, train_labels, test_images, test_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Processing CIFAR-10 Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        data_dict = pickle.load(fo, encoding='bytes')\n",
    "    return data_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def process_cifar_dataset() -> (np.ndarray, np.ndarray, np.ndarray, np.ndarray):\n",
    "    cifar_path = './cifar-10-python/cifar-10-batches-py'\n",
    "    data_batch = unpickle(cifar_path + '/data_batch_1')\n",
    "    train_images, train_labels = data_batch[b'data'], np.array(data_batch[b'labels'])\n",
    "    for i in range(2,6):\n",
    "        data_batch = unpickle(cifar_path + '/data_batch_' + str(i))\n",
    "        train_images = np.concatenate((train_images, data_batch[b'data']), axis=0)\n",
    "        train_labels = np.concatenate((train_labels, np.array(data_batch[b'labels'])), axis=0)\n",
    "    test_batch = unpickle(cifar_path + '/test_batch')\n",
    "    test_images, test_labels = test_batch[b'data'], np.array(test_batch[b'labels'])\n",
    "    return train_images, train_labels, test_images, test_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Processing Toy Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def process_toy_dataset():\n",
    "    toy_dataset_path = './Toy Dataset/'\n",
    "    a = np.loadtxt(toy_dataset_path + 'trainNN.txt')\n",
    "    b = np.loadtxt(toy_dataset_path + 'testNN.txt')\n",
    "    train_x, train_y, test_x, test_y = a[:, 0:4], a[:, -1], b[:, 0:4], b[:, -1]\n",
    "    return train_x, train_y, test_x, test_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 9.21323266, 11.82445528],\n       [16.69098092, 19.56967227]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_toy, y_train_toy, x_test_toy, y_test_toy = process_toy_dataset()\n",
    "toy_batch_1 = x_train_toy[0:50].reshape(50, 1, 2, 2)\n",
    "toy_batch_1[0, 0, :, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 0, 0, 0],\n       [0, 1, 0, 0],\n       [0, 0, 0, 1],\n       [0, 0, 1, 0],\n       [0, 0, 0, 1],\n       [0, 1, 0, 0],\n       [1, 0, 0, 0],\n       [0, 0, 1, 0],\n       [1, 0, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 1, 0, 0],\n       [1, 0, 0, 0],\n       [0, 1, 0, 0],\n       [1, 0, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [1, 0, 0, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [1, 0, 0, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [0, 1, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 1, 0, 0],\n       [1, 0, 0, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [0, 0, 0, 1],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 0, 1],\n       [0, 1, 0, 0],\n       [0, 0, 0, 1],\n       [0, 0, 1, 0]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_binarizer = LabelBinarizer()\n",
    "label_binarizer.fit(range(1,5))\n",
    "toy_labels_1 = label_binarizer.transform(y_train_toy[0:50].T)\n",
    "toy_labels_1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parsing Input Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def parse_input_model():\n",
    "    path = './input_model.txt'\n",
    "    model = []\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            tokens = line.split()\n",
    "            if tokens[0] == 'Conv':\n",
    "                model.append(ConvolutionLayer(int(tokens[1]), int(tokens[2]), int(tokens[3]), int(tokens[4])))\n",
    "            if tokens[0] == 'ReLU':\n",
    "                model.append(ActivationLayer())\n",
    "            if tokens[0] == 'Pool':\n",
    "                model.append(MaxPoolingLayer(int(tokens[1]), int(tokens[2])))\n",
    "            if tokens[0] == 'FC':\n",
    "                model.append(FlatteningLayer())\n",
    "                model.append(FullyConnectedLayer(int(tokens[1])))\n",
    "            if tokens[0] == 'Softmax':\n",
    "                model.append(SoftmaxLayer())\n",
    "        return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ReLU Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def relu(matrix:np.ndarray) -> np.ndarray:\n",
    "    return matrix * (matrix > 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convolution Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class ConvolutionLayer:\n",
    "    def __init__(self, output_channel_count: int, filter_dimension: int, stride: int, padding: int):\n",
    "        self.output_channel_count = output_channel_count\n",
    "        self.filter_dimension = filter_dimension\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self, input_image: np.ndarray) -> np.ndarray:\n",
    "        input_dimentions = input_image.shape[0]\n",
    "        output_dimentions = (input_dimentions - self.filter_dimension + 2 * self.padding) // self.stride + 1\n",
    "        input_shape = input_image.shape\n",
    "\n",
    "        filters = np.random.rand(\n",
    "            self.output_channel_count,\n",
    "            self.filter_dimension,\n",
    "            self.filter_dimension,\n",
    "            input_shape[2]\n",
    "        )\n",
    "\n",
    "        bias = np.random.rand(self.output_channel_count)\n",
    "\n",
    "        padded_image = np.pad(input_image, [(self.padding,self.padding), (self.padding,self.padding), (0,0)], mode='constant') * 1.0\n",
    "        padded_image /= 255.0\n",
    "        padded_dimensions = padded_image.shape\n",
    "\n",
    "        output = np.zeros((output_dimentions, output_dimentions, self.output_channel_count))\n",
    "\n",
    "        image_y = out_y = 0\n",
    "        while image_y + self.filter_dimension <= padded_dimensions[1]:\n",
    "            image_x = out_x = 0\n",
    "            while image_x + self.filter_dimension <= padded_dimensions[0]:\n",
    "                image_slice = padded_image[image_x:image_x+self.filter_dimension, image_y:image_y+self.filter_dimension, :]\n",
    "                output[out_x, out_y, :] = np.sum(image_slice * filters) + bias\n",
    "                image_x += self.stride\n",
    "                out_x += 1\n",
    "            image_y += self.stride\n",
    "            out_y += 1\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class ConvolutionLayerBatch:\n",
    "    def __init__(self, output_channel_count: int, filter_dimension: int, stride: int, padding: int):\n",
    "        self.output_channel_count = output_channel_count\n",
    "        self.filter_dimension = filter_dimension\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self, input_batch: np.ndarray) -> np.ndarray:\n",
    "        input_dimentions = input_batch.shape\n",
    "        output_dimentions = (input_dimentions[2] - self.filter_dimension + 2 * self.padding) // self.stride + 1\n",
    "        input_shape = input_batch.shape\n",
    "\n",
    "        filters = np.random.rand(\n",
    "            self.output_channel_count,\n",
    "            input_shape[1],\n",
    "            self.filter_dimension,\n",
    "            self.filter_dimension\n",
    "        )\n",
    "\n",
    "        bias = np.random.rand(self.output_channel_count)\n",
    "\n",
    "        padded_image = np.pad(input_batch, [(0, 0), (0, 0), (self.padding,self.padding), (self.padding,self.padding)], mode='constant') * 1.0\n",
    "        padded_image /= 255.0\n",
    "        padded_dimensions = padded_image.shape\n",
    "\n",
    "        output = np.zeros((input_dimentions[0], self.output_channel_count, output_dimentions, output_dimentions))\n",
    "\n",
    "        for i in range(input_dimentions[0]):\n",
    "            image_y = out_y = 0\n",
    "            while image_y + self.filter_dimension <= padded_dimensions[3]:\n",
    "                image_x = out_x = 0\n",
    "                while image_x + self.filter_dimension <= padded_dimensions[2]:\n",
    "                    image_slice = padded_image[i, :, image_x:image_x+self.filter_dimension, image_y:image_y+self.filter_dimension]\n",
    "                    output[i, :, out_x, out_y] = np.sum(image_slice * filters) + bias\n",
    "                    image_x += self.stride\n",
    "                    out_x += 1\n",
    "                image_y += self.stride\n",
    "                out_y += 1\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 3, 3, 3)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_conv = ConvolutionLayerBatch(3, 2, 2, 2)\n",
    "test_conv_out = test_conv.forward(toy_batch_1)\n",
    "test_conv_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.00394827, 0.00394827, 0.00394827],\n       [0.00394827, 0.35971887, 0.00394827],\n       [0.00394827, 0.00394827, 0.00394827]])"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_conv_out[0, 0, :, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Activation Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class ActivationLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, input_matrix: np.ndarray) -> np.ndarray:\n",
    "        return relu(input_matrix)\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 3, 3, 3)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_activation = ActivationLayer()\n",
    "test_activation_out = test_activation.forward(test_conv_out)\n",
    "test_activation_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.00394827, 0.00394827, 0.00394827],\n       [0.51219226, 0.51219226, 0.51219226],\n       [0.81262096, 0.81262096, 0.81262096]])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_activation_out[0, :, :, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Max Pooling Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class MaxPoolingLayer:\n",
    "    def __init__(self, filter_dimension: int, stride: int):\n",
    "        self.filter_dimension = filter_dimension\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, image: np.ndarray) -> np.ndarray:\n",
    "        input_dimensions = image.shape\n",
    "        output_dimension = (input_dimensions[0] - self.filter_dimension) // self.stride + 1\n",
    "\n",
    "        output = np.zeros((output_dimension, output_dimension, input_dimensions[2]))\n",
    "\n",
    "        image_y = out_y = 0\n",
    "        while image_y + self.filter_dimension <= input_dimensions[1]:\n",
    "            image_x = out_x = 0\n",
    "            while image_x + self.filter_dimension <= input_dimensions[0]:\n",
    "                image_slice = image[image_x: image_x+self.filter_dimension, image_y: image_y+self.filter_dimension, :]\n",
    "                output[out_x, out_y, :] = np.max(image_slice, axis=(0, 1))\n",
    "                image_x += self.stride\n",
    "                out_x += 1\n",
    "            image_y += self.stride\n",
    "            out_y += 1\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class MaxPoolingLayerBatch:\n",
    "    def __init__(self, filter_dimension: int, stride: int):\n",
    "        self.filter_dimension = filter_dimension\n",
    "        self.stride = stride\n",
    "        self.index_tracker = None\n",
    "\n",
    "    def forward(self, image: np.ndarray) -> np.ndarray:\n",
    "        input_dimensions = image.shape\n",
    "        output_dimension = (input_dimensions[1] - self.filter_dimension) // self.stride + 1\n",
    "\n",
    "        output = np.zeros((input_dimensions[0], output_dimension, output_dimension, input_dimensions[3]))\n",
    "        if not self.index_tracker:\n",
    "            self.index_tracker = np.zeros((input_dimensions[0], output_dimension, output_dimension, input_dimensions[3]))\n",
    "\n",
    "        for i in range(input_dimensions[0]):\n",
    "            image_y = out_y = 0\n",
    "            while image_y + self.filter_dimension <= input_dimensions[2]:\n",
    "                image_x = out_x = 0\n",
    "                while image_x + self.filter_dimension <= input_dimensions[1]:\n",
    "                    # image_slice = image[i, image_x: image_x+self.filter_dimension, image_y: image_y+self.filter_dimension, :]\n",
    "                    output[i, out_x, out_y, :] = np.max(image[i, image_x: image_x+self.filter_dimension, image_y: image_y+self.filter_dimension, :], axis=(0, 1))\n",
    "                    # self.index_tracker[i, out_x, out_y, :] = np.argmax(image[i, image_x: image_x+self.filter_dimension, image_y: image_y+self.filter_dimension, :], axis=(0, 1))\n",
    "                    image_x += self.stride\n",
    "                    out_x += 1\n",
    "                image_y += self.stride\n",
    "                out_y += 1\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 2, 2, 3)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_maxpool = MaxPoolingLayerBatch(2, 1)\n",
    "test_maxpool_out = test_maxpool.forward(test_activation_out)\n",
    "test_maxpool_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.51219226, 0.51219226],\n       [0.81262096, 0.81262096]])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_maxpool_out[0, :, :, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Flattening Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "class FlatteningLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, image: np.ndarray) -> np.ndarray:\n",
    "        return image.flatten().reshape(-1, 1)\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class FlatteningLayerBatch:\n",
    "    def __init__(self):\n",
    "        self.input_shape = None\n",
    "\n",
    "    def forward(self, input_batch: np.ndarray) -> np.ndarray:\n",
    "        input_shape = input_batch.shape\n",
    "        self.input_shape = input_shape\n",
    "        return input_batch.reshape((input_shape[0], -1))\n",
    "\n",
    "    def backward(self, dh_flattened: np.ndarray) -> np.ndarray:\n",
    "        return dh_flattened.reshape(self.input_shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 12)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_flattening = FlatteningLayerBatch()\n",
    "test_flattening_out = test_flattening.forward(test_maxpool_out)\n",
    "test_flattening_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.51219226, 0.86796287, 0.51219226, 0.51219226, 0.86796287,\n        0.51219226, 0.81262096, 1.16839157, 0.81262096, 0.81262096,\n        1.16839157, 0.81262096],\n       [0.51219226, 1.20964589, 0.51219226, 0.51219226, 1.20964589,\n        0.51219226, 0.81262096, 1.51007459, 0.81262096, 0.81262096,\n        1.51007459, 0.81262096],\n       [0.51219226, 1.90366618, 0.51219226, 0.51219226, 1.90366618,\n        0.51219226, 0.81262096, 2.20409488, 0.81262096, 0.81262096,\n        2.20409488, 0.81262096],\n       [0.51219226, 1.55759528, 0.51219226, 0.51219226, 1.55759528,\n        0.51219226, 0.81262096, 1.85802398, 0.81262096, 0.81262096,\n        1.85802398, 0.81262096],\n       [0.51219226, 1.90327794, 0.51219226, 0.51219226, 1.90327794,\n        0.51219226, 0.81262096, 2.20370664, 0.81262096, 0.81262096,\n        2.20370664, 0.81262096],\n       [0.51219226, 1.20560235, 0.51219226, 0.51219226, 1.20560235,\n        0.51219226, 0.81262096, 1.50603105, 0.81262096, 0.81262096,\n        1.50603105, 0.81262096],\n       [0.51219226, 0.85600092, 0.51219226, 0.51219226, 0.85600092,\n        0.51219226, 0.81262096, 1.15642962, 0.81262096, 0.81262096,\n        1.15642962, 0.81262096],\n       [0.51219226, 1.55980866, 0.51219226, 0.51219226, 1.55980866,\n        0.51219226, 0.81262096, 1.86023735, 0.81262096, 0.81262096,\n        1.86023735, 0.81262096],\n       [0.51219226, 0.85851226, 0.51219226, 0.51219226, 0.85851226,\n        0.51219226, 0.81262096, 1.15894096, 0.81262096, 0.81262096,\n        1.15894096, 0.81262096],\n       [0.51219226, 1.55898841, 0.51219226, 0.51219226, 1.55898841,\n        0.51219226, 0.81262096, 1.85941711, 0.81262096, 0.81262096,\n        1.85941711, 0.81262096],\n       [0.51219226, 1.55254233, 0.51219226, 0.51219226, 1.55254233,\n        0.51219226, 0.81262096, 1.85297103, 0.81262096, 0.81262096,\n        1.85297103, 0.81262096],\n       [0.51219226, 1.56202454, 0.51219226, 0.51219226, 1.56202454,\n        0.51219226, 0.81262096, 1.86245323, 0.81262096, 0.81262096,\n        1.86245323, 0.81262096],\n       [0.51219226, 1.56165456, 0.51219226, 0.51219226, 1.56165456,\n        0.51219226, 0.81262096, 1.86208326, 0.81262096, 0.81262096,\n        1.86208326, 0.81262096],\n       [0.51219226, 1.19953575, 0.51219226, 0.51219226, 1.19953575,\n        0.51219226, 0.81262096, 1.49996445, 0.81262096, 0.81262096,\n        1.49996445, 0.81262096],\n       [0.51219226, 0.84958264, 0.51219226, 0.51219226, 0.84958264,\n        0.51219226, 0.81262096, 1.15001134, 0.81262096, 0.81262096,\n        1.15001134, 0.81262096],\n       [0.51219226, 1.20895318, 0.51219226, 0.51219226, 1.20895318,\n        0.51219226, 0.81262096, 1.50938188, 0.81262096, 0.81262096,\n        1.50938188, 0.81262096],\n       [0.51219226, 0.86322697, 0.51219226, 0.51219226, 0.86322697,\n        0.51219226, 0.81262096, 1.16365566, 0.81262096, 0.81262096,\n        1.16365566, 0.81262096],\n       [0.51219226, 1.56527594, 0.51219226, 0.51219226, 1.56527594,\n        0.51219226, 0.81262096, 1.86570464, 0.81262096, 0.81262096,\n        1.86570464, 0.81262096],\n       [0.51219226, 1.89537144, 0.51219226, 0.51219226, 1.89537144,\n        0.51219226, 0.81262096, 2.19580014, 0.81262096, 0.81262096,\n        2.19580014, 0.81262096],\n       [0.51219226, 0.8529639 , 0.51219226, 0.51219226, 0.8529639 ,\n        0.51219226, 0.81262096, 1.1533926 , 0.81262096, 0.81262096,\n        1.1533926 , 0.81262096],\n       [0.51219226, 0.86524614, 0.51219226, 0.51219226, 0.86524614,\n        0.51219226, 0.81262096, 1.16567484, 0.81262096, 0.81262096,\n        1.16567484, 0.81262096],\n       [0.51219226, 1.9091744 , 0.51219226, 0.51219226, 1.9091744 ,\n        0.51219226, 0.81262096, 2.2096031 , 0.81262096, 0.81262096,\n        2.2096031 , 0.81262096],\n       [0.51219226, 0.8655251 , 0.51219226, 0.51219226, 0.8655251 ,\n        0.51219226, 0.81262096, 1.1659538 , 0.81262096, 0.81262096,\n        1.1659538 , 0.81262096],\n       [0.51219226, 0.86731814, 0.51219226, 0.51219226, 0.86731814,\n        0.51219226, 0.81262096, 1.16774684, 0.81262096, 0.81262096,\n        1.16774684, 0.81262096],\n       [0.51219226, 1.90787853, 0.51219226, 0.51219226, 1.90787853,\n        0.51219226, 0.81262096, 2.20830722, 0.81262096, 0.81262096,\n        2.20830722, 0.81262096],\n       [0.51219226, 0.85964971, 0.51219226, 0.51219226, 0.85964971,\n        0.51219226, 0.81262096, 1.16007841, 0.81262096, 0.81262096,\n        1.16007841, 0.81262096],\n       [0.51219226, 1.91049168, 0.51219226, 0.51219226, 1.91049168,\n        0.51219226, 0.81262096, 2.21092038, 0.81262096, 0.81262096,\n        2.21092038, 0.81262096],\n       [0.51219226, 0.85406419, 0.51219226, 0.51219226, 0.85406419,\n        0.51219226, 0.81262096, 1.15449289, 0.81262096, 0.81262096,\n        1.15449289, 0.81262096],\n       [0.51219226, 1.20726626, 0.51219226, 0.51219226, 1.20726626,\n        0.51219226, 0.81262096, 1.50769496, 0.81262096, 0.81262096,\n        1.50769496, 0.81262096],\n       [0.51219226, 1.56217704, 0.51219226, 0.51219226, 1.56217704,\n        0.51219226, 0.81262096, 1.86260574, 0.81262096, 0.81262096,\n        1.86260574, 0.81262096],\n       [0.51219226, 1.55909716, 0.51219226, 0.51219226, 1.55909716,\n        0.51219226, 0.81262096, 1.85952586, 0.81262096, 0.81262096,\n        1.85952586, 0.81262096],\n       [0.51219226, 1.56585878, 0.51219226, 0.51219226, 1.56585878,\n        0.51219226, 0.81262096, 1.86628748, 0.81262096, 0.81262096,\n        1.86628748, 0.81262096],\n       [0.51219226, 1.56593223, 0.51219226, 0.51219226, 1.56593223,\n        0.51219226, 0.81262096, 1.86636093, 0.81262096, 0.81262096,\n        1.86636093, 0.81262096],\n       [0.51219226, 1.22450814, 0.51219226, 0.51219226, 1.22450814,\n        0.51219226, 0.81262096, 1.52493684, 0.81262096, 0.81262096,\n        1.52493684, 0.81262096],\n       [0.51219226, 0.85421403, 0.51219226, 0.51219226, 0.85421403,\n        0.51219226, 0.81262096, 1.15464273, 0.81262096, 0.81262096,\n        1.15464273, 0.81262096],\n       [0.51219226, 1.90660918, 0.51219226, 0.51219226, 1.90660918,\n        0.51219226, 0.81262096, 2.20703788, 0.81262096, 0.81262096,\n        2.20703788, 0.81262096],\n       [0.51219226, 0.86355364, 0.51219226, 0.51219226, 0.86355364,\n        0.51219226, 0.81262096, 1.16398234, 0.81262096, 0.81262096,\n        1.16398234, 0.81262096],\n       [0.51219226, 1.56401613, 0.51219226, 0.51219226, 1.56401613,\n        0.51219226, 0.81262096, 1.86444482, 0.81262096, 0.81262096,\n        1.86444482, 0.81262096],\n       [0.51219226, 1.91883808, 0.51219226, 0.51219226, 1.91883808,\n        0.51219226, 0.81262096, 2.21926678, 0.81262096, 0.81262096,\n        2.21926678, 0.81262096],\n       [0.51219226, 0.8746173 , 0.51219226, 0.51219226, 0.8746173 ,\n        0.51219226, 0.81262096, 1.175046  , 0.81262096, 0.81262096,\n        1.175046  , 0.81262096],\n       [0.51219226, 1.90522307, 0.51219226, 0.51219226, 1.90522307,\n        0.51219226, 0.81262096, 2.20565176, 0.81262096, 0.81262096,\n        2.20565176, 0.81262096],\n       [0.51219226, 0.85999298, 0.51219226, 0.51219226, 0.85999298,\n        0.51219226, 0.81262096, 1.16042168, 0.81262096, 0.81262096,\n        1.16042168, 0.81262096],\n       [0.51219226, 1.90505158, 0.51219226, 0.51219226, 1.90505158,\n        0.51219226, 0.81262096, 2.20548028, 0.81262096, 0.81262096,\n        2.20548028, 0.81262096],\n       [0.51219226, 1.9085618 , 0.51219226, 0.51219226, 1.9085618 ,\n        0.51219226, 0.81262096, 2.20899049, 0.81262096, 0.81262096,\n        2.20899049, 0.81262096],\n       [0.51219226, 0.87204777, 0.51219226, 0.51219226, 0.87204777,\n        0.51219226, 0.81262096, 1.17247647, 0.81262096, 0.81262096,\n        1.17247647, 0.81262096],\n       [0.51219226, 1.55972102, 0.51219226, 0.51219226, 1.55972102,\n        0.51219226, 0.81262096, 1.86014972, 0.81262096, 0.81262096,\n        1.86014972, 0.81262096],\n       [0.51219226, 1.90980233, 0.51219226, 0.51219226, 1.90980233,\n        0.51219226, 0.81262096, 2.21023103, 0.81262096, 0.81262096,\n        2.21023103, 0.81262096],\n       [0.51219226, 1.20998087, 0.51219226, 0.51219226, 1.20998087,\n        0.51219226, 0.81262096, 1.51040956, 0.81262096, 0.81262096,\n        1.51040956, 0.81262096],\n       [0.51219226, 1.90187684, 0.51219226, 0.51219226, 1.90187684,\n        0.51219226, 0.81262096, 2.20230554, 0.81262096, 0.81262096,\n        2.20230554, 0.81262096],\n       [0.51219226, 1.548617  , 0.51219226, 0.51219226, 1.548617  ,\n        0.51219226, 0.81262096, 1.8490457 , 0.81262096, 0.81262096,\n        1.8490457 , 0.81262096]])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_flattening_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fully Connected Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "class FullyConnectedLayer:\n",
    "    def __init__(self, output_dimension: int):\n",
    "        self.output_dimension = output_dimension\n",
    "\n",
    "    def forward(self, flattened_input: np.ndarray) -> np.ndarray:\n",
    "        weights = np.random.rand(flattened_input.shape[0], self.output_dimension)\n",
    "        bias = np.random.rand(self.output_dimension, 1)\n",
    "\n",
    "        return weights.T @ flattened_input + bias\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "class FullyConnectedLayerBatch:\n",
    "    def __init__(self, output_dimension: int):\n",
    "        self.output_dimension = output_dimension\n",
    "        self.input_matrix = None\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def forward(self, flattened_input: np.ndarray) -> np.ndarray:\n",
    "        if not self.weights:\n",
    "            self.weights = np.random.rand(flattened_input.shape[1], self.output_dimension)\n",
    "        if not self.bias:\n",
    "            self.bias = np.random.rand(1, self.output_dimension)\n",
    "        self.input_matrix = flattened_input\n",
    "\n",
    "        return flattened_input @ self.weights + self.bias\n",
    "\n",
    "    def backward(self, d_theta: np.ndarray, learning_rate: int) -> np.ndarray:\n",
    "        n = d_theta.shape[0]\n",
    "        dw = self.input_matrix.T @ d_theta\n",
    "        db = np.sum(d_theta, axis=0, keepdims=True)\n",
    "        dh = d_theta @ self.weights.T\n",
    "        self.weights = self.weights - learning_rate * dw / n\n",
    "        self.bias = self.bias - learning_rate * db / n\n",
    "\n",
    "        return dh"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 4)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fc = FullyConnectedLayerBatch(4)\n",
    "test_fc_out = test_fc.forward(test_flattening_out)\n",
    "test_fc_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[6.35091783, 5.71333817, 4.93297295, 4.24332866],\n       [7.38872328, 6.66679487, 5.50438942, 4.78519853],\n       [9.49669466, 8.6034386 , 6.66504006, 5.88583466],\n       [8.44556177, 7.63773767, 6.08628549, 5.33700613],\n       [9.49551545, 8.60235523, 6.66439078, 5.88521896],\n       [7.37644169, 6.65551148, 5.49762717, 4.77878594],\n       [6.31458541, 5.67995871, 4.91296829, 4.2243584 ],\n       [8.45228453, 7.64391403, 6.08998705, 5.34051629],\n       [6.32221318, 5.68696653, 4.91716815, 4.22834109],\n       [8.44979318, 7.64162517, 6.08861531, 5.33921548],\n       [8.43021428, 7.62363756, 6.07783515, 5.32899274],\n       [8.45901489, 7.65009738, 6.09369279, 5.34403042],\n       [8.45789117, 7.64906498, 6.09307407, 5.34344368],\n       [7.3580154 , 6.6385828 , 5.48748164, 4.76916501],\n       [6.29509095, 5.66204868, 4.90223463, 4.21417975],\n       [7.38661929, 6.66486188, 5.50323096, 4.78409997],\n       [6.33653331, 5.70012277, 4.92505282, 4.23581807],\n       [8.4688905 , 7.65917034, 6.09913031, 5.34918677],\n       [9.47150077, 8.58029237, 6.65116828, 5.87268016],\n       [6.30536096, 5.67148399, 4.9078893 , 4.21954203],\n       [6.34266621, 5.70575721, 4.9284296 , 4.23902024],\n       [9.51342497, 8.61880914, 6.67425178, 5.89457006],\n       [6.34351351, 5.70653565, 4.92889613, 4.23946264],\n       [6.34895958, 5.71153908, 4.93189474, 4.2423062 ],\n       [9.50948896, 8.61519304, 6.67208461, 5.89251495],\n       [6.325668  , 5.69014055, 4.91907037, 4.23014496],\n       [9.517426  , 8.62248498, 6.67645475, 5.89665912],\n       [6.30870291, 5.67455432, 4.90972938, 4.22128697],\n       [7.38149555, 6.66015458, 5.50040983, 4.78142472],\n       [8.4594781 , 7.65052294, 6.09394783, 5.34427227],\n       [8.45012349, 7.64192863, 6.08879718, 5.33938794],\n       [8.47066078, 7.66079673, 6.10010503, 5.35011109],\n       [8.47088388, 7.6610017 , 6.10022786, 5.35022757],\n       [7.43386489, 6.70826755, 5.52924442, 4.80876834],\n       [6.30915801, 5.67497243, 4.90997996, 4.22152459],\n       [9.50563355, 8.61165097, 6.66996182, 5.89050192],\n       [6.33752554, 5.70103436, 4.92559915, 4.23633614],\n       [8.46506402, 7.65565485, 6.09702345, 5.34718885],\n       [9.54277679, 8.64577536, 6.69041291, 5.90989554],\n       [6.37112957, 5.73190718, 4.94410155, 4.25388183],\n       [9.50142344, 8.60778305, 6.66764373, 5.8883037 ],\n       [6.32671061, 5.69109842, 4.91964444, 4.23068934],\n       [9.50090258, 8.60730452, 6.66735694, 5.88803174],\n       [9.51156428, 8.61709968, 6.67322728, 5.89359854],\n       [6.36332505, 5.72473698, 4.93980438, 4.24980685],\n       [8.45201836, 7.64366949, 6.08984049, 5.34037731],\n       [9.5153322 , 8.62056136, 6.6753019 , 5.89556589],\n       [7.38974071, 6.6677296 , 5.50494961, 4.78572976],\n       [9.49125983, 8.5984455 , 6.66204764, 5.88299697],\n       [8.41829172, 7.61268403, 6.07127058, 5.32276761]])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fc_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Softmax Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "class SoftmaxLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, input_matrix: np.ndarray) -> np.ndarray:\n",
    "        exp = np.exp(input_matrix)\n",
    "        exp /= np.sum(exp)\n",
    "        return exp\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "class SoftmaxLayerBatch:\n",
    "    def __init__(self):\n",
    "        self.y_hat = None\n",
    "\n",
    "    def forward(self, input_matrix: np.ndarray) -> np.ndarray:\n",
    "        exp = np.exp(input_matrix)\n",
    "        exp_sum = np.sum(exp, axis=1).reshape(-1, 1)\n",
    "        exp /= exp_sum\n",
    "        self.y_hat = exp\n",
    "        return exp\n",
    "\n",
    "    def backward(self, y: np.ndarray) -> np.ndarray:\n",
    "        return self.y_hat - y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 4)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_softmax = SoftmaxLayerBatch()\n",
    "test_softmax_out = test_softmax.forward(test_fc_out)\n",
    "test_softmax_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.52845406, 0.27932507, 0.12799753, 0.06422334],\n       [0.58419508, 0.28381044, 0.08875689, 0.04323759],\n       [0.66877791, 0.27374472, 0.03940125, 0.01807613],\n       [0.63092235, 0.28128228, 0.05961496, 0.02818041],\n       [0.66873959, 0.27375526, 0.03941987, 0.01808528],\n       [0.58359445, 0.2838018 , 0.08915637, 0.04344738],\n       [0.5263183 , 0.27901889, 0.12957878, 0.06508403],\n       [0.6311899 , 0.28124784, 0.05946033, 0.02810194],\n       [0.52676772, 0.27908406, 0.12924562, 0.06490259],\n       [0.63109079, 0.28126062, 0.05951759, 0.028131  ],\n       [0.63031025, 0.28136013, 0.05996932, 0.02836031],\n       [0.63145739, 0.28121316, 0.05930587, 0.02802357],\n       [0.63141276, 0.28121896, 0.05933164, 0.02803664],\n       [0.58269073, 0.283787  , 0.08975851, 0.04376376],\n       [0.52516725, 0.27885014, 0.1304331 , 0.0655495 ],\n       [0.58409228, 0.28380903, 0.08882522, 0.04327347],\n       [0.52760996, 0.27920514, 0.12862186, 0.06456304],\n       [0.63184926, 0.28116191, 0.05907989, 0.02790894],\n       [0.6679572 , 0.2739692 , 0.03980098, 0.01827261],\n       [0.52577409, 0.27893943, 0.12998252, 0.06530396],\n       [0.52797008, 0.27925648, 0.1283554 , 0.06441804],\n       [0.66932076, 0.27359464, 0.03913786, 0.01794674],\n       [0.52801981, 0.27926354, 0.12831862, 0.06439802],\n       [0.52833926, 0.27930884, 0.1280824 , 0.0642695 ],\n       [0.66919321, 0.27363002, 0.03919968, 0.0179771 ],\n       [0.52697109, 0.27911343, 0.12909494, 0.06482055],\n       [0.66945033, 0.27355863, 0.03907511, 0.01791593],\n       [0.52597135, 0.2789683 , 0.12983614, 0.06522421],\n       [0.58384178, 0.28380547, 0.08899181, 0.04336095],\n       [0.63147579, 0.28121077, 0.05929526, 0.02801819],\n       [0.63110393, 0.28125893, 0.05950999, 0.02812714],\n       [0.63191942, 0.28115267, 0.05903947, 0.02788844],\n       [0.63192826, 0.28115151, 0.05903437, 0.02788586],\n       [0.58639084, 0.28383389, 0.08730136, 0.04247391],\n       [0.5259982 , 0.27897222, 0.12981622, 0.06521336],\n       [0.66906817, 0.27366463, 0.03926032, 0.01800689],\n       [0.52766825, 0.27921346, 0.12857873, 0.06453956],\n       [0.63169751, 0.28118182, 0.05916736, 0.02795331],\n       [0.67026902, 0.27332942, 0.03867971, 0.01772184],\n       [0.52963682, 0.27949073, 0.12712407, 0.06374838],\n       [0.66893152, 0.27370238, 0.03932663, 0.01803947],\n       [0.52703244, 0.27912227, 0.12904949, 0.0647958 ],\n       [0.66891461, 0.27370704, 0.03933485, 0.0180435 ],\n       [0.66926048, 0.27361137, 0.03916707, 0.01796109],\n       [0.52918057, 0.27942716, 0.12746082, 0.06393146],\n       [0.63117931, 0.28124921, 0.05946644, 0.02810504],\n       [0.66938254, 0.27357748, 0.03910794, 0.01793205],\n       [0.58424477, 0.28381111, 0.08872387, 0.04322025],\n       [0.6686012 , 0.2737933 , 0.03948716, 0.01811834],\n       [0.62983347, 0.28141987, 0.06024589, 0.02850078]])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_softmax_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Backprop Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Loss Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    labels = y_true * np.log(y_pred) * -1.0\n",
    "    return np.sum(labels) / y_true.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "2.2159611280267844"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function_test = loss_function(toy_labels_1, test_softmax_out)\n",
    "loss_function_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Softmax Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.47154594,  0.27932507,  0.12799753,  0.06422334],\n       [ 0.58419508, -0.71618956,  0.08875689,  0.04323759],\n       [ 0.66877791,  0.27374472,  0.03940125, -0.98192387],\n       [ 0.63092235,  0.28128228, -0.94038504,  0.02818041],\n       [ 0.66873959,  0.27375526,  0.03941987, -0.98191472],\n       [ 0.58359445, -0.7161982 ,  0.08915637,  0.04344738],\n       [-0.4736817 ,  0.27901889,  0.12957878,  0.06508403],\n       [ 0.6311899 ,  0.28124784, -0.94053967,  0.02810194],\n       [-0.47323228,  0.27908406,  0.12924562,  0.06490259],\n       [ 0.63109079,  0.28126062, -0.94048241,  0.028131  ],\n       [ 0.63031025,  0.28136013, -0.94003068,  0.02836031],\n       [ 0.63145739,  0.28121316, -0.94069413,  0.02802357],\n       [ 0.63141276,  0.28121896, -0.94066836,  0.02803664],\n       [ 0.58269073, -0.716213  ,  0.08975851,  0.04376376],\n       [-0.47483275,  0.27885014,  0.1304331 ,  0.0655495 ],\n       [ 0.58409228, -0.71619097,  0.08882522,  0.04327347],\n       [-0.47239004,  0.27920514,  0.12862186,  0.06456304],\n       [ 0.63184926,  0.28116191, -0.94092011,  0.02790894],\n       [ 0.6679572 ,  0.2739692 ,  0.03980098, -0.98172739],\n       [-0.47422591,  0.27893943,  0.12998252,  0.06530396],\n       [-0.47202992,  0.27925648,  0.1283554 ,  0.06441804],\n       [ 0.66932076,  0.27359464,  0.03913786, -0.98205326],\n       [-0.47198019,  0.27926354,  0.12831862,  0.06439802],\n       [-0.47166074,  0.27930884,  0.1280824 ,  0.0642695 ],\n       [ 0.66919321,  0.27363002,  0.03919968, -0.9820229 ],\n       [-0.47302891,  0.27911343,  0.12909494,  0.06482055],\n       [ 0.66945033,  0.27355863,  0.03907511, -0.98208407],\n       [-0.47402865,  0.2789683 ,  0.12983614,  0.06522421],\n       [ 0.58384178, -0.71619453,  0.08899181,  0.04336095],\n       [ 0.63147579,  0.28121077, -0.94070474,  0.02801819],\n       [ 0.63110393,  0.28125893, -0.94049001,  0.02812714],\n       [ 0.63191942,  0.28115267, -0.94096053,  0.02788844],\n       [ 0.63192826,  0.28115151, -0.94096563,  0.02788586],\n       [ 0.58639084, -0.71616611,  0.08730136,  0.04247391],\n       [-0.4740018 ,  0.27897222,  0.12981622,  0.06521336],\n       [ 0.66906817,  0.27366463,  0.03926032, -0.98199311],\n       [-0.47233175,  0.27921346,  0.12857873,  0.06453956],\n       [ 0.63169751,  0.28118182, -0.94083264,  0.02795331],\n       [ 0.67026902,  0.27332942,  0.03867971, -0.98227816],\n       [-0.47036318,  0.27949073,  0.12712407,  0.06374838],\n       [ 0.66893152,  0.27370238,  0.03932663, -0.98196053],\n       [-0.47296756,  0.27912227,  0.12904949,  0.0647958 ],\n       [ 0.66891461,  0.27370704,  0.03933485, -0.9819565 ],\n       [ 0.66926048,  0.27361137,  0.03916707, -0.98203891],\n       [-0.47081943,  0.27942716,  0.12746082,  0.06393146],\n       [ 0.63117931,  0.28124921, -0.94053356,  0.02810504],\n       [ 0.66938254,  0.27357748,  0.03910794, -0.98206795],\n       [ 0.58424477, -0.71618889,  0.08872387,  0.04322025],\n       [ 0.6686012 ,  0.2737933 ,  0.03948716, -0.98188166],\n       [ 0.62983347,  0.28141987, -0.93975411,  0.02850078]])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_softmax_back = test_softmax.backward(toy_labels_1)\n",
    "test_softmax_back"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fully Connected Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 9.07210861e-03, -1.43234462e-01, -9.92421092e-02,\n         6.83496082e-02,  5.44988454e-02, -8.74197445e-04,\n        -2.47248328e-02, -1.90218193e-01, -2.79561932e-01,\n         2.29300731e-01, -5.79315291e-02,  1.98217759e-01],\n       [-9.34905571e-02,  5.76479690e-02,  1.42621721e-01,\n        -7.78725763e-02, -3.13775495e-01,  1.69611947e-01,\n         5.50177620e-02,  3.28494635e-01,  3.14881620e-01,\n        -5.03444243e-01, -7.94748604e-02, -1.77734267e-01],\n       [-2.82463433e-01,  2.65420626e-01, -1.77042843e-02,\n        -2.45767883e-01,  5.21358029e-01,  2.18906634e-01,\n         4.05675418e-01,  4.08427802e-01,  3.01332280e-01,\n        -8.39380003e-02,  1.08647187e-01, -1.57681715e-01],\n       [ 3.40860731e-01,  4.80276260e-01,  1.58874469e-01,\n        -3.58209322e-02,  2.87050013e-01, -5.56177798e-01,\n        -2.15673970e-01, -6.17994139e-02,  5.05139092e-01,\n         1.58612113e-01,  4.67735244e-01, -5.07317802e-01],\n       [-2.82465459e-01,  2.65405027e-01, -1.77117230e-02,\n        -2.45762125e-01,  5.21354394e-01,  2.18912176e-01,\n         4.05674271e-01,  4.08415436e-01,  3.01308502e-01,\n        -8.39265903e-02,  1.08637475e-01, -1.57663339e-01],\n       [-9.35555542e-02,  5.73492055e-02,  1.42515982e-01,\n        -7.77773713e-02, -3.13950158e-01,  1.69771230e-01,\n         5.50058884e-02,  3.28340504e-01,  3.14496162e-01,\n        -5.03366508e-01, -7.96949460e-02, -1.77417606e-01],\n       [ 8.79436017e-03, -1.44380602e-01, -9.95991861e-02,\n         6.86979686e-02,  5.36891733e-02, -2.00604418e-04,\n        -2.47633607e-02, -1.90707868e-01, -2.80950693e-01,\n         2.29419327e-01, -5.88180662e-02,  1.99385670e-01],\n       [ 3.40882598e-01,  4.80397476e-01,  1.58924022e-01,\n        -3.58621729e-02,  2.87101823e-01, -5.56233094e-01,\n        -2.15667569e-01, -6.17221966e-02,  5.05308055e-01,\n         1.58555325e-01,  4.67818476e-01, -5.07452677e-01],\n       [ 8.85292449e-03, -1.44139201e-01, -9.95241020e-02,\n         6.86246360e-02,  5.38600630e-02, -3.42626786e-04,\n        -2.47552562e-02, -1.90604981e-01, -2.80658417e-01,\n         2.29394798e-01, -5.86312393e-02,  1.99139804e-01],\n       [ 3.40874503e-01,  4.80352583e-01,  1.58905664e-01,\n        -3.58468969e-02,  2.87082650e-01, -5.56212623e-01,\n        -2.15669941e-01, -6.17508068e-02,  5.05245468e-01,\n         1.58576378e-01,  4.67787655e-01, -5.07402720e-01],\n       [ 3.40810523e-01,  4.79998644e-01,  1.58761156e-01,\n        -3.57265530e-02,  2.86930846e-01, -5.56050898e-01,\n        -2.15688583e-01, -6.19758626e-02,  5.04752461e-01,\n         1.58741492e-01,  4.67544456e-01, -5.07009073e-01],\n       [ 3.40904413e-01,  4.80518591e-01,  1.58973582e-01,\n        -3.59033987e-02,  2.87153455e-01, -5.56288276e-01,\n        -2.15661159e-01, -6.16449369e-02,  5.05476968e-01,\n         1.58498403e-01,  4.67901595e-01, -5.07587486e-01],\n       [ 3.40900776e-01,  4.80498386e-01,  1.58965311e-01,\n        -3.58965197e-02,  2.87144851e-01, -5.56279075e-01,\n        -2.15662229e-01, -6.16578334e-02,  5.05448782e-01,\n         1.58507911e-01,  4.67887731e-01, -5.07564993e-01],\n       [-9.36536699e-02,  5.68991229e-02,  1.42357000e-01,\n        -7.76340629e-02, -3.14214184e-01,  1.70011611e-01,\n         5.49880618e-02,  3.28108983e-01,  3.13916062e-01,\n        -5.03250577e-01, -8.00267809e-02, -1.76940864e-01],\n       [ 8.64407583e-03, -1.44999426e-01, -9.97913635e-02,\n         6.88858603e-02,  5.32502400e-02,  1.63828229e-04,\n        -2.47841121e-02, -1.90971012e-01, -2.81699388e-01,\n         2.29481122e-01, -5.92972443e-02,  2.00015654e-01],\n       [-9.35016693e-02,  5.75968566e-02,  1.42603619e-01,\n        -7.78562842e-02, -3.13805343e-01,  1.69639181e-01,\n         5.50157284e-02,  3.28468241e-01,  3.14815654e-01,\n        -5.03430899e-01, -7.95125020e-02, -1.77680081e-01],\n       [ 8.96250848e-03, -1.43687117e-01, -9.93833107e-02,\n         6.84872458e-02,  5.41795877e-02, -6.08385540e-04,\n        -2.47400639e-02, -1.90411943e-01, -2.80110733e-01,\n         2.29348217e-01, -5.82815069e-02,  1.98679184e-01],\n       [ 3.40936285e-01,  4.80695877e-01,  1.59046212e-01,\n        -3.59637792e-02,  2.87228788e-01, -5.56368927e-01,\n        -2.15651754e-01, -6.15316536e-02,  5.05724381e-01,\n         1.58414754e-01,  4.68023183e-01, -5.07784898e-01],\n       [-2.82507110e-01,  2.65086146e-01, -1.78634929e-02,\n        -2.45644541e-01,  5.21279270e-01,  2.19025903e-01,\n         4.05650932e-01,  4.08163329e-01,  3.00822986e-01,\n        -8.36944815e-02,  1.08438655e-01, -1.57287989e-01],\n       [ 8.72335750e-03, -1.44673084e-01, -9.96900705e-02,\n         6.87867908e-02,  5.34818694e-02, -2.84232216e-05,\n        -2.47731730e-02, -1.90832348e-01, -2.81304655e-01,\n         2.29448728e-01, -5.90445005e-02,  1.99683478e-01],\n       [ 9.00929537e-03, -1.43493947e-01, -9.93230815e-02,\n         6.84285180e-02,  5.43159132e-02, -7.21855479e-04,\n        -2.47335665e-02, -1.90329318e-01, -2.79876584e-01,\n         2.29328056e-01, -5.81321298e-02,  1.98482299e-01],\n       [-2.82434865e-01,  2.65641360e-01, -1.75988832e-02,\n        -2.45849426e-01,  5.21409050e-01,  2.18828430e-01,\n         4.05691687e-01,  4.08603111e-01,  3.01669024e-01,\n        -8.41000062e-02,  1.08784486e-01, -1.57941868e-01],\n       [ 9.01575245e-03, -1.43467280e-01, -9.93147637e-02,\n         6.84204097e-02,  5.43347231e-02, -7.37515720e-04,\n        -2.47326692e-02, -1.90317905e-01, -2.79844254e-01,\n         2.29325261e-01, -5.81115114e-02,  1.98455116e-01],\n       [ 9.05721621e-03, -1.43295999e-01, -9.92613186e-02,\n         6.83683237e-02,  5.44554834e-02, -8.38078229e-04,\n        -2.47269046e-02, -1.90244560e-01, -2.79636564e-01,\n         2.29307237e-01, -5.79790954e-02,  1.98280501e-01],\n       [-2.82441555e-01,  2.65589529e-01, -1.76236569e-02,\n        -2.45830268e-01,  5.21397138e-01,  2.18846757e-01,\n         4.05687859e-01,  4.08561890e-01,  3.01589906e-01,\n        -8.40618715e-02,  1.08752269e-01, -1.57880757e-01],\n       [ 8.87940560e-03, -1.44030000e-01, -9.94901151e-02,\n         6.85914561e-02,  5.39373052e-02, -4.06846470e-04,\n        -2.47515883e-02, -1.90558396e-01, -2.80526163e-01,\n         2.29383623e-01, -5.85467436e-02,  1.99028562e-01],\n       [-2.82428084e-01,  2.65693986e-01, -1.75737147e-02,\n        -2.45868884e-01,  5.21421101e-01,  2.18809846e-01,\n         4.05695578e-01,  4.08644998e-01,  3.01749384e-01,\n        -8.41387842e-02,  1.08817182e-01, -1.58003929e-01],\n       [ 8.74910392e-03, -1.44567050e-01, -9.96571332e-02,\n         6.87545935e-02,  5.35570554e-02, -9.08575843e-05,\n        -2.47696166e-02, -1.90787243e-01, -2.81176353e-01,\n         2.29438110e-01, -5.89624018e-02,  1.99575524e-01],\n       [-9.35287693e-02,  5.74722652e-02,  1.42559515e-01,\n        -7.78165784e-02, -3.13878157e-01,  1.69705595e-01,\n         5.50107752e-02,  3.28403947e-01,  3.14654893e-01,\n        -5.03398451e-01, -7.96042755e-02, -1.77548018e-01],\n       [ 3.40905912e-01,  4.80526918e-01,  1.58976991e-01,\n        -3.59062337e-02,  2.87157000e-01, -5.56292068e-01,\n        -2.15660718e-01, -6.16396213e-02,  5.05488584e-01,\n         1.58494483e-01,  4.67907308e-01, -5.07596756e-01],\n       [ 3.40875577e-01,  4.80358537e-01,  1.58908099e-01,\n        -3.58489227e-02,  2.87085194e-01, -5.56215338e-01,\n        -2.15669627e-01, -6.17470133e-02,  5.05253768e-01,\n         1.58573587e-01,  4.67791743e-01, -5.07409345e-01],\n       [ 3.40941981e-01,  4.80727603e-01,  1.59059220e-01,\n        -3.59745889e-02,  2.87242238e-01, -5.56383344e-01,\n        -2.15650068e-01, -6.15113570e-02,  5.05768677e-01,\n         1.58399744e-01,  4.68044932e-01, -5.07820235e-01],\n       [ 3.40942699e-01,  4.80731600e-01,  1.59060859e-01,\n        -3.59759509e-02,  2.87243932e-01, -5.56385160e-01,\n        -2.15649856e-01, -6.15087993e-02,  5.05774258e-01,\n         1.58397852e-01,  4.68047672e-01, -5.07824688e-01],\n       [-9.32543906e-02,  5.87376839e-02,  1.43008821e-01,\n        -7.82203589e-02, -3.13142514e-01,  1.69032899e-01,\n         5.50613493e-02,  3.29059886e-01,  3.16290214e-01,\n        -5.03733117e-01, -7.86733879e-02, -1.78890632e-01],\n       [ 8.75260802e-03, -1.44552617e-01, -9.96526488e-02,\n         6.87502105e-02,  5.35672869e-02, -9.93549746e-05,\n        -2.47691325e-02, -1.90781101e-01, -2.81158887e-01,\n         2.29436661e-01, -5.89512274e-02,  1.99560828e-01],\n       [-2.82448126e-01,  2.65538699e-01, -1.76479371e-02,\n        -2.45811487e-01,  5.21385415e-01,  2.18864752e-01,\n         4.05684109e-01,  4.08521500e-01,  3.01512345e-01,\n        -8.40245299e-02,  1.08720662e-01, -1.57820842e-01],\n       [ 8.97008394e-03, -1.43655846e-01, -9.93735636e-02,\n         6.84777397e-02,  5.42016646e-02, -6.26757746e-04,\n        -2.47390123e-02, -1.90398574e-01, -2.80072834e-01,\n         2.29344963e-01, -5.82573231e-02,  1.98647315e-01],\n       [ 3.40923955e-01,  4.80627245e-01,  1.59018083e-01,\n        -3.59403993e-02,  2.87199659e-01, -5.56337722e-01,\n        -2.15655398e-01, -6.15755358e-02,  5.05628578e-01,\n         1.58447183e-01,  4.67976124e-01, -5.07708463e-01],\n       [-2.82385580e-01,  2.66025973e-01, -1.74145869e-02,\n        -2.45991790e-01,  5.21496116e-01,  2.18693140e-01,\n         4.05720246e-01,  4.08910065e-01,  3.02257014e-01,\n        -8.43847897e-02,  1.09023108e-01, -1.58395781e-01],\n       [ 9.22530109e-03, -1.42600911e-01, -9.90440850e-02,\n         6.81568404e-02,  5.49445552e-02, -1.24575799e-03,\n        -2.47034809e-02, -1.89946217e-01, -2.78793092e-01,\n         2.29232837e-01, -5.74420203e-02,  1.97571551e-01],\n       [-2.82455323e-01,  2.65483128e-01, -1.76744668e-02,\n        -2.45790960e-01,  5.21372553e-01,  2.18884449e-01,\n         4.05680015e-01,  4.08477378e-01,  3.01427578e-01,\n        -8.39837672e-02,  1.08686090e-01, -1.57755352e-01],\n       [ 8.88739180e-03, -1.43997062e-01, -9.94798608e-02,\n         6.85814471e-02,  5.39605964e-02, -4.26214076e-04,\n        -2.47504817e-02, -1.90544339e-01, -2.80486266e-01,\n         2.29380243e-01, -5.85212591e-02,  1.98995005e-01],\n       [-2.82456215e-01,  2.65476248e-01, -1.76777501e-02,\n        -2.45788420e-01,  5.21370957e-01,  2.18886890e-01,\n         4.05679509e-01,  4.08471918e-01,  3.01417086e-01,\n        -8.39787252e-02,  1.08681808e-01, -1.57747245e-01],\n       [-2.82438025e-01,  2.65616865e-01, -1.76105928e-02,\n        -2.45840372e-01,  5.21403425e-01,  2.18837089e-01,\n         4.05689877e-01,  4.08583626e-01,  3.01631630e-01,\n        -8.40819770e-02,  1.08769263e-01, -1.57912986e-01],\n       [ 9.16625944e-03, -1.42845206e-01, -9.91204971e-02,\n         6.82311884e-02,  5.47728483e-02, -1.10255199e-03,\n        -2.47117189e-02, -1.90051200e-01, -2.79089654e-01,\n         2.29259216e-01, -5.76307272e-02,  1.97820779e-01],\n       [ 3.40881734e-01,  4.80392681e-01,  1.58922061e-01,\n        -3.58605412e-02,  2.87099776e-01, -5.56230908e-01,\n        -2.15667822e-01, -6.17252530e-02,  5.05301370e-01,\n         1.58557574e-01,  4.67815184e-01, -5.07447341e-01],\n       [-2.82431630e-01,  2.65666454e-01, -1.75868839e-02,\n        -2.45858704e-01,  5.21414801e-01,  2.18819566e-01,\n         4.05693542e-01,  4.08623080e-01,  3.01707339e-01,\n        -8.41184895e-02,  1.08800079e-01, -1.57971459e-01],\n       [-9.34851869e-02,  5.76726751e-02,  1.42630473e-01,\n        -7.78804520e-02, -3.13761073e-01,  1.69598785e-01,\n         5.50187453e-02,  3.28507397e-01,  3.14913509e-01,\n        -5.03450699e-01, -7.94566672e-02, -1.77760460e-01],\n       [-2.82472788e-01,  2.65348684e-01, -1.77385792e-02,\n        -2.45741332e-01,  5.21341235e-01,  2.18932209e-01,\n         4.05670134e-01,  4.08370798e-01,  3.01222639e-01,\n        -8.38854231e-02,  1.08602384e-01, -1.57596981e-01],\n       [ 3.40771243e-01,  4.79782123e-01,  1.58672950e-01,\n        -3.56530138e-02,  2.86837418e-01, -5.55951680e-01,\n        -2.15699934e-01, -6.21130967e-02,  5.04451240e-01,\n         1.58841746e-01,  4.67395498e-01, -5.06768450e-01]])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fc_back = test_fc.backward(test_softmax_back, learning_rate=0.01)\n",
    "test_fc_back"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Flattening Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.00907211,  0.06834961],\n       [-0.02472483,  0.22930073]])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_flattening_back = test_flattening.backward(test_fc_back)\n",
    "test_flattening_back[0, :, :, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7fe797c83a90>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = process_mnist_data()\n",
    "img = x_train[0].reshape(28, 28, 1)\n",
    "plt.imshow(img, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 6, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "m = parse_input_model()\n",
    "c1 = ConvolutionLayerBatch(6, 5, 1, 2)\n",
    "mnist_batch_1 = x_train[0:64].reshape(64, 28, 28, 1)\n",
    "o = c1.forward(mnist_batch_1)\n",
    "print(o.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[9.86851380e-01, 9.86851380e-01, 3.15663135e+00, 7.91239468e+00,\n        1.40110998e+01, 2.24311106e+01, 3.60908330e+01, 5.10759381e+01,\n        6.39607815e+01, 8.12261663e+01, 1.04454942e+02, 1.21048966e+02,\n        1.30476285e+02, 1.37940258e+02, 1.41006087e+02, 1.40217556e+02,\n        1.29952965e+02, 1.16401296e+02, 1.00993375e+02, 8.16753201e+01,\n        5.40329074e+01, 3.54382342e+01, 2.34450626e+01, 1.71768862e+01,\n        1.04181153e+01, 3.73905635e+00, 9.86851380e-01, 9.86851380e-01],\n       [7.80425441e-02, 7.80425441e-02, 2.24782251e+00, 7.00358584e+00,\n        1.31022909e+01, 2.15223018e+01, 3.51820242e+01, 5.01671293e+01,\n        6.30519727e+01, 8.03173574e+01, 1.03546133e+02, 1.20140157e+02,\n        1.29567476e+02, 1.37031450e+02, 1.40097278e+02, 1.39308747e+02,\n        1.29044156e+02, 1.15492487e+02, 1.00084566e+02, 8.07665112e+01,\n        5.31240986e+01, 3.45294253e+01, 2.25362538e+01, 1.62680773e+01,\n        9.50930643e+00, 2.83024751e+00, 7.80425441e-02, 7.80425441e-02],\n       [7.57853677e-01, 7.57853677e-01, 2.92763364e+00, 7.68339698e+00,\n        1.37821021e+01, 2.22021129e+01, 3.58618353e+01, 5.08469404e+01,\n        6.37317838e+01, 8.09971686e+01, 1.04225944e+02, 1.20819968e+02,\n        1.30247288e+02, 1.37711261e+02, 1.40777089e+02, 1.39988558e+02,\n        1.29723967e+02, 1.16172299e+02, 1.00764377e+02, 8.14463224e+01,\n        5.38039097e+01, 3.52092364e+01, 2.32160649e+01, 1.69478885e+01,\n        1.01891176e+01, 3.51005864e+00, 7.57853677e-01, 7.57853677e-01],\n       [1.55426128e-01, 1.55426128e-01, 2.32520610e+00, 7.08096943e+00,\n        1.31796745e+01, 2.15996854e+01, 3.52594078e+01, 5.02445129e+01,\n        6.31293563e+01, 8.03947410e+01, 1.03623517e+02, 1.20217540e+02,\n        1.29644860e+02, 1.37108833e+02, 1.40174662e+02, 1.39386131e+02,\n        1.29121540e+02, 1.15569871e+02, 1.00161949e+02, 8.08438948e+01,\n        5.32014822e+01, 3.46068089e+01, 2.26136374e+01, 1.63454609e+01,\n        9.58669002e+00, 2.90763110e+00, 1.55426128e-01, 1.55426128e-01],\n       [6.39509237e-01, 6.39509237e-01, 2.80928920e+00, 7.56505254e+00,\n        1.36637576e+01, 2.20837685e+01, 3.57434909e+01, 5.07285960e+01,\n        6.36134394e+01, 8.08788241e+01, 1.04107600e+02, 1.20701623e+02,\n        1.30128943e+02, 1.37592916e+02, 1.40658745e+02, 1.39870214e+02,\n        1.29605623e+02, 1.16053954e+02, 1.00646033e+02, 8.13279779e+01,\n        5.36855653e+01, 3.50908920e+01, 2.30977205e+01, 1.68295440e+01,\n        1.00707731e+01, 3.39171420e+00, 6.39509237e-01, 6.39509237e-01],\n       [6.73611531e-01, 6.73611531e-01, 2.84339150e+00, 7.59915483e+00,\n        1.36978599e+01, 2.21178708e+01, 3.57775932e+01, 5.07626983e+01,\n        6.36475417e+01, 8.09129264e+01, 1.04141702e+02, 1.20735726e+02,\n        1.30163045e+02, 1.37627019e+02, 1.40692847e+02, 1.39904316e+02,\n        1.29639725e+02, 1.16088056e+02, 1.00680135e+02, 8.13620802e+01,\n        5.37196676e+01, 3.51249943e+01, 2.31318228e+01, 1.68636463e+01,\n        1.01048754e+01, 3.42581650e+00, 6.73611531e-01, 6.73611531e-01]])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0, :, :, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "(64, 6, 28, 28)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = ActivationLayer()\n",
    "o1 = a1.forward(o)\n",
    "o1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 2 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [43]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m m1 \u001B[38;5;241m=\u001B[39m MaxPoolingLayerBatch(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m o2 \u001B[38;5;241m=\u001B[39m \u001B[43mm1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mo1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m o2\u001B[38;5;241m.\u001B[39mshape\n",
      "Input \u001B[0;32mIn [19]\u001B[0m, in \u001B[0;36mMaxPoolingLayerBatch.forward\u001B[0;34m(self, image)\u001B[0m\n\u001B[1;32m     18\u001B[0m image_x \u001B[38;5;241m=\u001B[39m out_x \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m image_x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfilter_dimension \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m input_dimensions[\u001B[38;5;241m1\u001B[39m]:\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;66;03m# image_slice = image[i, image_x: image_x+self.filter_dimension, image_y: image_y+self.filter_dimension, :]\u001B[39;00m\n\u001B[0;32m---> 21\u001B[0m     output[i, out_x, out_y, :] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmax(image[i, image_x: image_x\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfilter_dimension, image_y: image_y\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfilter_dimension, :], axis\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;66;03m# self.index_tracker[i, out_x, out_y, :] = np.argmax(image[i, image_x: image_x+self.filter_dimension, image_y: image_y+self.filter_dimension, :], axis=(0, 1))\u001B[39;00m\n\u001B[1;32m     23\u001B[0m     image_x \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride\n",
      "\u001B[0;31mIndexError\u001B[0m: index 3 is out of bounds for axis 2 with size 3"
     ]
    }
   ],
   "source": [
    "m1 = MaxPoolingLayerBatch(2, 2)\n",
    "o2 = m1.forward(o1)\n",
    "o2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = np.arange(1,25).reshape(2, 3, 4)\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = np.max(x, axis=(1, 2))\n",
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}