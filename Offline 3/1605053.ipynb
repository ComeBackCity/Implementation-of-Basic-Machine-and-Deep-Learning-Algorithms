{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importing Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pickle\n",
    "from mlxtend.data import loadlocal_mnist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting Numpy Seed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Processing MNIST Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def process_mnist_data() -> (np.ndarray, np.ndarray, np.ndarray, np.ndarray):\n",
    "    mnist_path = './MNIST/'\n",
    "    train_images, train_labels = loadlocal_mnist(\n",
    "        images_path = mnist_path + './train-images.idx3-ubyte',\n",
    "        labels_path = mnist_path + './train-labels.idx1-ubyte'\n",
    "    )\n",
    "    test_images, test_labels = loadlocal_mnist(\n",
    "        images_path = mnist_path + './t10k-images.idx3-ubyte',\n",
    "        labels_path = mnist_path + './t10k-labels.idx1-ubyte'\n",
    "    )\n",
    "    return train_images, train_labels, test_images, test_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Processing CIFAR-10 Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        data_dict = pickle.load(fo, encoding='bytes')\n",
    "    return data_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def process_cifar_dataset() -> (np.ndarray, np.ndarray, np.ndarray, np.ndarray):\n",
    "    cifar_path = './cifar-10-python/cifar-10-batches-py'\n",
    "    data_batch = unpickle(cifar_path + '/data_batch_1')\n",
    "    train_images, train_labels = data_batch[b'data'], np.array(data_batch[b'labels'])\n",
    "    for i in range(2,6):\n",
    "        data_batch = unpickle(cifar_path + '/data_batch_' + str(i))\n",
    "        train_images = np.concatenate((train_images, data_batch[b'data']), axis=0)\n",
    "        train_labels = np.concatenate((train_labels, np.array(data_batch[b'labels'])), axis=0)\n",
    "    test_batch = unpickle(cifar_path + '/test_batch')\n",
    "    test_images, test_labels = test_batch[b'data'], np.array(test_batch[b'labels'])\n",
    "    return train_images, train_labels, test_images, test_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Processing Toy Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def process_toy_dataset():\n",
    "    toy_dataset_path = './Toy Dataset/'\n",
    "    a = np.loadtxt(toy_dataset_path + 'trainNN.txt')\n",
    "    b = np.loadtxt(toy_dataset_path + 'testNN.txt')\n",
    "    train_x, train_y, test_x, test_y = a[:, 0:4], a[:, -1], b[:, 0:4], b[:, -1]\n",
    "    return train_x, train_y, test_x, test_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 9.21323266, 11.82445528],\n       [16.69098092, 19.56967227]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_toy, y_train_toy, x_test_toy, y_test_toy = process_toy_dataset()\n",
    "toy_batch_1 = x_train_toy[0:50].reshape(50, 2, 2, 1)\n",
    "toy_batch_1[0, :, :, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 0, 0, 0],\n       [0, 1, 0, 0],\n       [0, 0, 0, 1],\n       [0, 0, 1, 0],\n       [0, 0, 0, 1],\n       [0, 1, 0, 0],\n       [1, 0, 0, 0],\n       [0, 0, 1, 0],\n       [1, 0, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 1, 0, 0],\n       [1, 0, 0, 0],\n       [0, 1, 0, 0],\n       [1, 0, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [1, 0, 0, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [1, 0, 0, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [0, 1, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 0, 1, 0],\n       [0, 1, 0, 0],\n       [1, 0, 0, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [0, 0, 0, 1],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 0, 1],\n       [0, 1, 0, 0],\n       [0, 0, 0, 1],\n       [0, 0, 1, 0]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_binarizer = LabelBinarizer()\n",
    "label_binarizer.fit(range(1,5))\n",
    "toy_labels_1 = label_binarizer.transform(y_train_toy[0:50].T)\n",
    "toy_labels_1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parsing Input Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def parse_input_model():\n",
    "    path = './input_model.txt'\n",
    "    model = []\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            tokens = line.split()\n",
    "            if tokens[0] == 'Conv':\n",
    "                model.append(ConvolutionLayer(int(tokens[1]), int(tokens[2]), int(tokens[3]), int(tokens[4])))\n",
    "            if tokens[0] == 'ReLU':\n",
    "                model.append(ActivationLayer())\n",
    "            if tokens[0] == 'Pool':\n",
    "                model.append(MaxPoolingLayer(int(tokens[1]), int(tokens[2])))\n",
    "            if tokens[0] == 'FC':\n",
    "                model.append(FlatteningLayer())\n",
    "                model.append(FullyConnectedLayer(int(tokens[1])))\n",
    "            if tokens[0] == 'Softmax':\n",
    "                model.append(SoftmaxLayer())\n",
    "        return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ReLU Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def relu(matrix:np.ndarray) -> np.ndarray:\n",
    "    return matrix * (matrix > 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convolution Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class ConvolutionLayer:\n",
    "    def __init__(self, output_channel_count: int, filter_dimension: int, stride: int, padding: int):\n",
    "        self.output_channel_count = output_channel_count\n",
    "        self.filter_dimension = filter_dimension\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self, input_image: np.ndarray) -> np.ndarray:\n",
    "        input_dimentions = input_image.shape[0]\n",
    "        output_dimentions = (input_dimentions - self.filter_dimension + 2 * self.padding) // self.stride + 1\n",
    "        input_shape = input_image.shape\n",
    "\n",
    "        filters = np.random.rand(\n",
    "            self.output_channel_count,\n",
    "            self.filter_dimension,\n",
    "            self.filter_dimension,\n",
    "            input_shape[2]\n",
    "        )\n",
    "\n",
    "        bias = np.random.rand(self.output_channel_count)\n",
    "\n",
    "        padded_image = np.pad(input_image, [(self.padding,self.padding), (self.padding,self.padding), (0,0)], mode='constant') * 1.0\n",
    "        padded_image /= 255.0\n",
    "        padded_dimensions = padded_image.shape\n",
    "\n",
    "        output = np.zeros((output_dimentions, output_dimentions, self.output_channel_count))\n",
    "\n",
    "        image_y = out_y = 0\n",
    "        while image_y + self.filter_dimension <= padded_dimensions[1]:\n",
    "            image_x = out_x = 0\n",
    "            while image_x + self.filter_dimension <= padded_dimensions[0]:\n",
    "                image_slice = padded_image[image_x:image_x+self.filter_dimension, image_y:image_y+self.filter_dimension, :]\n",
    "                output[out_x, out_y, :] = np.sum(image_slice * filters) + bias\n",
    "                image_x += self.stride\n",
    "                out_x += 1\n",
    "            image_y += self.stride\n",
    "            out_y += 1\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class ConvolutionLayerBatch:\n",
    "    def __init__(self, output_channel_count: int, filter_dimension: int, stride: int, padding: int):\n",
    "        self.output_channel_count = output_channel_count\n",
    "        self.filter_dimension = filter_dimension\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self, input_batch: np.ndarray) -> np.ndarray:\n",
    "        input_dimentions = input_batch.shape\n",
    "        output_dimentions = (input_dimentions[1] - self.filter_dimension + 2 * self.padding) // self.stride + 1\n",
    "        input_shape = input_batch.shape\n",
    "\n",
    "        filters = np.random.rand(\n",
    "            self.output_channel_count,\n",
    "            self.filter_dimension,\n",
    "            self.filter_dimension,\n",
    "            input_shape[3],\n",
    "        )\n",
    "\n",
    "        bias = np.random.rand(self.output_channel_count)\n",
    "\n",
    "        padded_image = np.pad(input_batch, [(0, 0), (self.padding,self.padding), (self.padding,self.padding), (0,0)], mode='constant') * 1.0\n",
    "        padded_image /= 255.0\n",
    "        padded_dimensions = padded_image.shape\n",
    "\n",
    "        output = np.zeros((input_dimentions[0], output_dimentions, output_dimentions, self.output_channel_count))\n",
    "\n",
    "        for i in range(input_dimentions[0]):\n",
    "            image_y = out_y = 0\n",
    "            while image_y + self.filter_dimension <= padded_dimensions[2]:\n",
    "                image_x = out_x = 0\n",
    "                while image_x + self.filter_dimension <= padded_dimensions[1]:\n",
    "                    image_slice = padded_image[i, image_x:image_x+self.filter_dimension, image_y:image_y+self.filter_dimension, :]\n",
    "                    output[i, out_x, out_y, :] = np.sum(image_slice * filters) + bias\n",
    "                    image_x += self.stride\n",
    "                    out_x += 1\n",
    "                image_y += self.stride\n",
    "                out_y += 1\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 3, 3, 3)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_conv = ConvolutionLayerBatch(3, 2, 2, 2)\n",
    "test_conv_out = test_conv.forward(toy_batch_1)\n",
    "test_conv_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.00394827, 0.00394827, 0.00394827],\n       [0.00394827, 0.35971887, 0.00394827],\n       [0.00394827, 0.00394827, 0.00394827]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_conv_out[0, :, :, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Activation Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class ActivationLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, input_matrix: np.ndarray) -> np.ndarray:\n",
    "        return relu(input_matrix)\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 3, 3, 3)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_activation = ActivationLayer()\n",
    "test_activation_out = test_activation.forward(test_conv_out)\n",
    "test_activation_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.00394827, 0.00394827, 0.00394827],\n       [0.00394827, 0.35971887, 0.00394827],\n       [0.00394827, 0.00394827, 0.00394827]])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_activation_out[0, :, :, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Max Pooling Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class MaxPoolingLayer:\n",
    "    def __init__(self, filter_dimension: int, stride: int):\n",
    "        self.filter_dimension = filter_dimension\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, image: np.ndarray) -> np.ndarray:\n",
    "        input_dimensions = image.shape\n",
    "        output_dimension = (input_dimensions[0] - self.filter_dimension) // self.stride + 1\n",
    "\n",
    "        output = np.zeros((output_dimension, output_dimension, input_dimensions[2]))\n",
    "\n",
    "        image_y = out_y = 0\n",
    "        while image_y + self.filter_dimension <= input_dimensions[1]:\n",
    "            image_x = out_x = 0\n",
    "            while image_x + self.filter_dimension <= input_dimensions[0]:\n",
    "                image_slice = image[image_x: image_x+self.filter_dimension, image_y: image_y+self.filter_dimension, :]\n",
    "                output[out_x, out_y, :] = np.max(image_slice, axis=(0, 1))\n",
    "                image_x += self.stride\n",
    "                out_x += 1\n",
    "            image_y += self.stride\n",
    "            out_y += 1\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class MaxPoolingLayerBatch:\n",
    "    def __init__(self, filter_dimension: int, stride: int):\n",
    "        self.filter_dimension = filter_dimension\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, image: np.ndarray) -> np.ndarray:\n",
    "        input_dimensions = image.shape\n",
    "        output_dimension = (input_dimensions[1] - self.filter_dimension) // self.stride + 1\n",
    "\n",
    "        output = np.zeros((input_dimensions[0], output_dimension, output_dimension, input_dimensions[3]))\n",
    "\n",
    "        for i in range(input_dimensions[0]):\n",
    "            image_y = out_y = 0\n",
    "            while image_y + self.filter_dimension <= input_dimensions[2]:\n",
    "                image_x = out_x = 0\n",
    "                while image_x + self.filter_dimension <= input_dimensions[1]:\n",
    "                    image_slice = image[i, image_x: image_x+self.filter_dimension, image_y: image_y+self.filter_dimension, :]\n",
    "                    output[i, out_x, out_y, :] = np.max(image_slice, axis=(0, 1))\n",
    "                    image_x += self.stride\n",
    "                    out_x += 1\n",
    "                image_y += self.stride\n",
    "                out_y += 1\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 2, 2, 3)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_maxpool = MaxPoolingLayerBatch(2, 1)\n",
    "test_maxpool_out = test_maxpool.forward(test_activation_out)\n",
    "test_maxpool_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.35971887, 0.35971887],\n       [0.35971887, 0.35971887]])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_maxpool_out[0, :, :, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Flattening Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "class FlatteningLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, image: np.ndarray) -> np.ndarray:\n",
    "        return image.flatten().reshape(-1, 1)\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class FlatteningLayerBatch:\n",
    "    def __init__(self):\n",
    "        self.input_shape = None\n",
    "\n",
    "    def forward(self, input_batch: np.ndarray) -> np.ndarray:\n",
    "        input_shape = input_batch.shape\n",
    "        self.input_shape = input_shape\n",
    "        return input_batch.reshape((input_shape[0], -1))\n",
    "\n",
    "    def backward(self, dh_flattened: np.ndarray) -> np.ndarray:\n",
    "        return dh_flattened.reshape(self.input_shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 12)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_flattening = FlatteningLayerBatch()\n",
    "test_flattening_out = test_flattening.forward(test_maxpool_out)\n",
    "test_flattening_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.35971887, 0.86796287, 1.16839157, 0.35971887, 0.86796287,\n        1.16839157, 0.35971887, 0.86796287, 1.16839157, 0.35971887,\n        0.86796287, 1.16839157],\n       [0.70140189, 1.20964589, 1.51007459, 0.70140189, 1.20964589,\n        1.51007459, 0.70140189, 1.20964589, 1.51007459, 0.70140189,\n        1.20964589, 1.51007459],\n       [1.39542218, 1.90366618, 2.20409488, 1.39542218, 1.90366618,\n        2.20409488, 1.39542218, 1.90366618, 2.20409488, 1.39542218,\n        1.90366618, 2.20409488],\n       [1.04935128, 1.55759528, 1.85802398, 1.04935128, 1.55759528,\n        1.85802398, 1.04935128, 1.55759528, 1.85802398, 1.04935128,\n        1.55759528, 1.85802398],\n       [1.39503394, 1.90327794, 2.20370664, 1.39503394, 1.90327794,\n        2.20370664, 1.39503394, 1.90327794, 2.20370664, 1.39503394,\n        1.90327794, 2.20370664],\n       [0.69735835, 1.20560235, 1.50603105, 0.69735835, 1.20560235,\n        1.50603105, 0.69735835, 1.20560235, 1.50603105, 0.69735835,\n        1.20560235, 1.50603105],\n       [0.34775693, 0.85600092, 1.15642962, 0.34775693, 0.85600092,\n        1.15642962, 0.34775693, 0.85600092, 1.15642962, 0.34775693,\n        0.85600092, 1.15642962],\n       [1.05156466, 1.55980866, 1.86023735, 1.05156466, 1.55980866,\n        1.86023735, 1.05156466, 1.55980866, 1.86023735, 1.05156466,\n        1.55980866, 1.86023735],\n       [0.35026826, 0.85851226, 1.15894096, 0.35026826, 0.85851226,\n        1.15894096, 0.35026826, 0.85851226, 1.15894096, 0.35026826,\n        0.85851226, 1.15894096],\n       [1.05074442, 1.55898841, 1.85941711, 1.05074442, 1.55898841,\n        1.85941711, 1.05074442, 1.55898841, 1.85941711, 1.05074442,\n        1.55898841, 1.85941711],\n       [1.04429834, 1.55254233, 1.85297103, 1.04429834, 1.55254233,\n        1.85297103, 1.04429834, 1.55254233, 1.85297103, 1.04429834,\n        1.55254233, 1.85297103],\n       [1.05378054, 1.56202454, 1.86245323, 1.05378054, 1.56202454,\n        1.86245323, 1.05378054, 1.56202454, 1.86245323, 1.05378054,\n        1.56202454, 1.86245323],\n       [1.05341057, 1.56165456, 1.86208326, 1.05341057, 1.56165456,\n        1.86208326, 1.05341057, 1.56165456, 1.86208326, 1.05341057,\n        1.56165456, 1.86208326],\n       [0.69129175, 1.19953575, 1.49996445, 0.69129175, 1.19953575,\n        1.49996445, 0.69129175, 1.19953575, 1.49996445, 0.69129175,\n        1.19953575, 1.49996445],\n       [0.34133865, 0.84958264, 1.15001134, 0.34133865, 0.84958264,\n        1.15001134, 0.34133865, 0.84958264, 1.15001134, 0.34133865,\n        0.84958264, 1.15001134],\n       [0.70070918, 1.20895318, 1.50938188, 0.70070918, 1.20895318,\n        1.50938188, 0.70070918, 1.20895318, 1.50938188, 0.70070918,\n        1.20895318, 1.50938188],\n       [0.35498297, 0.86322697, 1.16365566, 0.35498297, 0.86322697,\n        1.16365566, 0.35498297, 0.86322697, 1.16365566, 0.35498297,\n        0.86322697, 1.16365566],\n       [1.05703195, 1.56527594, 1.86570464, 1.05703195, 1.56527594,\n        1.86570464, 1.05703195, 1.56527594, 1.86570464, 1.05703195,\n        1.56527594, 1.86570464],\n       [1.38712744, 1.89537144, 2.19580014, 1.38712744, 1.89537144,\n        2.19580014, 1.38712744, 1.89537144, 2.19580014, 1.38712744,\n        1.89537144, 2.19580014],\n       [0.3447199 , 0.8529639 , 1.1533926 , 0.3447199 , 0.8529639 ,\n        1.1533926 , 0.3447199 , 0.8529639 , 1.1533926 , 0.3447199 ,\n        0.8529639 , 1.1533926 ],\n       [0.35700214, 0.86524614, 1.16567484, 0.35700214, 0.86524614,\n        1.16567484, 0.35700214, 0.86524614, 1.16567484, 0.35700214,\n        0.86524614, 1.16567484],\n       [1.4009304 , 1.9091744 , 2.2096031 , 1.4009304 , 1.9091744 ,\n        2.2096031 , 1.4009304 , 1.9091744 , 2.2096031 , 1.4009304 ,\n        1.9091744 , 2.2096031 ],\n       [0.3572811 , 0.8655251 , 1.1659538 , 0.3572811 , 0.8655251 ,\n        1.1659538 , 0.3572811 , 0.8655251 , 1.1659538 , 0.3572811 ,\n        0.8655251 , 1.1659538 ],\n       [0.35907415, 0.86731814, 1.16774684, 0.35907415, 0.86731814,\n        1.16774684, 0.35907415, 0.86731814, 1.16774684, 0.35907415,\n        0.86731814, 1.16774684],\n       [1.39963453, 1.90787853, 2.20830722, 1.39963453, 1.90787853,\n        2.20830722, 1.39963453, 1.90787853, 2.20830722, 1.39963453,\n        1.90787853, 2.20830722],\n       [0.35140571, 0.85964971, 1.16007841, 0.35140571, 0.85964971,\n        1.16007841, 0.35140571, 0.85964971, 1.16007841, 0.35140571,\n        0.85964971, 1.16007841],\n       [1.40224769, 1.91049168, 2.21092038, 1.40224769, 1.91049168,\n        2.21092038, 1.40224769, 1.91049168, 2.21092038, 1.40224769,\n        1.91049168, 2.21092038],\n       [0.3458202 , 0.85406419, 1.15449289, 0.3458202 , 0.85406419,\n        1.15449289, 0.3458202 , 0.85406419, 1.15449289, 0.3458202 ,\n        0.85406419, 1.15449289],\n       [0.69902227, 1.20726626, 1.50769496, 0.69902227, 1.20726626,\n        1.50769496, 0.69902227, 1.20726626, 1.50769496, 0.69902227,\n        1.20726626, 1.50769496],\n       [1.05393304, 1.56217704, 1.86260574, 1.05393304, 1.56217704,\n        1.86260574, 1.05393304, 1.56217704, 1.86260574, 1.05393304,\n        1.56217704, 1.86260574],\n       [1.05085317, 1.55909716, 1.85952586, 1.05085317, 1.55909716,\n        1.85952586, 1.05085317, 1.55909716, 1.85952586, 1.05085317,\n        1.55909716, 1.85952586],\n       [1.05761478, 1.56585878, 1.86628748, 1.05761478, 1.56585878,\n        1.86628748, 1.05761478, 1.56585878, 1.86628748, 1.05761478,\n        1.56585878, 1.86628748],\n       [1.05768824, 1.56593223, 1.86636093, 1.05768824, 1.56593223,\n        1.86636093, 1.05768824, 1.56593223, 1.86636093, 1.05768824,\n        1.56593223, 1.86636093],\n       [0.71626414, 1.22450814, 1.52493684, 0.71626414, 1.22450814,\n        1.52493684, 0.71626414, 1.22450814, 1.52493684, 0.71626414,\n        1.22450814, 1.52493684],\n       [0.34597003, 0.85421403, 1.15464273, 0.34597003, 0.85421403,\n        1.15464273, 0.34597003, 0.85421403, 1.15464273, 0.34597003,\n        0.85421403, 1.15464273],\n       [1.39836519, 1.90660918, 2.20703788, 1.39836519, 1.90660918,\n        2.20703788, 1.39836519, 1.90660918, 2.20703788, 1.39836519,\n        1.90660918, 2.20703788],\n       [0.35530965, 0.86355364, 1.16398234, 0.35530965, 0.86355364,\n        1.16398234, 0.35530965, 0.86355364, 1.16398234, 0.35530965,\n        0.86355364, 1.16398234],\n       [1.05577213, 1.56401613, 1.86444482, 1.05577213, 1.56401613,\n        1.86444482, 1.05577213, 1.56401613, 1.86444482, 1.05577213,\n        1.56401613, 1.86444482],\n       [1.41059408, 1.91883808, 2.21926678, 1.41059408, 1.91883808,\n        2.21926678, 1.41059408, 1.91883808, 2.21926678, 1.41059408,\n        1.91883808, 2.21926678],\n       [0.3663733 , 0.8746173 , 1.175046  , 0.3663733 , 0.8746173 ,\n        1.175046  , 0.3663733 , 0.8746173 , 1.175046  , 0.3663733 ,\n        0.8746173 , 1.175046  ],\n       [1.39697907, 1.90522307, 2.20565176, 1.39697907, 1.90522307,\n        2.20565176, 1.39697907, 1.90522307, 2.20565176, 1.39697907,\n        1.90522307, 2.20565176],\n       [0.35174898, 0.85999298, 1.16042168, 0.35174898, 0.85999298,\n        1.16042168, 0.35174898, 0.85999298, 1.16042168, 0.35174898,\n        0.85999298, 1.16042168],\n       [1.39680758, 1.90505158, 2.20548028, 1.39680758, 1.90505158,\n        2.20548028, 1.39680758, 1.90505158, 2.20548028, 1.39680758,\n        1.90505158, 2.20548028],\n       [1.4003178 , 1.9085618 , 2.20899049, 1.4003178 , 1.9085618 ,\n        2.20899049, 1.4003178 , 1.9085618 , 2.20899049, 1.4003178 ,\n        1.9085618 , 2.20899049],\n       [0.36380378, 0.87204777, 1.17247647, 0.36380378, 0.87204777,\n        1.17247647, 0.36380378, 0.87204777, 1.17247647, 0.36380378,\n        0.87204777, 1.17247647],\n       [1.05147703, 1.55972102, 1.86014972, 1.05147703, 1.55972102,\n        1.86014972, 1.05147703, 1.55972102, 1.86014972, 1.05147703,\n        1.55972102, 1.86014972],\n       [1.40155833, 1.90980233, 2.21023103, 1.40155833, 1.90980233,\n        2.21023103, 1.40155833, 1.90980233, 2.21023103, 1.40155833,\n        1.90980233, 2.21023103],\n       [0.70173687, 1.20998087, 1.51040956, 0.70173687, 1.20998087,\n        1.51040956, 0.70173687, 1.20998087, 1.51040956, 0.70173687,\n        1.20998087, 1.51040956],\n       [1.39363284, 1.90187684, 2.20230554, 1.39363284, 1.90187684,\n        2.20230554, 1.39363284, 1.90187684, 2.20230554, 1.39363284,\n        1.90187684, 2.20230554],\n       [1.040373  , 1.548617  , 1.8490457 , 1.040373  , 1.548617  ,\n        1.8490457 , 1.040373  , 1.548617  , 1.8490457 , 1.040373  ,\n        1.548617  , 1.8490457 ]])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_flattening_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fully Connected Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "class FullyConnectedLayer:\n",
    "    def __init__(self, output_dimension: int):\n",
    "        self.output_dimension = output_dimension\n",
    "\n",
    "    def forward(self, flattened_input: np.ndarray) -> np.ndarray:\n",
    "        weights = np.random.rand(flattened_input.shape[0], self.output_dimension)\n",
    "        bias = np.random.rand(self.output_dimension, 1)\n",
    "\n",
    "        return weights.T @ flattened_input + bias\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "class FullyConnectedLayerBatch:\n",
    "    def __init__(self, output_dimension: int):\n",
    "        self.output_dimension = output_dimension\n",
    "        self.input_matrix = None\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def forward(self, flattened_input: np.ndarray) -> np.ndarray:\n",
    "        if not self.weights:\n",
    "            self.weights = np.random.rand(flattened_input.shape[1], self.output_dimension)\n",
    "        if not self.bias:\n",
    "            self.bias = np.random.rand(1, self.output_dimension)\n",
    "        self.input_matrix = flattened_input\n",
    "\n",
    "        return flattened_input @ self.weights + self.bias\n",
    "\n",
    "    def backward(self, d_theta: np.ndarray, learning_rate: int) -> np.ndarray:\n",
    "        n = d_theta.shape[0]\n",
    "        dw = self.input_matrix.T @ d_theta\n",
    "        db = np.sum(d_theta, axis=0, keepdims=True)\n",
    "        dh = d_theta @ self.weights.T\n",
    "        self.weights = self.weights - learning_rate * dw / n\n",
    "        self.bias = self.bias - learning_rate * db / n\n",
    "\n",
    "        return dh"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 4)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fc = FullyConnectedLayerBatch(4)\n",
    "test_fc_out = test_fc.forward(test_flattening_out)\n",
    "test_fc_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 6.3557987 ,  5.17494228,  5.2019971 ,  4.14542299],\n       [ 8.74515052,  7.57014592,  7.20639698,  6.01910829],\n       [13.59835809, 12.43523958, 11.27769723,  9.82490349],\n       [11.17832234, 10.00927687,  9.24755695,  7.92715642],\n       [13.59564318, 12.43251802, 11.27541972,  9.82277451],\n       [ 8.71687449,  7.54180063,  7.18267654,  5.99693475],\n       [ 6.27215014,  5.09108886,  5.13182528,  4.07982734],\n       [11.19380024, 10.02479268,  9.26054119,  7.9392939 ],\n       [ 6.28971165,  5.10869338,  5.14655743,  4.09359875],\n       [11.18806437, 10.01904276,  9.25572943,  7.93479594],\n       [11.14298764,  9.97385563,  9.21791507,  7.8994476 ],\n       [11.20929564, 10.04032602,  9.2735401 ,  7.9514451 ],\n       [11.20670846, 10.03773251,  9.27136975,  7.94941629],\n       [ 8.67445141,  7.49927366,  7.14708831,  5.96366736],\n       [ 6.22726781,  5.04609661,  5.09417401,  4.04463145],\n       [ 8.74030647,  7.56529001,  7.20233337,  6.01530968],\n       [ 6.32268105,  5.14174353,  5.17421509,  4.11945274],\n       [11.23203237, 10.06311844,  9.29261368,  7.96927483],\n       [13.5403539 , 12.37709333, 11.22903818,  9.77941768],\n       [ 6.25091258,  5.06979929,  5.11400934,  4.06317324],\n       [ 6.3368009 ,  5.15589796,  5.18606006,  4.13052527],\n       [13.63687648, 12.47385231, 11.31000986,  9.8551089 ],\n       [ 6.33875164,  5.15785348,  5.18769652,  4.13205501],\n       [ 6.3512902 ,  5.17042275,  5.19821498,  4.14188751],\n       [13.62781458, 12.46476821, 11.30240794,  9.84800272],\n       [ 6.29766571,  5.11666692,  5.15323   ,  4.09983618],\n       [13.6460881 , 12.48308648, 11.31773738,  9.86233248],\n       [ 6.25860679,  5.07751234,  5.12046392,  4.0692069 ],\n       [ 8.72851005,  7.55346469,  7.19243748,  6.00605914],\n       [11.21036208, 10.04139508,  9.27443472,  7.95228139],\n       [11.18882485, 10.0198051 ,  9.25636739,  7.93539229],\n       [11.2361081 , 10.06720415,  9.29603276,  7.97247094],\n       [11.23662174, 10.06771905,  9.29646365,  7.97287372],\n       [ 8.8490806 ,  7.67433053,  7.29358273,  6.10060833],\n       [ 6.25965457,  5.07856269,  5.12134289,  4.07002855],\n       [13.6189382 , 12.4558701 , 11.29496165,  9.84104203],\n       [ 6.32496548,  5.14403355,  5.17613146,  4.12124415],\n       [11.22322261, 10.0542871 ,  9.28522327,  7.96236638],\n       [13.70445353, 12.54159486, 11.36669948,  9.90810157],\n       [ 6.40233242,  5.22158997,  5.24103371,  4.18191387],\n       [13.60924523, 12.44615339, 11.28683033,  9.83344099],\n       [ 6.30006613,  5.11907322,  5.15524369,  4.10171854],\n       [13.60804604, 12.44495126, 11.28582434,  9.8325006 ],\n       [13.63259261, 12.46955795, 11.30641617,  9.85174957],\n       [ 6.38436399,  5.20357754,  5.2259602 ,  4.16782336],\n       [11.19318742, 10.02417836,  9.2600271 ,  7.93881334],\n       [13.64126754, 12.47825412, 11.31369347,  9.85855228],\n       [ 8.74749296,  7.5724941 ,  7.20836203,  6.02094519],\n       [13.58584542, 12.42269627, 11.26720049,  9.81509129],\n       [11.1155382 ,  9.94633896,  9.19488805,  7.87792226]])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fc_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Softmax Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "class SoftmaxLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, input_matrix: np.ndarray) -> np.ndarray:\n",
    "        exp = np.exp(input_matrix)\n",
    "        exp /= np.sum(exp)\n",
    "        return exp\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "class SoftmaxLayerBatch:\n",
    "    def __init__(self):\n",
    "        self.y_hat = None\n",
    "\n",
    "    def forward(self, input_matrix: np.ndarray) -> np.ndarray:\n",
    "        exp = np.exp(input_matrix)\n",
    "        exp_sum = np.sum(exp, axis=1).reshape(-1, 1)\n",
    "        exp /= exp_sum\n",
    "        self.y_hat = exp\n",
    "        return exp\n",
    "\n",
    "    def backward(self, y: np.ndarray) -> np.ndarray:\n",
    "        return self.y_hat - y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 4)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_softmax = SoftmaxLayerBatch()\n",
    "test_softmax_out = test_softmax.forward(test_fc_out)\n",
    "test_softmax_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.57733038, 0.17724949, 0.1821104 , 0.06330973],\n       [0.62934881, 0.19435396, 0.13508877, 0.04120845],\n       [0.69750021, 0.21797586, 0.06850056, 0.01602337],\n       [0.66915167, 0.20788089, 0.09705185, 0.02591559],\n       [0.69747377, 0.21796614, 0.06852793, 0.01603215],\n       [0.6288108 , 0.19417437, 0.13558957, 0.04142525],\n       [0.57526641, 0.17657964, 0.18392138, 0.06423257],\n       [0.66936604, 0.20795537, 0.09684115, 0.02583744],\n       [0.57570108, 0.17672066, 0.18354032, 0.06403794],\n       [0.66928665, 0.20792779, 0.09691919, 0.02586638],\n       [0.66866056, 0.20771034, 0.09753429, 0.02609481],\n       [0.66958019, 0.2080298 , 0.09663059, 0.02575942],\n       [0.66954447, 0.20801738, 0.09666572, 0.02577243],\n       [0.62800021, 0.19390391, 0.13634349, 0.04175238],\n       [0.57415223, 0.17621826, 0.18489734, 0.06473216],\n       [0.62925677, 0.19432324, 0.13517447, 0.04124552],\n       [0.57651518, 0.17698485, 0.18282615, 0.06367381],\n       [0.66989359, 0.20813875, 0.09632233, 0.02564533],\n       [0.69693289, 0.21776762, 0.06908747, 0.01621202],\n       [0.57473978, 0.17640881, 0.18438282, 0.06446858],\n       [0.57686306, 0.17709777, 0.18252079, 0.06351838],\n       [0.69787418, 0.2181133 , 0.06811328, 0.01589924],\n       [0.57691109, 0.17711336, 0.18247862, 0.06349693],\n       [0.57721956, 0.17721351, 0.18220774, 0.06335919],\n       [0.6977864 , 0.21808102, 0.06820422, 0.01592836],\n       [0.57589772, 0.17678447, 0.18336787, 0.06394994],\n       [0.69796329, 0.21814607, 0.06802095, 0.01586969],\n       [0.5749307 , 0.17647074, 0.18421557, 0.064383  ],\n       [0.62903241, 0.19424834, 0.13538333, 0.04133592],\n       [0.66959491, 0.20803491, 0.09661612, 0.02575406],\n       [0.66929718, 0.20793144, 0.09690884, 0.02586254],\n       [0.66994966, 0.20815826, 0.09626716, 0.02562492],\n       [0.66995673, 0.20816071, 0.09626021, 0.02562235],\n       [0.63131072, 0.19500947, 0.13325976, 0.04042005],\n       [0.57495668, 0.17647917, 0.1841928 , 0.06437135],\n       [0.69770029, 0.21804937, 0.0682934 , 0.01595693],\n       [0.5765715 , 0.17700313, 0.18277673, 0.06364864],\n       [0.66977227, 0.20809657, 0.09644168, 0.02568948],\n       [0.69852496, 0.21835283, 0.06743855, 0.01568365],\n       [0.57847149, 0.17762007, 0.18110746, 0.06280098],\n       [0.69760614, 0.21801477, 0.0683909 , 0.01598819],\n       [0.57595704, 0.17680371, 0.18331585, 0.0639234 ],\n       [0.69759448, 0.21801049, 0.06840297, 0.01599206],\n       [0.6978327 , 0.21809805, 0.06815626, 0.015913  ],\n       [0.57803147, 0.17747715, 0.18149435, 0.06299704],\n       [0.66935756, 0.20795242, 0.09684948, 0.02584053],\n       [0.69791667, 0.21812893, 0.06806926, 0.01588515],\n       [0.6293933 , 0.19436882, 0.13504734, 0.04119054],\n       [0.69737825, 0.21793106, 0.06862679, 0.01606389],\n       [0.66827738, 0.20757736, 0.09791044, 0.02623482]])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_softmax_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Backprop Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Loss Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    labels = y_true * np.log(y_pred) * -1.0\n",
    "    return np.sum(labels) / y_true.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "2.135417505373132"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function_test = loss_function(toy_labels_1, test_softmax_out)\n",
    "loss_function_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Softmax Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.42266962,  0.17724949,  0.1821104 ,  0.06330973],\n       [ 0.62934881, -0.80564604,  0.13508877,  0.04120845],\n       [ 0.69750021,  0.21797586,  0.06850056, -0.98397663],\n       [ 0.66915167,  0.20788089, -0.90294815,  0.02591559],\n       [ 0.69747377,  0.21796614,  0.06852793, -0.98396785],\n       [ 0.6288108 , -0.80582563,  0.13558957,  0.04142525],\n       [-0.42473359,  0.17657964,  0.18392138,  0.06423257],\n       [ 0.66936604,  0.20795537, -0.90315885,  0.02583744],\n       [-0.42429892,  0.17672066,  0.18354032,  0.06403794],\n       [ 0.66928665,  0.20792779, -0.90308081,  0.02586638],\n       [ 0.66866056,  0.20771034, -0.90246571,  0.02609481],\n       [ 0.66958019,  0.2080298 , -0.90336941,  0.02575942],\n       [ 0.66954447,  0.20801738, -0.90333428,  0.02577243],\n       [ 0.62800021, -0.80609609,  0.13634349,  0.04175238],\n       [-0.42584777,  0.17621826,  0.18489734,  0.06473216],\n       [ 0.62925677, -0.80567676,  0.13517447,  0.04124552],\n       [-0.42348482,  0.17698485,  0.18282615,  0.06367381],\n       [ 0.66989359,  0.20813875, -0.90367767,  0.02564533],\n       [ 0.69693289,  0.21776762,  0.06908747, -0.98378798],\n       [-0.42526022,  0.17640881,  0.18438282,  0.06446858],\n       [-0.42313694,  0.17709777,  0.18252079,  0.06351838],\n       [ 0.69787418,  0.2181133 ,  0.06811328, -0.98410076],\n       [-0.42308891,  0.17711336,  0.18247862,  0.06349693],\n       [-0.42278044,  0.17721351,  0.18220774,  0.06335919],\n       [ 0.6977864 ,  0.21808102,  0.06820422, -0.98407164],\n       [-0.42410228,  0.17678447,  0.18336787,  0.06394994],\n       [ 0.69796329,  0.21814607,  0.06802095, -0.98413031],\n       [-0.4250693 ,  0.17647074,  0.18421557,  0.064383  ],\n       [ 0.62903241, -0.80575166,  0.13538333,  0.04133592],\n       [ 0.66959491,  0.20803491, -0.90338388,  0.02575406],\n       [ 0.66929718,  0.20793144, -0.90309116,  0.02586254],\n       [ 0.66994966,  0.20815826, -0.90373284,  0.02562492],\n       [ 0.66995673,  0.20816071, -0.90373979,  0.02562235],\n       [ 0.63131072, -0.80499053,  0.13325976,  0.04042005],\n       [-0.42504332,  0.17647917,  0.1841928 ,  0.06437135],\n       [ 0.69770029,  0.21804937,  0.0682934 , -0.98404307],\n       [-0.4234285 ,  0.17700313,  0.18277673,  0.06364864],\n       [ 0.66977227,  0.20809657, -0.90355832,  0.02568948],\n       [ 0.69852496,  0.21835283,  0.06743855, -0.98431635],\n       [-0.42152851,  0.17762007,  0.18110746,  0.06280098],\n       [ 0.69760614,  0.21801477,  0.0683909 , -0.98401181],\n       [-0.42404296,  0.17680371,  0.18331585,  0.0639234 ],\n       [ 0.69759448,  0.21801049,  0.06840297, -0.98400794],\n       [ 0.6978327 ,  0.21809805,  0.06815626, -0.984087  ],\n       [-0.42196853,  0.17747715,  0.18149435,  0.06299704],\n       [ 0.66935756,  0.20795242, -0.90315052,  0.02584053],\n       [ 0.69791667,  0.21812893,  0.06806926, -0.98411485],\n       [ 0.6293933 , -0.80563118,  0.13504734,  0.04119054],\n       [ 0.69737825,  0.21793106,  0.06862679, -0.98393611],\n       [ 0.66827738,  0.20757736, -0.90208956,  0.02623482]])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_softmax_back = test_softmax.backward(toy_labels_1)\n",
    "test_softmax_back"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fully Connected Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.0197077 , -0.15633701, -0.08847197,  0.05882853,  0.00443632,\n         0.04698737, -0.00585719, -0.14366789, -0.26101429,  0.15788223,\n        -0.08865479,  0.19789338],\n       [-0.11873753,  0.04720907,  0.15239168, -0.08667135, -0.35689845,\n         0.21129224,  0.07186725,  0.37009072,  0.33252453, -0.56645364,\n        -0.10572233, -0.17907735],\n       [-0.29851232,  0.25905848, -0.01162076, -0.25146439,  0.49477048,\n         0.24520445,  0.41655787,  0.43477944,  0.31256364, -0.1234358 ,\n         0.0922721 , -0.15860194],\n       [ 0.32014768,  0.47224735,  0.16706397, -0.04326672,  0.25204247,\n        -0.52213181, -0.20170405, -0.02727304,  0.52032705,  0.10670346,\n         0.44655221, -0.50896731],\n       [-0.29851948,  0.25904149, -0.01162557, -0.25146075,  0.4947574 ,\n         0.24521848,  0.41656016,  0.43477662,  0.31254507, -0.12343874,\n         0.09225729, -0.15858498],\n       [-0.11885155,  0.04687933,  0.15230093, -0.08658866, -0.35716281,\n         0.21153516,  0.07188539,  0.37000866,  0.33215825, -0.56649241,\n        -0.1060001 , -0.17875184],\n       [-0.02007986, -0.1575733 , -0.08880323,  0.05916532,  0.0034126 ,\n         0.04783439, -0.00584932, -0.14403218, -0.26239567,  0.15776753,\n        -0.08967654,  0.19910273],\n       [ 0.32019952,  0.47238181,  0.16710167, -0.04329784,  0.25214764,\n        -0.52223713, -0.20171718, -0.0272453 ,  0.52047534,  0.10672278,\n         0.44666748, -0.50910093],\n       [-0.02000168, -0.15731302, -0.08873352,  0.05909433,  0.00362823,\n         0.04765626, -0.00585079, -0.14395531, -0.26210483,  0.15779159,\n        -0.08946149,  0.19884816],\n       [ 0.32018032,  0.47233201,  0.16708771, -0.04328632,  0.25210869,\n        -0.52219812, -0.20171231, -0.02725557,  0.52042042,  0.10671562,\n         0.44662479, -0.50905145],\n       [ 0.32002907,  0.47193938,  0.16697764, -0.04319537,  0.25180154,\n        -0.52189073, -0.2016741 , -0.02733671,  0.51998738,  0.10665928,\n         0.44628823, -0.50866128],\n       [ 0.32025135,  0.47251615,  0.16713933, -0.04332892,  0.25225271,\n        -0.52234239, -0.20173033, -0.02721762,  0.52062349,  0.10674211,\n         0.44678267, -0.50923445],\n       [ 0.3202427 ,  0.47249374,  0.16713305, -0.04332374,  0.25223518,\n        -0.52232483, -0.20172813, -0.02722224,  0.52059877,  0.10673889,\n         0.44676345, -0.50921217],\n       [-0.11902298,  0.04638268,  0.15216429, -0.08646396, -0.35756113,\n         0.21190069,  0.07191239,  0.36988476,  0.33160651, -0.56655063,\n        -0.10641835, -0.17826163],\n       [-0.02027978, -0.15824026, -0.0889818 ,  0.05934743,  0.00285979,\n         0.04829035, -0.00584601, -0.14422958, -0.26314102,  0.15770609,\n        -0.09022746,  0.19975497],\n       [-0.11875705,  0.04715266,  0.15237615, -0.08665721, -0.35694367,\n         0.21133382,  0.07187037,  0.37007669,  0.33246186, -0.56646028,\n        -0.10576985, -0.17902166],\n       [-0.01985497, -0.15682543, -0.08860288,  0.05896146,  0.00403204,\n         0.04732228, -0.00585381, -0.14381156, -0.26155999,  0.15783679,\n        -0.08905853,  0.1983712 ],\n       [ 0.32032727,  0.47271279,  0.16719447, -0.04337439,  0.25240646,\n        -0.52249653, -0.20174964, -0.02717717,  0.52084033,  0.10677045,\n         0.44695129, -0.50942988],\n       [-0.29866567,  0.25869398, -0.01172395, -0.25138628,  0.49448976,\n         0.24550532,  0.41660691,  0.43471884,  0.31216528, -0.12349863,\n         0.0919544 , -0.15823822],\n       [-0.02017444, -0.15788858, -0.08888766,  0.05925137,  0.00315132,\n         0.04805001, -0.00584767, -0.14412542, -0.262748  ,  0.15773845,\n        -0.08993699,  0.19941106],\n       [-0.01979217, -0.15661702, -0.08854703,  0.05890472,  0.00420457,\n         0.04717942, -0.0058552 , -0.14375022, -0.26132714,  0.15785616,\n        -0.08888627,  0.19816733],\n       [-0.29841101,  0.25929887, -0.0115527 , -0.25151582,  0.49495559,\n         0.24500581,  0.41652535,  0.43481921,  0.31282631, -0.12339421,\n         0.0924817 , -0.15884183],\n       [-0.0197835 , -0.15658825, -0.08853932,  0.05889689,  0.00422838,\n         0.04715969, -0.0058554 , -0.14374175, -0.26129499,  0.15785884,\n        -0.08886248,  0.19813918],\n       [-0.01972774, -0.15640342, -0.08848977,  0.0588466 ,  0.00438136,\n         0.04703293, -0.00585671, -0.14368741, -0.26108849,  0.15787604,\n        -0.08870969,  0.19795835],\n       [-0.29843481,  0.25924244, -0.01156868, -0.25150375,  0.49491213,\n         0.24505246,  0.416533  ,  0.43480989,  0.31276465, -0.12340399,\n         0.09243249, -0.15878551],\n       [-0.01996628, -0.15719526, -0.08870198,  0.05906223,  0.00372578,\n         0.04757563, -0.00585148, -0.14392057, -0.26197324,  0.15780249,\n        -0.08936418,  0.19873297],\n       [-0.29838685,  0.25935617, -0.01153648, -0.25152807,  0.4949997 ,\n         0.24495844,  0.41651758,  0.43482866,  0.31288891, -0.12338428,\n         0.09253167, -0.15889901],\n       [-0.02014017, -0.15777429, -0.08885706,  0.05922017,  0.00324605,\n         0.04797187, -0.00584825, -0.14409161, -0.26262028,  0.15774898,\n        -0.08984258,  0.1992993 ],\n       [-0.1188046 ,  0.04701514,  0.15233831, -0.08662273, -0.35705391,\n         0.21143513,  0.07187794,  0.37004248,  0.33230911, -0.56647646,\n        -0.1058857 , -0.17888591],\n       [ 0.32025492,  0.47252539,  0.16714192, -0.04333106,  0.25225993,\n        -0.52234963, -0.20173124, -0.02721572,  0.52063367,  0.10674344,\n         0.44679059, -0.50924362],\n       [ 0.32018287,  0.47233862,  0.16708956, -0.04328785,  0.25211386,\n        -0.52220329, -0.20171296, -0.02725421,  0.5204277 ,  0.10671657,\n         0.44663045, -0.50905801],\n       [ 0.32034086,  0.47274798,  0.16720434, -0.04338252,  0.25243398,\n        -0.52252413, -0.20175311, -0.02716994,  0.52087913,  0.10677553,\n         0.44698147, -0.50946485],\n       [ 0.32034257,  0.47275241,  0.16720559, -0.04338355,  0.25243744,\n        -0.5225276 , -0.20175354, -0.02716902,  0.52088401,  0.10677617,\n         0.44698527, -0.50946925],\n       [-0.11832011,  0.04841227,  0.15272303, -0.08697243, -0.35593461,\n         0.21040426,  0.07179958,  0.3703887 ,  0.33386082, -0.56631134,\n        -0.10470828, -0.18026533],\n       [-0.0201355 , -0.15775873, -0.08885289,  0.05921592,  0.00325894,\n         0.04796123, -0.00584833, -0.144087  , -0.26260289,  0.15775041,\n        -0.08982973,  0.19928408],\n       [-0.29845814,  0.25918708, -0.01158435, -0.25149191,  0.49486951,\n         0.2450982 ,  0.41654049,  0.43480074,  0.31270417, -0.12341357,\n         0.09238423, -0.15873027],\n       [-0.01984481, -0.15679169, -0.08859384,  0.05895228,  0.00405997,\n         0.04729916, -0.00585403, -0.14380163, -0.2615223 ,  0.15783992,\n        -0.08903065,  0.1983382 ],\n       [ 0.32029787,  0.47263667,  0.16717313, -0.04335679,  0.25234694,\n        -0.52243685, -0.20174216, -0.02719282,  0.52075639,  0.10675947,\n         0.44688601, -0.50935422],\n       [-0.29823431,  0.25971745, -0.01143418, -0.25160522,  0.49527782,\n         0.24465956,  0.41646841,  0.43488808,  0.31328357, -0.12332151,\n         0.0928468 , -0.15925956],\n       [-0.01950092, -0.15565307, -0.08828855,  0.05864264,  0.0050021 ,\n         0.04651777, -0.00586251, -0.14346725, -0.2602502 ,  0.15794615,\n        -0.08808922,  0.19722416],\n       [-0.29848364,  0.25912656, -0.01160149, -0.25147896,  0.49482291,\n         0.24514821,  0.41654868,  0.43479072,  0.31263803, -0.12342404,\n         0.09233146, -0.15866988],\n       [-0.0199556 , -0.15715974, -0.08869246,  0.05905255,  0.0037552 ,\n         0.04755131, -0.0058517 , -0.14391009, -0.26193355,  0.15780578,\n        -0.08933482,  0.19869823],\n       [-0.2984868 ,  0.25911907, -0.01160361, -0.25147736,  0.49481714,\n         0.2451544 ,  0.41654969,  0.43478948,  0.31262984, -0.12342533,\n         0.09232492, -0.1586624 ],\n       [-0.29842226,  0.2592722 , -0.01156025, -0.25151012,  0.49493505,\n         0.24502786,  0.41652897,  0.4348148 ,  0.31279717, -0.12339883,\n         0.09245845, -0.15881522],\n       [-0.01958074, -0.15591685, -0.08835931,  0.05871429,  0.00478395,\n         0.04669896, -0.00586037, -0.14354456, -0.26054487,  0.15792146,\n        -0.08830737,  0.19748227],\n       [ 0.32019747,  0.47237649,  0.16710018, -0.04329661,  0.25214348,\n        -0.52223296, -0.20171666, -0.0272464 ,  0.52046947,  0.10672202,\n         0.44666292, -0.50909565],\n       [-0.29839949,  0.25932619, -0.01154497, -0.25152166,  0.49497662,\n         0.24498323,  0.41652165,  0.43482372,  0.31285616, -0.12338948,\n         0.09250553, -0.1588691 ],\n       [-0.11872809,  0.04723634,  0.15239919, -0.08667819, -0.35687659,\n         0.21127214,  0.07186574,  0.3700975 ,  0.33255482, -0.56645043,\n        -0.10569935, -0.17910427],\n       [-0.29854532,  0.2589801 , -0.01164295, -0.2514476 ,  0.49471013,\n         0.24526917,  0.41656844,  0.43476644,  0.31247799, -0.12344934,\n         0.09220378, -0.15852373],\n       [ 0.31993666,  0.47169917,  0.16691032, -0.04313967,  0.25161357,\n        -0.52170284, -0.20165087, -0.0273865 ,  0.51972242,  0.10662491,\n         0.44608238, -0.5084226 ]])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fc_back = test_fc.backward(test_softmax_back, learning_rate=0.01)\n",
    "test_fc_back"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Flattening Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.0197077 ,  0.05882853],\n       [-0.00585719,  0.15788223]])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_flattening_back = test_flattening.backward(test_fc_back)\n",
    "test_flattening_back[0, :, :, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f5af371bac0>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = process_mnist_data()\n",
    "img = x_train[0].reshape(28, 28, 1)\n",
    "plt.imshow(img, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 28, 28, 6)\n"
     ]
    }
   ],
   "source": [
    "m = parse_input_model()\n",
    "c1 = ConvolutionLayerBatch(6, 5, 1, 2)\n",
    "mnist_batch_1 = x_train[0:64].reshape(64, 28, 28, 1)\n",
    "o = c1.forward(mnist_batch_1)\n",
    "print(o.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 7.64754773e-02, 2.40503136e-01,\n        4.20315557e-01, 6.47766932e-01, 1.75873942e+00, 3.01259691e+00,\n        4.95988407e+00, 4.78850952e+00, 6.50720480e+00, 6.89531241e+00,\n        9.07941105e+00, 8.36704559e+00, 8.13245339e+00, 6.24397377e+00,\n        3.62799361e+00, 1.47485392e+00, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 3.21998353e-01, 6.52819603e-01,\n        1.65231239e+00, 3.00579486e+00, 4.91712980e+00, 7.28084629e+00,\n        9.49027925e+00, 1.16573060e+01, 1.36664336e+01, 1.59056065e+01,\n        1.77467127e+01, 1.66417301e+01, 1.81970238e+01, 1.84539610e+01,\n        2.05856450e+01, 1.82027279e+01, 1.58214942e+01, 1.07662185e+01,\n        5.78648947e+00, 1.94412987e+00, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.94773711e-01, 2.99079019e+00, 5.90805017e+00,\n        1.01096674e+01, 1.35782502e+01, 1.77668125e+01, 2.05792272e+01,\n        2.27770365e+01, 2.48298798e+01, 2.74473638e+01, 2.97922513e+01,\n        2.96950776e+01, 2.73067661e+01, 2.66507697e+01, 2.74226986e+01,\n        2.52300750e+01, 2.21434859e+01, 1.85148701e+01, 1.26161529e+01,\n        6.80671135e+00, 1.68387795e+00, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 7.45557189e-01, 5.73110907e+00, 1.13306475e+01,\n        1.90001518e+01, 2.50535654e+01, 3.12475236e+01, 3.49813126e+01,\n        3.72545249e+01, 3.82493782e+01, 4.11610075e+01, 4.31480525e+01,\n        4.04783046e+01, 3.54261422e+01, 3.28054656e+01, 3.15968396e+01,\n        2.59770105e+01, 2.24636234e+01, 1.88451041e+01, 1.37177636e+01,\n        7.41556213e+00, 1.91779054e+00, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 9.90598071e-01, 7.97608610e+00, 1.53517800e+01,\n        2.38610095e+01, 3.37846800e+01, 4.14583911e+01, 4.69785709e+01,\n        4.71282130e+01, 4.72945699e+01, 4.75217646e+01, 4.91260730e+01,\n        4.39795435e+01, 3.89881707e+01, 3.57575039e+01, 3.26027765e+01,\n        2.58218223e+01, 2.35929346e+01, 1.96610236e+01, 1.38906445e+01,\n        6.68014644e+00, 1.40128778e+00, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 1.01163331e+00, 8.74337887e+00, 1.64722923e+01,\n        2.40553619e+01, 3.72668054e+01, 4.76903771e+01, 5.48676265e+01,\n        5.41660823e+01, 5.27635946e+01, 5.05367339e+01, 4.79395283e+01,\n        3.85600148e+01, 3.39915009e+01, 3.00762950e+01, 2.29706997e+01,\n        1.64616517e+01, 1.38720599e+01, 1.03832719e+01, 6.42745930e+00,\n        2.53148671e+00, 3.89356249e-01, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 1.03458391e+00, 8.56552409e+00, 1.61743623e+01,\n        2.26688046e+01, 3.60159984e+01, 4.78987729e+01, 5.25966689e+01,\n        5.01971137e+01, 4.61587729e+01, 4.12531716e+01, 3.54183371e+01,\n        2.39989110e+01, 2.02339539e+01, 1.74605444e+01, 9.39186794e+00,\n        4.04854365e+00, 2.90787553e+00, 1.88403928e+00, 9.76481535e-01,\n        2.56480823e-01, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 3.18266107e-01, 4.62620672e+00, 9.42757408e+00,\n        1.33096464e+01, 2.43044573e+01, 3.66536513e+01, 4.23243696e+01,\n        4.10924113e+01, 3.88071692e+01, 3.15980358e+01, 2.36636214e+01,\n        1.23632142e+01, 9.95531836e+00, 7.83695141e+00, 2.95935114e+00,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 1.24506604e+00, 3.37446067e+00,\n        4.36819510e+00, 1.26944595e+01, 2.39544271e+01, 3.10875823e+01,\n        3.29287934e+01, 3.38531117e+01, 2.65622087e+01, 1.67642617e+01,\n        7.90270242e+00, 5.19313406e+00, 3.98275123e+00, 8.78933444e-01,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 2.58472563e-01,\n        2.03549142e-01, 4.65935812e+00, 1.39238669e+01, 2.22412327e+01,\n        2.68361469e+01, 3.22543688e+01, 3.08831410e+01, 2.22814051e+01,\n        1.45264860e+01, 8.60162680e+00, 4.99912887e+00, 1.55298570e+00,\n        3.29836646e-01, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 2.28158172e+00, 8.52514986e+00, 1.76538738e+01,\n        2.31244706e+01, 2.91179158e+01, 3.42582584e+01, 3.04204217e+01,\n        2.41412644e+01, 1.79794110e+01, 1.12380830e+01, 5.49515199e+00,\n        2.13600430e+00, 3.52287966e-01, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 2.13627405e-01, 3.49070615e+00, 1.08239315e+01,\n        1.71476588e+01, 2.41472119e+01, 3.12931720e+01, 3.38892898e+01,\n        3.15337495e+01, 2.79421852e+01, 1.98034248e+01, 1.22193823e+01,\n        5.85234930e+00, 2.39851395e+00, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 5.72388671e-01, 5.13840043e+00,\n        1.11056605e+01, 1.84435764e+01, 2.70454135e+01, 3.39863455e+01,\n        3.71447189e+01, 3.71763383e+01, 2.90372049e+01, 2.16107157e+01,\n        1.08922311e+01, 5.20438988e+00, 7.67637369e-01, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 1.26001443e+00,\n        5.49396158e+00, 1.21516055e+01, 2.15679154e+01, 3.39842954e+01,\n        4.16513573e+01, 4.56301380e+01, 3.82804182e+01, 2.94714443e+01,\n        1.63783662e+01, 6.94224425e+00, 6.64524586e-01, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.03839312e-01, 1.75416305e+00,\n        5.20909048e+00, 1.20803974e+01, 2.08421097e+01, 3.58219462e+01,\n        4.66734764e+01, 5.07455487e+01, 4.50767145e+01, 3.50390610e+01,\n        2.09396295e+01, 9.22424224e+00, 5.92726535e-01, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        2.67437714e-01, 1.30685579e+00, 3.86606249e+00, 8.11281069e+00,\n        1.39532547e+01, 2.10727979e+01, 2.85330060e+01, 4.03626145e+01,\n        4.80263420e+01, 5.08278184e+01, 4.36419729e+01, 3.41430992e+01,\n        2.09322899e+01, 7.97867494e+00, 7.42686982e-01, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 2.58344274e-01, 8.61161990e-01,\n        3.17433862e+00, 6.84907439e+00, 1.27805311e+01, 1.97577063e+01,\n        2.79144193e+01, 3.44544447e+01, 3.91326620e+01, 4.52882803e+01,\n        4.70465516e+01, 4.55883110e+01, 3.66756564e+01, 2.73219554e+01,\n        1.75023181e+01, 6.11647811e+00, 4.10515170e-01, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        2.12877075e-01, 1.76992974e+00, 4.11547018e+00, 7.79984403e+00,\n        1.26733612e+01, 1.94892383e+01, 2.67663692e+01, 3.34745092e+01,\n        3.97290023e+01, 4.40439387e+01, 4.59762834e+01, 4.60468889e+01,\n        4.29186006e+01, 3.72244020e+01, 2.72480752e+01, 1.87231441e+01,\n        1.05622137e+01, 3.10715495e+00, 5.98251919e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 5.49334350e-01, 2.11974460e+00,\n        4.64805725e+00, 9.20542905e+00, 1.41998089e+01, 2.03573442e+01,\n        2.66645923e+01, 3.37740417e+01, 3.91860923e+01, 4.43021917e+01,\n        4.70179768e+01, 4.70411832e+01, 4.43638738e+01, 3.91773691e+01,\n        3.30048192e+01, 2.55677039e+01, 1.72732307e+01, 1.09609223e+01,\n        5.14149262e+00, 1.01652826e+00, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 1.88380923e+00, 6.01173408e+00,\n        1.17891895e+01, 1.97242732e+01, 2.70486714e+01, 3.26901427e+01,\n        3.85660564e+01, 4.29006424e+01, 4.56141230e+01, 4.57191228e+01,\n        4.46390681e+01, 3.97889327e+01, 3.35525225e+01, 2.59528284e+01,\n        1.87750013e+01, 1.21111746e+01, 6.51339057e+00, 2.39796335e+00,\n        4.63766488e-01, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 2.36469196e+00, 7.42343025e+00,\n        1.35388558e+01, 2.14706384e+01, 2.88867487e+01, 3.41598135e+01,\n        3.96147967e+01, 4.25588223e+01, 4.25642010e+01, 3.93465108e+01,\n        3.47735536e+01, 2.72954133e+01, 1.92756767e+01, 1.21627287e+01,\n        6.60914095e+00, 2.52988860e+00, 5.12001048e-01, 5.98251919e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 2.89176561e+00, 8.51506799e+00,\n        1.37717166e+01, 2.21203889e+01, 2.98950394e+01, 3.46126142e+01,\n        3.77252594e+01, 3.67630399e+01, 3.26496180e+01, 2.71952959e+01,\n        2.04474460e+01, 1.35283677e+01, 7.20608219e+00, 2.60778709e+00,\n        6.19699312e-01, 9.70303113e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 2.78229111e+00, 8.05279021e+00,\n        1.30136127e+01, 1.91942358e+01, 2.48099195e+01, 2.64011635e+01,\n        2.59833253e+01, 2.31170610e+01, 1.84854028e+01, 1.34517336e+01,\n        8.74820406e+00, 3.80217203e+00, 9.33684725e-01, 1.07660345e-01,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 2.08217566e+00, 5.18536264e+00,\n        8.07622286e+00, 1.17566289e+01, 1.37555236e+01, 1.28180957e+01,\n        1.14862334e+01, 8.08329003e+00, 5.18990938e+00, 3.10086860e+00,\n        1.00909348e+00, 1.34235431e-01, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02],\n       [4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02,\n        4.91951578e-02, 4.91951578e-02, 4.91951578e-02, 4.91951578e-02]])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0, :, :, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "(64, 28, 28, 6)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = ActivationLayer()\n",
    "o1 = a1.forward(o)\n",
    "o1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "(64, 14, 14, 6)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = MaxPoolingLayerBatch(2, 2)\n",
    "o2 = m1.forward(o1)\n",
    "o2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}