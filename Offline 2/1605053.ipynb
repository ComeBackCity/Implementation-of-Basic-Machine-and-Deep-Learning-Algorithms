{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# package imports\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "from scipy.linalg import eig\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "outputs": [],
   "source": [
    "# get stationary dustribution of transition matrix\n",
    "# from stack overflow\n",
    "def get_stationary_distibution(state_transition_matrix: np.ndarray) -> np.ndarray:\n",
    "    S, U = eig(state_transition_matrix.T)\n",
    "    stationary = np.array(U[:, np.where(np.abs(S - 1.) < 1e-8)[0][0]].flat)\n",
    "    stationary = stationary / np.sum(stationary)\n",
    "    return stationary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "outputs": [],
   "source": [
    "def estimate_sequence(state_transition_matrix:np.ndarray, gaussian_params: np.ndarray, initial_state_probability:np.ndarray, observations:np.ndarray, state_count: int, state_converter:dict):\n",
    "    observation_count = observations.shape[0]\n",
    "    state_probability_matrix = np.zeros((state_count, observation_count))\n",
    "    path = np.ndarray((state_count, observation_count-1), dtype=int)\n",
    "    emission_matrix = norm(loc=gaussian_params[0,:], scale=gaussian_params[1,:]).pdf(observations).T\n",
    "    emission_matrix = normalize(emission_matrix, axis=0)\n",
    "    state_probability_matrix[:,0] = np.log(initial_state_probability) + np.log(emission_matrix[:,0])\n",
    "    for i in range(1, observation_count):\n",
    "        for j in range(state_count):\n",
    "            prob = state_probability_matrix[:,i-1] + np.log(state_transition_matrix[:,j]) + np.log(emission_matrix[j,i])\n",
    "            path[j,i-1] = np.argmax(prob)\n",
    "            state_probability_matrix[j,i] = max(prob)\n",
    "\n",
    "    out_path = ['' for i in range(observation_count)]\n",
    "    sink_index = np.argmax(state_probability_matrix[:,-1])\n",
    "    out_path[observation_count-1] = state_converter[sink_index]\n",
    "    for i in range(observation_count-2,-1,-1):\n",
    "        sink_index = path[sink_index, i]\n",
    "        out_path[i] = state_converter[sink_index]\n",
    "\n",
    "    return path, state_probability_matrix, emission_matrix, out_path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "outputs": [],
   "source": [
    "# Viterbi algorithm\n",
    "def viterbi():\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "outputs": [],
   "source": [
    "# Baum-Welch Learning\n",
    "def baum_welch():\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "outputs": [
    {
     "data": {
      "text/plain": "(1000, 1)"
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "observed_states = np.loadtxt('./Input/data.txt', dtype=float).reshape(-1,1)\n",
    "observed_states.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "outputs": [],
   "source": [
    "# read parameters\n",
    "with open('./Input/parameters.txt.txt', 'r') as f:\n",
    "    no_of_states = int(f.readline())\n",
    "\n",
    "with open('./Input/parameters.txt.txt', 'r') as lines:\n",
    "    transition_matrix = np.genfromtxt(islice(lines, 1, 1+no_of_states))\n",
    "\n",
    "with open('./Input/parameters.txt.txt', 'r') as lines:\n",
    "    gaussian_parameters = np.genfromtxt(islice(lines, 1+no_of_states, 1+2*no_of_states), dtype=int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "outputs": [],
   "source": [
    "initial_distribution = get_stationary_distibution(transition_matrix)\n",
    "index_state_map = {\n",
    "    0: '\\\"El Nino\\\"',\n",
    "    1: '\\\"La Nina\\\"'\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "outputs": [],
   "source": [
    "a, b, c, hidden_path = estimate_sequence(transition_matrix, gaussian_parameters, initial_distribution, observed_states, no_of_states, index_state_map)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 1, 1, ..., 0, 0, 1],\n       [1, 1, 1, ..., 1, 1, 1]])"
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# norm.pdf(104.524317662043, loc=gaussian_parameters[:,0], scale=gaussian_parameters[:,1])\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-4.68619767e+01, -5.42948762e+01, -5.14943271e+01, ...,\n        -5.36454548e+02, -5.90702136e+02, -5.89241290e+02],\n       [-2.87682072e-01, -3.93042588e-01, -4.98403104e-01, ...,\n        -5.35555976e+02, -5.35661337e+02, -5.35766697e+02]])"
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.77894327e-20, 3.50730551e-23, 6.41200887e-22, ...,\n        3.14837047e-01, 3.93979520e-24, 5.37677679e-23],\n       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00, ...,\n        9.49145739e-01, 1.00000000e+00, 1.00000000e+00]])"
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857\n"
     ]
    }
   ],
   "source": [
    "viterbi_output = []\n",
    "with open('./Output/states_Viterbi_wo_learning.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        viterbi_output.append(line.rstrip('\\n'))\n",
    "\n",
    "match = 0\n",
    "\n",
    "for item1, item2 in zip(viterbi_output, hidden_path):\n",
    "    if item1 == item2:\n",
    "        match += 1\n",
    "\n",
    "print(match)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}